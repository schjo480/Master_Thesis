seml:
  executable: main_seml.py
  name: synthetic_d3pm
  output_dir: experiments/synthetic_d3pm
  project_root_dir: ../..
  conda_environment: /ceph/hdd/students/schmitj/miniconda3/base

slurm:
  experiments_per_job: 1
  sbatch_options:
    # partition: gpu_large
    gres: gpu:1       # num GPUs
    mem: 16G          # memory
    cpus-per-task: 12  # num cores
    time: 1-12:00     # max time, D-HH:MM

fixed:
  data:
    dataset: synthetic_graph
    train_data_path: '/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/data/synthetic_small.h5'
    test_data_path: '/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/data/synthetic_small.h5'
    history_len: 5
    future_len: 2
    num_classes: 2
    edge_features: ['one_hot_edges']
    # edge_features: ['one_hot_edges', 'edge_orientations']

  diffusion_config:
    type: 'linear' # Options: 'linear', 'cosine', 'jsd'
    start: 0.0001  # 1e-4 gauss, 0.02 uniform
    stop: 0.02  # 0.02 gauss, 1. uniform
    num_timesteps: 1000
  
  model:
    name: edge_encoder_mlp
    dropout: 0.1
    model_output: logits
    model_prediction: x_start  # Options: 'x_start','xprev'
    transition_mat_type: 'gaussian'  # Options: 'gaussian','uniform','absorbing'
    transition_bands: null
    loss_type: cross_entropy_x_start  # Options: kl, cross_entropy_x_start, hybrid
    hybrid_coeff: 0.001  # Only used for hybrid loss type.
  
  training:
    batch_size: 8
    optimizer: adam
    gradient_accumulation: False
    gradient_accumulation_steps: 8
    num_epochs: 20000
    learning_rate_warmup_steps: 5000 # previously 10000
    lr_decay: 0.9999 # previously 0.9999
    log_loss_every_steps: 20
    save_model: True
    save_model_every_steps: 1000

  testing:
    batch_size: 1
    model_path: '/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/experiments/synthetic_d3pm_without_last_two_relu_longer_training/synthetic_d3pm_without_last_two_relu_longer_training.pth'
  
  wandb:
    exp_name: "synthetic_d3pm_mlp"
    project: "trajectory_prediction_using_denoising_diffusion_models"
    entity: "joeschmit99"
    job_type: "train"
    notes: ""
    tags: ["synthetic_graph", "edge_encoder"]

  eval: False

grid:
  model.class_weights:
    type: choice
    options:
      - [0.05, 0.95]
  model.hidden_channels:
    type: choice
    options:
      - 16
      - 32
      - 64
  model.time_embedding_dim: 
    type: choice
    options:
      - 16
      - 32
      - 64
  model.condition_dim: 
    type: choice
    options:
      - 16
      - 32
      - 64
  model.num_layers: 
    type: choice
    options:
      - 2
      - 3
      - 4
  training.lr:
    type: choice
    options:
      - 0.01

random:
  samples: 1
  seed: 7059
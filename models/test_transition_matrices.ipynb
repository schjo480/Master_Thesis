{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000e+00, 4.2085e-07],\n",
      "        [6.3086e-04, 9.9937e-01]])\n",
      "tensor([[9.9998e-01, 1.8605e-05],\n",
      "        [2.7889e-02, 9.7211e-01]])\n",
      "tensor([[9.9994e-01, 6.1386e-05],\n",
      "        [9.2017e-02, 9.0798e-01]])\n",
      "tensor([[9.9987e-01, 1.2542e-04],\n",
      "        [1.8800e-01, 8.1200e-01]])\n",
      "tensor([[9.9979e-01, 2.0570e-04],\n",
      "        [3.0835e-01, 6.9165e-01]])\n",
      "tensor([[9.9970e-01, 2.9595e-04],\n",
      "        [4.4364e-01, 5.5636e-01]])\n",
      "tensor([[9.9961e-01, 3.8913e-04],\n",
      "        [5.8330e-01, 4.1670e-01]])\n",
      "tensor([[9.9952e-01, 4.7793e-04],\n",
      "        [7.1642e-01, 2.8358e-01]])\n",
      "tensor([[9.9944e-01, 5.5543e-04],\n",
      "        [8.3259e-01, 1.6741e-01]])\n",
      "tensor([[9.9938e-01, 6.1557e-04],\n",
      "        [9.2273e-01, 7.7265e-02]])\n",
      "tensor([[9.9935e-01, 6.5364e-04],\n",
      "        [9.7980e-01, 2.0198e-02]])\n",
      "tensor([[9.9933e-01, 6.6667e-04],\n",
      "        [9.9933e-01, 6.6691e-04]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"import matplotlib.pyplot as plt\\n\\nspec = {'type': 'linear', 'start': 1.0, 'stop': 100.0, 'num_timesteps': 100}\\nbetas = get_diffusion_betas(spec, device='cpu')\\nplt.plot(betas)\\nplt.show()\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "def get_diffusion_betas(spec, device):\n",
    "    \"\"\"Get betas from the hyperparameters.\"\"\"\n",
    "    \n",
    "    if spec['type'] == 'linear':\n",
    "        # Used by Ho et al. for DDPM, https://arxiv.org/abs/2006.11239.\n",
    "        # To be used with Gaussian diffusion models in continuous and discrete\n",
    "        # state spaces.\n",
    "        # To be used with transition_mat_type = 'gaussian'\n",
    "        return torch.linspace(spec['start'], spec['stop'], spec['num_timesteps']).to(device)\n",
    "    elif spec['type'] == 'cosine':\n",
    "        # Schedule proposed by Hoogeboom et al. https://arxiv.org/abs/2102.05379\n",
    "        # To be used with transition_mat_type = 'uniform'.\n",
    "        steps = torch.linspace(0, 1, spec['num_timesteps'] + 1, dtype=torch.float64)\n",
    "        alpha_bar = torch.square(torch.cos(((steps + 0.008) / 1.008) * torch.pi / 2))\n",
    "        betas = torch.minimum(1 - alpha_bar[1:] / alpha_bar[:-1], torch.tensor(0.999))\n",
    "        return betas.to(device)\n",
    "    elif spec['type'] == 'jsd':  # 1/T, 1/(T-1), 1/(T-2), ..., 1\n",
    "        # Proposed by Sohl-Dickstein et al., https://arxiv.org/abs/1503.03585\n",
    "        # To be used with absorbing state models.\n",
    "        # ensures that the probability of decaying to the absorbing state\n",
    "        # increases linearly over time, and is 1 for t = T-1 (the final time).\n",
    "        # To be used with transition_mat_type = 'absorbing'\n",
    "        return 1. / torch.linspace(spec['num_timesteps'], 1, spec['num_timesteps']).to(device)\n",
    "    else:\n",
    "        raise NotImplementedError(spec['type'])\n",
    "    \n",
    "    \n",
    "def _get_gaussian_transition_mat(t):\n",
    "    r\"\"\"Computes transition matrix for q(x_t|x_{t-1}).\n",
    "\n",
    "    This method constructs a transition matrix Q with\n",
    "    decaying entries as a function of how far off diagonal the entry is.\n",
    "    Normalization option 1:\n",
    "    Q_{ij} =  ~ softmax(-val^2/beta_t)   if |i-j| <= transition_bands\n",
    "                1 - \\sum_{l \\neq i} Q_{il}  if i==j.\n",
    "                0                          else.\n",
    "\n",
    "    Normalization option 2:\n",
    "    tilde{Q}_{ij} =  softmax(-val^2/beta_t)   if |i-j| <= transition_bands\n",
    "                        0                        else.\n",
    "\n",
    "    Q_{ij} =  tilde{Q}_{ij} / sum_l{tilde{Q}_{lj}}\n",
    "\n",
    "    Args:\n",
    "        t: timestep. integer scalar (or numpy array?)\n",
    "\n",
    "    Returns:\n",
    "        Q_t: transition matrix. shape = (num_classes, num_classes).\n",
    "    \"\"\"\n",
    "    num_classes = 2\n",
    "    device = 'cpu'\n",
    "    transition_bands = 1\n",
    "    spec = {'type': 'cosine', 'start': 0.9, 'stop': 1.0, 'num_timesteps': 100}\n",
    "    betas = get_diffusion_betas(spec, device=device)\n",
    "    transition_bands = transition_bands if transition_bands else num_classes - 1\n",
    "\n",
    "    beta_t = betas[t]\n",
    "\n",
    "    mat = torch.zeros((num_classes, num_classes),\n",
    "                    dtype=torch.float64).to(device, non_blocking=True)\n",
    "\n",
    "    # Make the values correspond to a similar type of gaussian as in the\n",
    "    # gaussian diffusion case for continuous state spaces.\n",
    "    values = torch.linspace(torch.tensor(0.), torch.tensor(num_classes-1), num_classes, dtype=torch.float64).to(device, non_blocking=True)\n",
    "    #print(values)   # [0, 1]\n",
    "    values = values * 2./ (num_classes - 1.)\n",
    "    #print(values)   # [0, 2]\n",
    "    values = values[:transition_bands+1]\n",
    "    #print(values)   # [0, 2]\n",
    "    values = -values * values / beta_t\n",
    "    #print(values)   # [0, -6300]\n",
    "    \n",
    "    # To reverse the tensor 'values' starting from the second element\n",
    "    reversed_values = values[1:].flip(dims=[0])\n",
    "    #print(reversed_values)  # [-6300]\n",
    "    # Concatenating the reversed values with the original values\n",
    "    values = torch.cat([reversed_values, values], dim=0)\n",
    "    #print(values)   # [-6300, 0, -6300]\n",
    "    values = F.softmax(values, dim=0)\n",
    "    #print(values)   # [0, 1, 0]\n",
    "    values = values[transition_bands:]\n",
    "    #print(values)   # [1, 0]\n",
    "    \n",
    "    for k in range(1, transition_bands + 1):\n",
    "        off_diag = torch.full((num_classes - k,), values[k], dtype=torch.float64).to(device, non_blocking=True)\n",
    "\n",
    "        mat += torch.diag(off_diag, k)\n",
    "        mat += torch.diag(off_diag, -k)\n",
    "\n",
    "    # Add diagonal values such that rows and columns sum to one.\n",
    "    # Technically only the ROWS need to sum to one\n",
    "    # NOTE: this normalization leads to a doubly stochastic matrix,\n",
    "    # which is necessary if we want to have a uniform stationary distribution.\n",
    "    diag = 1. - mat.sum(dim=1)\n",
    "    mat += torch.diag_embed(diag)\n",
    "\n",
    "    return mat.to(device, non_blocking=True)\n",
    "\n",
    "def _get_prior_distribution_transition_mat(t):\n",
    "        \"\"\"Computes transition matrix for q(x_t|x_{t-1}).\n",
    "        Use cosine schedule for these transition matrices.\n",
    "\n",
    "        Args:\n",
    "        t: timestep. integer scalar.\n",
    "\n",
    "        Returns:\n",
    "        Q_t: transition matrix. shape = (num_classes, num_classes).\n",
    "        \"\"\"\n",
    "        device = 'cpu'\n",
    "        spec = {'type': 'cosine', 'start': 0.9, 'stop': 1.0, 'num_timesteps': 100}\n",
    "        betas = get_diffusion_betas(spec, device=device)\n",
    "        beta_t = betas[t]\n",
    "        num_classes = 2\n",
    "        class_probs = torch.tensor([1 - 10/15000, 10/15000], device=device)\n",
    "        mat = torch.zeros((num_classes, num_classes), dtype=torch.float64).to(device, non_blocking=True)\n",
    "\n",
    "        '''for i in range(num_classes):\n",
    "            for j in range(num_classes):\n",
    "                if i != j:\n",
    "                    mat[i, j] = beta_t * class_probs[j]\n",
    "                else:\n",
    "                    mat[i, j] = 1 - beta_t + beta_t * class_probs[j]'''\n",
    "        mat = beta_t * class_probs + (1 - beta_t) * torch.eye(2, device=device)\n",
    "        \n",
    "        return mat\n",
    "\n",
    "\n",
    "q_one_step_mats = [_get_prior_distribution_transition_mat(t)\n",
    "                            for t in range(0, 100)]\n",
    "q_onestep_mats = torch.stack(q_one_step_mats, axis=0).to('cpu', non_blocking=True)\n",
    "assert q_onestep_mats.shape == (100,\n",
    "                                    2,\n",
    "                                    2)\n",
    "\n",
    "# Construct transition matrices for q(x_t|x_start)\n",
    "q_mat_t = q_onestep_mats[0]\n",
    "q_mats = [q_mat_t]\n",
    "for t in range(1, 100):\n",
    "    # Q_{1...t} = Q_{1 ... t-1} Q_t = Q_1 Q_2 ... Q_t\n",
    "    q_mat_t = torch.tensordot(q_mat_t, q_onestep_mats[t],\n",
    "                            dims=[[1], [0]])\n",
    "    q_mats.append(q_mat_t)\n",
    "q_mats = torch.stack(q_mats, axis=0)\n",
    "\n",
    "for t in range(0, 100, 9):\n",
    "    print(q_mats[t])\n",
    "    # print(_get_gaussian_transition_mat(t))\n",
    "    # print(_get_prior_distribution_transition_mat(t))\n",
    "\n",
    "'''import matplotlib.pyplot as plt\n",
    "\n",
    "spec = {'type': 'linear', 'start': 1.0, 'stop': 100.0, 'num_timesteps': 100}\n",
    "betas = get_diffusion_betas(spec, device='cpu')\n",
    "plt.plot(betas)\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9000, 0.1000],\n",
      "         [0.9000, 0.1000]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "e_marginals = torch.tensor([0.9, 0.1], dtype=torch.float64)\n",
    "print(e_marginals.unsqueeze(0).expand(2, -1).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "[0. 2.]\n",
      "[0. 2.]\n",
      "[-0. -4.]\n",
      "[-4. -0. -4.]\n",
      "[0.01766842 0.96466316 0.01766842]\n",
      "[0.96466316 0.01766842]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.98233158, 0.01766842],\n",
       "       [0.01766842, 0.98233158]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as onp\n",
    "def get_diffusion_betas(spec):\n",
    "  \"\"\"Get betas from the hyperparameters.\"\"\"\n",
    "  if spec['type'] == 'linear':\n",
    "    # Used by Ho et al. for DDPM, https://arxiv.org/abs/2006.11239.\n",
    "    # To be used with Gaussian diffusion models in continuous and discrete\n",
    "    # state spaces.\n",
    "    # To be used with transition_mat_type = 'gaussian'\n",
    "    return onp.linspace(spec['start'], spec['stop'], spec['num_timesteps'])\n",
    "  elif spec['type'] == 'cosine':\n",
    "    # Schedule proposed by Hoogeboom et al. https://arxiv.org/abs/2102.05379\n",
    "    # To be used with transition_mat_type = 'uniform'.\n",
    "    steps = (\n",
    "        onp.arange(spec['num_timesteps'] + 1, dtype=onp.float64) /\n",
    "        spec['num_timesteps'])\n",
    "    alpha_bar = onp.cos((steps + 0.008) / 1.008 * onp.pi / 2)\n",
    "    betas = onp.minimum(1 - alpha_bar[1:] / alpha_bar[:-1], 0.999)\n",
    "    return betas\n",
    "  elif spec['type'] == 'jsd':  # 1/T, 1/(T-1), 1/(T-2), ..., 1\n",
    "    # Proposed by Sohl-Dickstein et al., https://arxiv.org/abs/1503.03585\n",
    "    # To be used with absorbing state models.\n",
    "    # ensures that the probability of decaying to the absorbing state\n",
    "    # increases linearly over time, and is 1 for t = T-1 (the final time).\n",
    "    # To be used with transition_mat_type = 'absorbing'\n",
    "    return 1. / onp.linspace(spec['num_timesteps'], 1., spec['num_timesteps'])\n",
    "  else:\n",
    "    raise NotImplementedError(spec['type'])\n",
    "  \n",
    "spec = {'type': 'linear', 'start': 0.9, 'stop': 1.0, 'num_timesteps': 100}\n",
    "betas = get_diffusion_betas(spec)\n",
    "plt.plot(betas)\n",
    "plt.show()\n",
    "\n",
    "import scipy\n",
    "def _get_gaussian_transition_mat(t):\n",
    "    r\"\"\"Computes transition matrix for q(x_t|x_{t-1}).\n",
    "\n",
    "    This method constructs a transition matrix Q with\n",
    "    decaying entries as a function of how far off diagonal the entry is.\n",
    "    Normalization option 1:\n",
    "    Q_{ij} =  ~ softmax(-val^2/beta_t)   if |i-j| <= transition_bands\n",
    "             1 - \\sum_{l \\neq i} Q_{il}  if i==j.\n",
    "             0                          else.\n",
    "\n",
    "    Normalization option 2:\n",
    "    tilde{Q}_{ij} =  softmax(-val^2/beta_t)   if |i-j| <= transition_bands\n",
    "                     0                        else.\n",
    "\n",
    "    Q_{ij} =  tilde{Q}_{ij} / sum_l{tilde{Q}_{lj}}\n",
    "\n",
    "    Args:\n",
    "      t: timestep. integer scalar (or numpy array?)\n",
    "\n",
    "    Returns:\n",
    "      Q_t: transition matrix. shape = (num_pixel_vals, num_pixel_vals).\n",
    "    \"\"\"\n",
    "    transition_bands = 2 - 1\n",
    "    betas = get_diffusion_betas(spec)\n",
    "    beta_t = betas[t]\n",
    "\n",
    "    mat = onp.zeros((2, 2),\n",
    "                    dtype=onp.float64)\n",
    "\n",
    "    # Make the values correspond to a similar type of gaussian as in the\n",
    "    # gaussian diffusion case for continuous state spaces.\n",
    "    values = onp.linspace(start=0., stop=1., num=2,\n",
    "                          endpoint=True, dtype=onp.float64)\n",
    "    print(values)\n",
    "    values = values * 2./ (2 - 1.)\n",
    "    print(values)\n",
    "    values = values[:transition_bands+1]\n",
    "    print(values)\n",
    "    values = -values * values / beta_t\n",
    "    print(values)\n",
    "\n",
    "    values = onp.concatenate([values[:0:-1], values], axis=0)\n",
    "    print(values)\n",
    "    values = scipy.special.softmax(values, axis=0)\n",
    "    print(values)\n",
    "    values = values[transition_bands:]\n",
    "    print(values)\n",
    "    for k in range(1, transition_bands + 1):\n",
    "      off_diag = onp.full(shape=(2 - k,),\n",
    "                          fill_value=values[k],\n",
    "                          dtype=onp.float64)\n",
    "\n",
    "      mat += onp.diag(off_diag, k=k)\n",
    "      mat += onp.diag(off_diag, k=-k)\n",
    "\n",
    "    # Add diagonal values such that rows and columns sum to one.\n",
    "    # Technically only the ROWS need to sum to one\n",
    "    # NOTE: this normalization leads to a doubly stochastic matrix,\n",
    "    # which is necessary if we want to have a uniform stationary distribution.\n",
    "    diag = 1. - mat.sum(1)\n",
    "    mat += onp.diag(diag, k=0)\n",
    "\n",
    "    return mat\n",
    "  \n",
    "_get_gaussian_transition_mat(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_beta_schedule(T, s=0.008):\n",
    "    \"\"\"\n",
    "    Generate a cosine schedule for diffusion betas.\n",
    "    \n",
    "    Args:\n",
    "    - T (int): The total number of diffusion timesteps.\n",
    "    - s (float): A small constant to ensure the betas do not reach 0, which could cause numerical stability issues.\n",
    "    \n",
    "    Returns:\n",
    "    - np.array: An array of length T with the beta values for each timestep.\n",
    "    \"\"\"\n",
    "    steps = np.arange(T, dtype=np.float64)\n",
    "    x = s + (1 - s) * np.cos(0.5 * np.pi * steps / T)\n",
    "    betas = 1 - x / x.max()\n",
    "    return betas\n",
    "\n",
    "# Example usage\n",
    "T = 1000  # Total number of diffusion steps\n",
    "betas = cosine_beta_schedule(T)\n",
    "alphas = 1 - betas\n",
    "alpha_bar = np.cumprod(alphas)\n",
    "plt.plot(betas)\n",
    "#plt.plot(alphas)\n",
    "plt.plot(alpha_bar)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABA80lEQVR4nO3dd3xV9eHG8eeO5GZfCCELkhBEZK8EkKV1RVGpW1QgbE0dCLRWKf3VSge2thYXKLJEEHGgRaVqtMpeCQFZMmQkkISQAElIyLzn9weaNgU0++Qmn/frdV82535P7nO/oPfpued8j8UwDEMAAAAmsZodAAAANG+UEQAAYCrKCAAAMBVlBAAAmIoyAgAATEUZAQAApqKMAAAAU1FGAACAqexmB6gKl8ul9PR0+fv7y2KxmB0HAABUgWEYys/PV3h4uKzWSx//cIsykp6eroiICLNjAACAGkhLS1Pbtm0v+bxblBF/f39J599MQECAyWkAAEBV5OXlKSIiouJz/FLcooz88NVMQEAAZQQAADfzU6dYcAIrAAAwFWUEAACYijICAABMRRkBAACmoowAAABTUUYAAICpKCMAAMBUlBEAAGAqyggAADBVtcvImjVrNGzYMIWHh8tisejDDz/8yX1Wr16tmJgYeXl5qX379nr11VdrkhUAADRB1S4jBQUF6tmzp15++eUqjT98+LBuvvlmDRkyRCkpKfrNb36jSZMm6f333692WAAA0PRU+940Q4cO1dChQ6s8/tVXX1VkZKRmzZolSercubOSkpL0t7/9TXfddVd1Xx4AADQx9X6jvI0bNyouLq7SthtvvFHz589XaWmpPDw8LtinuLhYxcXFFT/n5eXVS7b3k49pV3qu/Bx2+f7w8LTJ12FXoK+ngv0dau3vkI+nW9xPEAAAt1Tvn7KZmZkKCQmptC0kJERlZWXKzs5WWFjYBfvMnDlTzzzzTH1H09f7T+qjHek/Oc7X06bW/g4FB3gpMtBHUYE+imzlo6hWvmrXykctfDzrPSsAAE1Vg/xf/v+9dbBhGBfd/oNp06Zp6tSpFT/n5eUpIiKiznPd1DVUbVt6q6C4TGeLy1RQXKaC4nLlF5fpdEGJsvKLVFTqUkFJuQpyCnUkp1BbDp+64Pe09neoU6i/OocFqFOovzqFBqhDsJ887VysBADAT6n3MhIaGqrMzMxK27KysmS329WqVauL7uNwOORwOOo7mm7pEaZbelx4ZOYHhmGooKRcJ/OLdTK/WBm553Q0p1BHcwqVeqpAR3MKlfX9cyfzi7X2QHbFvp52q7q3capPZAv1iWyp3pEtFer0qvf3BACAu6n3MjJgwAB99NFHlbZ9/vnnio2Nvej5Io2JxWKRn8MuP4dd0UG+Fx1TUFym/Sfy9W1mvr7NyNPe7/+ZV1Sm5KOnlXz0tKTDkqQ2Lbx1ZftWGnx5Kw3qEKRgf8oJAADVLiNnz57VwYMHK34+fPiwtm/frsDAQEVGRmratGk6fvy4Fi9eLElKSEjQyy+/rKlTp2rixInauHGj5s+fr2XLltXduzCRr8Ou3t8f+fiBYRg6klOobUdPa1vqaW1LPaN9mXk6fuac3t92TO9vOyZJuiLEX4M6BOmqjkEacFkrOew2s94GAACmsRg/nMBRRV9//bWuueaaC7aPHj1aixYt0pgxY3TkyBF9/fXXFc+tXr1aU6ZM0e7duxUeHq4nn3xSCQkJVX7NvLw8OZ1O5ebmKiAgoDpxG42zxWVKST2t9QdztP5gtnal5+q/Z97X06arr2itG7qE6JorgjkpFgDg9qr6+V3tMmKGplBG/tfpghJtPJSjtQdO6su9WcrK/8+lzDarRf3aBerWnmG6uVuYWvpSTAAA7ocy4kZcLkM7j+cqcc8JfbH3hL7NzK94zm616KqOrfXznuG6oUuIfB2seQIAcA+UETeWmlOof+3K0Mod6dqd/p8F37w8rLqpa6iG943Ule0DL3lpNAAAjQFlpIk4mHVWK3ek66Md6TqcXVCxvV0rH90TG6F7YtoqOICrcgAAjQ9lpIkxDEM7juXqnaQ0rdyerrPFZZLOn19ybadgjRnYTgMva8XREgBAo0EZacIKS8r0yTcZWr41TUlHT1ds7xjipzEDo3VH7zby9uQyYQCAuSgjzcTBrHwt3nhU7yUfU2FJuSSphY+H7usbqfgBUQpv4W1yQgBAc0UZaWbyikr1ztY0vbHxiNJOnZN0/kqc23u3UcLVl6lDsJ/JCQEAzQ1lpJkqdxn6cu8JLVh/WJsOnb+pn8Vy/qaAD/+sg7q3dZqcEADQXFBGoJTU05r99XdK3HOiYtuQy4P02LWXq190oInJAADNAWUEFfZl5uvV1d9p5Y50lbvO/3EPuTxIv4q7Qj0jWpgbDgDQZFFGcIHUnELNWf2d3k1KU9n3pSSuS4imxnVUp1DmFQBQtygjuKTUnELN+nK/Pkw5Lpdx/pySYT3CNeWGjooO8jU7HgCgiaCM4CcdzMrXPxIP6JOdGZLOX30zakCUHr/ucu4aDACoNcoIqmx3eq6e+2yfvt53UpLk9PbQY9d2UPyAdvK0W01OBwBwV5QRVNvaAyf1p0/2Vtw1uF0rHz01tJNu7BrKMvMAgGqjjKBGyl2G3k1K098T9+tkfrEk6cr2gfrDbd10eYi/yekAAO6EMoJaKSgu02urv9Nraw6puMwlu9WicYOjNem6y+XnsJsdDwDgBigjqBNppwo14+M9FQunhQZ4afotnXVrjzC+ugEA/Kiqfn5zdiJ+VESgj16Pj9WCMbGKDPRRZl6RHluWohHzNutg1lmz4wEAmgDKCKrk2k4h+nzKVZpyfUc57FZt+C5HN7+wVi9+eUAlZS6z4wEA3BhlBFXm5WHT49dfrsQpV+uaK1qrpNyl5xP3a9hL67Q97YzZ8QAAbooygmqLbOWjBWP66oX7einQ11P7TuTrztnr9YeP96iwpMzseAAAN0MZQY1YLBbd1quNvph6te7o3UYuQ5q/7rBunLVGaw+cNDseAMCNUEZQK4G+nvrH8F5aOLav2rTwVtqpcxo1f4t+88FOFRRzlAQA8NMoI6gT11wRrM+mXKXRA6IkSW9tTtXQF9Yq6cgpk5MBABo7ygjqjJ/Drmdu66a3JvRXmxbeSj1VqHte26iZ/9qr4rJys+MBABopygjq3MAOQfrX5CG6O6atDEN6bfUh/fyl9dqdnmt2NABAI0QZQb0I8PLQ3+7pqbmjYtTq+ytubn9lveZ8/Z1crka/6C8AoAFRRlCv4rqG6rMpV+nGriEqLTf0l0+/VfyCLcrKKzI7GgCgkaCMoN4F+Tn06sgY/eWu7vLysGrdwWwNfWGtvtqXZXY0AEAjQBlBg7BYLBreN1IfPzZYnUL9lVNQorELt+oPH+/h5FYAaOYoI2hQHYL99eEjgzRmYDtJ5xdKu2vOBh06yU33AKC5ooygwXl52PT7n3fVvPhYtfTx0K7jebr1pXX65/bjZkcDAJiAMgLTXN8lRP96/CoNaN9KhSXlevzt7fq/D3fxtQ0ANDOUEZgq1OmlJRP667FrO0iS3tx0VPe+tknHTheanAwA0FAoIzCdzWrRL+Ou0MIxfeX09tCOtDO69aV1+pqrbQCgWaCMoNG4plOwPn5ssHq0depMYanGLtqq5xP3q5xF0gCgSaOMoFGJCPTRuwkDNKJ/pAxDevHLAxqzcItOF5SYHQ0AUE8oI2h0HHab/nRHdz1/b095eVi19kC2fv7KOn2bmWd2NABAPaCMoNG6s09bffDwIEUEeivt1DndOXuDPt2VYXYsAEAdo4ygUescFqCVjwzWwMvOX/6bsGSbnv98HzfbA4AmhDKCRq+lr6cWj+uncYOiJUkv/vugHnwzWflFpSYnAwDUBcoI3ILdZtXvhnXR3+7pKU+7VV/sPaE7Zm/Q4ewCs6MBAGqJMgK3cndMW73z0ACFBDh0MOusbnt5ndYdyDY7FgCgFigjcDu9Ilroo0cHq09kC+UVlWn0wi1atiXV7FgAgBqijMAtBQd4admDV+r2XuEqdxmatmKn/rxqLwukAYAboozAbTnsNv1jeC9Nub6jJGnumkNKWJKswpIyk5MBAKqDMgK3ZrFY9Pj1l+uF+3rJ02ZV4p4Tuve1jcrMLTI7GgCgiigjaBJu69VGb03sr0BfT+06nqfbX1mvXcdzzY4FAKgCygiajNh2gfrw4UHqEOynzLwi3fvaRn2594TZsQAAP4EygiYlspWP3v/FQA3uEKTCknJNXJzElTYA0MhRRtDkOL09tHBsX90d01YuQ5q2Yqf+kbhfhsGVNgDQGFFG0CR52Kx67u4eeuzaDpKkF748oKfe36mycpfJyQAA/4sygibLYrHol3FX6E93dJPVIi1PStPExUlc+gsAjQxlBE3eiP5RenVkjBx2q77ad1L3z92k7LPFZscCAHyPMoJmIa5rqN6aeKVa+nhox7Fc3TVng45wkz0AaBQoI2g2YqJa6r1fDFTblt46mlOou+Zs0M5jrEUCAGarURmZPXu2oqOj5eXlpZiYGK1du/ZHxy9dulQ9e/aUj4+PwsLCNHbsWOXk5NQoMFAbl7X204qHB6preIByCkp0/+ubtOkQfxcBwEzVLiPLly/X5MmTNX36dKWkpGjIkCEaOnSoUlMvvpbDunXrFB8fr/Hjx2v37t169913tXXrVk2YMKHW4YGaCPb30tsPXqn+0YE6W1ym+AVb9MUeFkcDALNUu4w8//zzGj9+vCZMmKDOnTtr1qxZioiI0Jw5cy46ftOmTWrXrp0mTZqk6OhoDR48WA899JCSkpJqHR6oKX8vD70xrp+u7xyikjKXHlqSrA9SjpkdCwCapWqVkZKSEiUnJysuLq7S9ri4OG3YsOGi+wwcOFDHjh3TqlWrZBiGTpw4offee0+33HLLJV+nuLhYeXl5lR5AXfPysOnVkX10Z582KncZmrJ8hxauP2x2LABodqpVRrKzs1VeXq6QkJBK20NCQpSZmXnRfQYOHKilS5dq+PDh8vT0VGhoqFq0aKGXXnrpkq8zc+ZMOZ3OikdERER1YgJVZrdZ9be7e2rsoHaSpGc+2sNqrQDQwGp0AqvFYqn0s2EYF2z7wZ49ezRp0iT97ne/U3Jysj799FMdPnxYCQkJl/z906ZNU25ubsUjLS2tJjGBKrFaLfrdrV009YaOks6v1vrMR3vkclFIAKAh2KszOCgoSDab7YKjIFlZWRccLfnBzJkzNWjQID3xxBOSpB49esjX11dDhgzRH//4R4WFhV2wj8PhkMPhqE40oFYsFosmXXe5Wvh46Hf/3K1FG44o71yp/np3D9ltXAEPAPWpWv+V9fT0VExMjBITEyttT0xM1MCBAy+6T2FhoazWyi9js9kkiUPhaHTiB7TTC/f1kt1q0YqU45r0dopKyrifDQDUp2r/X76pU6dq3rx5WrBggfbu3aspU6YoNTW14muXadOmKT4+vmL8sGHDtGLFCs2ZM0eHDh3S+vXrNWnSJPXr10/h4eF1906AOnJbrzaaMzJGnjarVu3M1MNLk1VUWm52LABosqr1NY0kDR8+XDk5OZoxY4YyMjLUrVs3rVq1SlFRUZKkjIyMSmuOjBkzRvn5+Xr55Zf1y1/+Ui1atNC1116rv/zlL3X3LoA6dkOXEL0+OlYPLk7SF3uzNHFxkuaOipW3p83saADQ5FgMN/iuJC8vT06nU7m5uQoICDA7DpqRDd9la8IbSSosKVf/6EDNH9NXfo5qd3gAaJaq+vnNmXnAjxh4WZDeHN9P/g67Nh8+pVHzNyv3XKnZsQCgSaGMAD8hJipQSyf2l9PbQympZzRi3iadLigxOxYANBmUEaAKerRtoWUTr1QrX0/tOp6n++Zu0sn8YrNjAUCTQBkBqqhLeICWP3Slgv0d2nciX8PnblRWXpHZsQDA7VFGgGroEOyvdx4aoHCnlw6dLNB9r2+ikABALVFGgGpqF+Srtx8coDYtvCkkAFAHKCNADUS28tGyiVdSSACgDlBGgBqikABA3aCMALVAIQGA2qOMALVEIQGA2qGMAHWAQgIANUcZAeoIhQQAaoYyAtSh/y0kD8zbrOyzrNQKAD+GMgLUsR8KSZjTSwezzmrkvM06U8i9bADgUigjQD2IbOWjpRP6q7W/Q99m5mvU/C3KK+JuvwBwMZQRoJ60b+2npRP6K9DXUzuP52rswq0qKC4zOxYANDqUEaAedQzx15vj+ynAy67ko6c1/o2tOldSbnYsAGhUKCNAPesa7tSb4/vLz2HXpkOn9OCbSSoqpZAAwA8oI0AD6BnRQovG9pWPp01rD2Tr0be2qaTMZXYsAGgUKCNAA4ltF6h5o2PlsFv1xd4sPf52isrKKSQAQBkBGtDAy4I0Nz5Wnjar/rUrU798d4fKXYbZsQDAVJQRoIFd3bG1XhnRR3arRf/cnq5pK76Ri0ICoBmjjAAmuKFLiF64r7esFumdpGP6wyd7ZBgUEgDNE2UEMMktPcL03N09JUkL1x/RC18eMDkRAJiDMgKY6K6Ytvr9sC6SpFlfHNCCdYdNTgQADY8yAphszKBoTb2hoyRpxsd79G5SmsmJAKBhUUaARuCxaztowuBoSdKT73+jT3dlmJwIABoOZQRoBCwWi6bf0lnDYyPkMqTHlqVozf6TZscCgAZBGQEaCYvFoj/f2V23dA9Tabmhh95MVvLRU2bHAoB6RxkBGhGb1aJ/DO+lqzq21rnSco1ZuFV70vPMjgUA9YoyAjQynnarXh3ZR7FRLZVfVKb4BZt1OLvA7FgAUG8oI0Aj5ONp1/wxfdUlLEDZZ0s0ct5mpZ85Z3YsAKgXlBGgkXJ6e2jx+H5qH+Sr42fOaeT8zTpVUGJ2LACoc5QRoBEL8nNoyYT+Cnd66dDJAo1duEUFxWVmxwKAOkUZARq58BbeWjy+v1r6eGjHsVwlLElWSZnL7FgAUGcoI4Ab6BDspwVj+srbw6a1B7L1q3d3cKdfAE0GZQRwE70jW+rVUTGyWy1auSNdMz7mTr8AmgbKCOBGru7YWn+/9/ydfhdtOKLZX39nciIAqD3KCOBmbuvVRr+79fydfp/7bJ+WbUk1OREA1A5lBHBD4wZH6+GfXSZJmv7BTn26K9PkRABQc5QRwE09ceMVFTfWm/R2ijYdyjE7EgDUCGUEcFMWi0V/uqObbugSopIylya+kcR9bAC4JcoI4MbsNqteur+3+rULVH5xmeIXbFFqTqHZsQCgWigjgJvz8rDp9dGx6hTqr+yzxRq1YLNO5hebHQsAqowyAjQBTm8PLR7XT21beutoTqHGLNyi/KJSs2MBQJVQRoAmIjjAS2+O769Wvp7anZ6nXyzZxrLxANwCZQRoQqKDfLVwbF/5eNq07mC2nnz/G1ZpBdDoUUaAJqZH2xZ6ZUQf2awWfZByXH/9bJ/ZkQDgR1FGgCbomiuCNfPO7pKkOV9/p8Ubj5gbCAB+BGUEaKLujY3QL2/oKEl6euVuVmkF0GhRRoAm7NFrO+j+fpEyDOnxt1OUdOSU2ZEA4AKUEaAJs1gs+sNtXXV952AVl7k0/o0kHczKNzsWAFRCGQGauPOrtPZRr4gWyj1XqtELtiorr8jsWABQgTICNAPenjbNHx2r6CBfHT9zTmMWbmVRNACNBmUEaCZa+Tn0xth+CvLz1J4MFkUD0HhQRoBmJLKVjxaO6ceiaAAalRqVkdmzZys6OlpeXl6KiYnR2rVrf3R8cXGxpk+frqioKDkcDl122WVasGBBjQIDqJ3ubZ2azaJoABqRapeR5cuXa/LkyZo+fbpSUlI0ZMgQDR06VKmpqZfc595779WXX36p+fPna9++fVq2bJk6depUq+AAau5nVwTrWRZFA9BIWIxqHqPt37+/+vTpozlz5lRs69y5s26//XbNnDnzgvGffvqp7rvvPh06dEiBgYE1CpmXlyen06nc3FwFBATU6HcAuNBLXx7Q3xP3y2KR5oyI0U3dQs2OBKAJqernd7WOjJSUlCg5OVlxcXGVtsfFxWnDhg0X3WflypWKjY3VX//6V7Vp00YdO3bUr371K507d+6Sr1NcXKy8vLxKDwB179FrO+iB/v9ZFC356GmzIwFohqpVRrKzs1VeXq6QkJBK20NCQpSZefGlpg8dOqR169Zp165d+uCDDzRr1iy99957euSRRy75OjNnzpTT6ax4REREVCcmgCqyWCya8fP/LIo2cXGSjmQXmB0LQDNToxNYLRZLpZ8Nw7hg2w9cLpcsFouWLl2qfv366eabb9bzzz+vRYsWXfLoyLRp05Sbm1vxSEtLq0lMAFVgt1n14v291aOtU6cKSjR20VadKigxOxaAZqRaZSQoKEg2m+2CoyBZWVkXHC35QVhYmNq0aSOn01mxrXPnzjIMQ8eOHbvoPg6HQwEBAZUeAOqPj6dd80bHqk0Lbx3OLtDExUkqKi03OxaAZqJaZcTT01MxMTFKTEystD0xMVEDBw686D6DBg1Senq6zp49W7Ft//79slqtatu2bQ0iA6gPwf5eemNcXwV42ZV89LR++c4OuVysQQKg/lX7a5qpU6dq3rx5WrBggfbu3aspU6YoNTVVCQkJks5/xRIfH18x/oEHHlCrVq00duxY7dmzR2vWrNETTzyhcePGydvbu+7eCYBa6xDsr7nxsfKwWfTJzgw9++m3ZkcC0AxUu4wMHz5cs2bN0owZM9SrVy+tWbNGq1atUlRUlCQpIyOj0pojfn5+SkxM1JkzZxQbG6sRI0Zo2LBhevHFF+vuXQCoM1e2b6Xn7u4pSZq75pDeZA0SAPWs2uuMmIF1RoCG9/K/D+hvn++X1SLNHRWr67tc/LwwALiUellnBEDz8cg1HXRf3wi5DOmxZSn65tgZsyMBaKIoIwAuymKx6A+3d9NVHVvrXGm5xi1KUtqpQrNjAWiCKCMALsnDZtUrD/RW57AAZZ8t1thFW5VbWGp2LABNDGUEwI/y9/LQwjF9Feb00sGss3rwzSQVl7EGCYC6QxkB8JNCnV5aMKav/Bx2bT58Sk++943c4Nx3AG6CMgKgSjqHBWjOyD6yWy36cHu6/v75frMjAWgiKCMAqmzI5a315zu7S5Je/uqglm1J/Yk9AOCnUUYAVMu9sRGadG0HSdJvP9ylr/dlmZwIgLujjACotik3dNSdvduo3GXokaXbtDs91+xIANwYZQRAtVksFj17Vw8NaN9KBSXlGrdoq9LPnDM7FgA3RRkBUCOedqteHRWjy4P9dCKvWOMWbVVeEWuQAKg+ygiAGnN6e2jh2L5q7e/Qt5n5emTpNpWWu8yOBcDNUEYA1Erblj5aMLqvvD1sWnsgW7/9YBdrkACoFsoIgFrr3taplx/oLatFWp6Uple+Omh2JABuhDICoE5c1zlEz/y8qyTpb5/v14cpx01OBMBdUEYA1JlRA9pp4pBoSdKv3/tGmw7lmJwIgDugjACoU9OGdtbQbqEqKXfpoTeTdTDrrNmRADRylBEAdcpqtegfw3upd2QL5Z4r1dhFW5R9ttjsWAAaMcoIgDrn5WHTvPhYRQb6KO3UOU14I0nnSsrNjgWgkaKMAKgXrfwcWjS2r1r4eGh72hlNXp6icheX/AK4EGUEQL1p39pPc0fFytNm1We7T+jPq/aaHQlAI0QZAVCv+kUH6rl7ekiS5q87rEXrD5ucCEBjQxkBUO9u69VGT9x4hSRpxsd7lLjnhMmJADQmlBEADeLhn12m+/tFyGVIk5al6JtjZ8yOBKCRoIwAaBAWi0Uzbuumqzq21rnSco1blKS0U4VmxwLQCFBGADQYD5tVrzzQW51C/ZV9tlhjF21V7rlSs2MBMBllBECD8vfy0MKxfRUS4NDBrLNKeDNZJWUus2MBMBFlBECDC3N6a8GYvvL1tGnjoRw9teIbGQZrkADNFWUEgCm6hjv1yog+slktWrHtuF748oDZkQCYhDICwDQ/uyJYf7itmyRp1hcH9F7yMZMTATADZQSAqR7oH6lf/OwySdJT73+jDQezTU4EoKFRRgCY7om4K3RrjzCVuQw9tCRZ+0/kmx0JQAOijAAwndVq0d/u6anYqJbKLyrT2IVblZVfZHYsAA2EMgKgUfDysOn1+FhFB/nq+JlzGr8oSYUlZWbHAtAAKCMAGo2Wvp5aOKavAn09tfN4riYtS1G5i0t+gaaOMgKgUWkX5KvX42Plabfqi71ZmvHRbtYgAZo4ygiARicmqqVmDe8lSXpj41HNX3fY3EAA6hVlBECjdHP3MP3m5k6SpD+t2qtPd2WYnAhAfaGMAGi0Jg5pr5FXRsowpMff3q6U1NNmRwJQDygjABoti8Wi3w/rqms7Bau4zKUJbyQpNafQ7FgA6hhlBECjZrdZ9dL9vdU1PEA5BSUas2iLzhSWmB0LQB2ijABo9Hwddi0Y01fhTi8dOlmgB99MVnFZudmxANQRyggAtxAS4KUFY/vK32HXlsOn9MS738jFGiRAk0AZAeA2OoUGaM7IGNmtFq3cka7nE/ebHQlAHaCMAHArgy8P0p/v7C5Jevmrg1q+NdXkRABqizICwO3cGxuhSdd2kCT95oNdWrP/pMmJANQGZQSAW5pyQ0fd0buNyl2GHl66TXsz8syOBKCGKCMA3JLFYtGzd3VX/+hAnS0u07hFW5WZW2R2LAA1QBkB4LYcdpvmjorVZa19lZFbpHGLtupscZnZsQBUE2UEgFtz+nho0dh+CvLz1J6MPD361jaVlbvMjgWgGigjANxeRKCP5o3uKy8Pq77ed1JPr9wtw2ANEsBdUEYANAm9Ilrohft6y2KRlm5O1dw1h8yOBKCKKCMAmowbu4bq/27pIkma+a9v9fE36SYnAlAVlBEATcq4wdEaM7CdJGnqOzuUdOSUuYEA/CTKCIAm5/9u7aIbuoSopMyliYuTdDi7wOxIAH4EZQRAk2OzWvTCfb3Us61TpwtLNXbhFp0qKDE7FoBLqFEZmT17tqKjo+Xl5aWYmBitXbu2SvutX79edrtdvXr1qsnLAkCV+XjaNW90X7Vt6a0jOYWauDhJRaXlZscCcBHVLiPLly/X5MmTNX36dKWkpGjIkCEaOnSoUlN//GZVubm5io+P13XXXVfjsABQHa39HVo0tq8CvOxKPnpav3xnh1wuLvkFGptql5Hnn39e48eP14QJE9S5c2fNmjVLERERmjNnzo/u99BDD+mBBx7QgAEDahwWAKqrQ7C/Xh0VIw+bRZ/szNBfPvvW7EgA/ke1ykhJSYmSk5MVFxdXaXtcXJw2bNhwyf0WLlyo7777Tk8//XSVXqe4uFh5eXmVHgBQUwMvC9Jf7uohSXpt9SEt2XTU5EQA/lu1ykh2drbKy8sVEhJSaXtISIgyMzMvus+BAwf01FNPaenSpbLb7VV6nZkzZ8rpdFY8IiIiqhMTAC5wZ5+2mnJ9R0nS7/65S199m2VyIgA/qNEJrBaLpdLPhmFcsE2SysvL9cADD+iZZ55Rx44dq/z7p02bptzc3IpHWlpaTWICQCWTruugu2PaymVIj7y1TbuO55odCYCkqh2q+F5QUJBsNtsFR0GysrIuOFoiSfn5+UpKSlJKSooeffRRSZLL5ZJhGLLb7fr888917bXXXrCfw+GQw+GoTjQA+EkWi0V/vqO7MnLPaf3BHI1/Y6s+eHiQwlt4mx0NaNaqdWTE09NTMTExSkxMrLQ9MTFRAwcOvGB8QECAdu7cqe3bt1c8EhISdMUVV2j79u3q379/7dIDQDV52q2aPSJGHUP8dCKvWOMWbVVeUanZsYBmrVpHRiRp6tSpGjVqlGJjYzVgwADNnTtXqampSkhIkHT+K5bjx49r8eLFslqt6tatW6X9g4OD5eXldcF2AGgoTm8PLRjTV3fM3qBvM/P1yNJtWjCmrzxsrAMJmKHa/+YNHz5cs2bN0owZM9SrVy+tWbNGq1atUlRUlCQpIyPjJ9ccAQCztW3powWj+8rbw6a1B7L15HvfyDBYgwQwg8Vwg3/78vLy5HQ6lZubq4CAALPjAGhCvvo2SxMWJ6ncZSjh6sv01NBOZkcCmoyqfn5zTBJAs3ZNp2A9e2d3SdKrq7/TovWHTU4END+UEQDN3j2xEXrixiskSc98vEeffJNhciKgeaGMAICkh392mUZdGSXDkKYs366N3+WYHQloNigjAKDza5D8/udddVPXUJWUu/Tg4iTtzeBWFEBDoIwAwPdsVotm3ddL/doFKr+4TGMWbtHxM+fMjgU0eZQRAPgvXh42vR4fW7EoWvz8zTpdUGJ2LKBJo4wAwP9w+njojXH9FOb00ncnCzRhcZKKSsvNjgU0WZQRALiIMKe33hjXTwFediUfPa1H30pRWbnL7FhAk0QZAYBL6Bjir/lj+srTbtUXe0/o//65m1VagXpAGQGAH9G3XaBevK+3rBZp2ZZUvfjlQbMjAU0OZQQAfsJN3UL1zG3nb+75jy/26+0t3H8LqEuUEQCoglFXRumxaztIkn7zwU4l7jlhciKg6aCMAEAVTb2ho+6NbSuXIT361jZtOXzK7EhAk0AZAYAqslgs+vMd3XV952AVl7k0ftFW7UlnlVagtigjAFANdptVLz/Qp2KV1vgFW3Q0p8DsWIBbo4wAQDV5edj0+uhYdQ4LUPbZYo2cv1lZeUVmxwLcFmUEAGrA6e2hN8b1VVQrH6WdOqf4BVuUW1hqdizALVFGAKCGgv299Oa4/mrt79C3mfka/8ZWnSth2XiguigjAFALka18tPj7ZeOTjp7Ww0uTVcqy8UC1UEYAoJY6hwVowZi+8vKw6qt9J/XEuzvkcrFsPFBVlBEAqAOx7QI1Z0SM7FaLPtyerhkf7+E+NkAVUUYAoI5c0ylYf7unpyRp0YYjeunf3McGqArKCADUodt7t9HTw7pIkp5P3K83Nx01ORHQ+FFGAKCOjR0UrUnf38fmd//cpZU70k1OBDRulBEAqAdTbuiokVdGyjCkqcu36wturAdcEmUEAOqBxWLRMz/vptt6havMZejht7Zp/cFss2MBjRJlBADqic1q0d/u6akbuoSopMyliYuTlHz0tNmxgEaHMgIA9cjDZtVL9/fW4A5BKiwp15iFW7Q7PdfsWECjQhkBgHrm5WHT3PgYxUa1VH5RmeLnb9HBrLNmxwIaDcoIADQAH0+7Foztq25tApRTUKKR8zYr7VSh2bGARoEyAgANJMDLQ4vH9dflwX7KzCvSiHmbdSKvyOxYgOkoIwDQgAJ9PbVkQn9FtfJR6qlCjZi3WTlni82OBZiKMgIADSwkwEtLxvdXaICXDmadVfyCLco9V2p2LMA0lBEAMEFEoI+WTOivVr6e2p2ep3GLtqqwpMzsWIApKCMAYJIOwX56c3x/BXjZlXz0tCa8kaRzJeVmxwIaHGUEAEzUJTxAb4zrJz+HXRu+y9GDbyapqJRCguaFMgIAJusd2VILx/aVj6dNaw9kK2FJsorLKCRoPigjANAI9G0XqAVj+srLw6qv953UI0u3qaTMZXYsoEFQRgCgkbiyfSvNH91XDrtVX+zN0mPLtqm0nEKCpo8yAgCNyKAOQZobHytPm1Wf7T6hyW9vVxmFBE0cZQQAGpmrO7bWa6Ni5GGz6JOdGfrluztU7jLMjgXUG8oIADRC13QK1uwRMbJbLfrn9nQ98R6FBE0XZQQAGqkbuoTopft7y2a1aMW24/rNip1yUUjQBFFGAKARG9o9TLOG95LVIi1PStP0DykkaHooIwDQyA3rGa7n7z1fSJZtSdOT73/DVzZoUigjAOAGbu/dRv/4/gjJu8nHOIcETQplBADcxG292ujF/zqH5JfvcNkvmgbKCAC4kVt7hOvl+3vLbrXow+3pmvLODgoJ3B5lBADczNDuYXplRB952Cz6aEe6Hn97Oyu1wq1RRgDADd3YNVRzRsTI02bVJzsz9Ohb3MsG7osyAgBu6vouIXptVEzF0vEPL93G3X7hligjAODGrukUrLnxMfK0W/XF3hP6xZJtKiqlkMC9UEYAwM397IpgzR8dK4fdqn9/m6Xxb2xVQXGZ2bGAKqOMAEATMOTy1lo0tp98PW1afzBHo+ZvVu65UrNjAVVCGQGAJmLAZa20ZEJ/BXjZtS31jO6fu0k5Z4vNjgX8JMoIADQhvSNbavlDAxTk56k9GXm697WNyswtMjsW8KNqVEZmz56t6OhoeXl5KSYmRmvXrr3k2BUrVuiGG25Q69atFRAQoAEDBuizzz6rcWAAwI/rHBag5Q8NUJjTS9+dLNA9r21Q2qlCs2MBl1TtMrJ8+XJNnjxZ06dPV0pKioYMGaKhQ4cqNTX1ouPXrFmjG264QatWrVJycrKuueYaDRs2TCkpKbUODwC4uMta++mdhwYoqpWP0k6d092vbtDBrHyzYwEXZTEMo1p3Wurfv7/69OmjOXPmVGzr3Lmzbr/9ds2cObNKv6Nr164aPny4fve731VpfF5enpxOp3JzcxUQEFCduADQrGXlFWnk/M3af+KsAn09tXhcP3Vr4zQ7FpqJqn5+V+vISElJiZKTkxUXF1dpe1xcnDZs2FCl3+FyuZSfn6/AwMBLjikuLlZeXl6lBwCg+oIDvLT8wQHq0dapUwUluv/1Tdp65JTZsYBKqlVGsrOzVV5erpCQkErbQ0JClJmZWaXf8fe//10FBQW69957Lzlm5syZcjqdFY+IiIjqxAQA/JeWvp5aOqG/+rULVH5RmUbO26zEPSfMjgVUqNEJrBaLpdLPhmFcsO1ili1bpt///vdavny5goODLzlu2rRpys3NrXikpaXVJCYA4Hv+Xh5aPL6fru8crOIylxKWJOudJP7bisahWmUkKChINpvtgqMgWVlZFxwt+V/Lly/X+PHj9c477+j666//0bEOh0MBAQGVHgCA2vHysOnVkTG6J6atyl2Gfv3eN5r99UFV89RBoM5Vq4x4enoqJiZGiYmJlbYnJiZq4MCBl9xv2bJlGjNmjN566y3dcsstNUsKAKg1u82qv97dQwlXXyZJ+uun+/SHj/fK5aKQwDz26u4wdepUjRo1SrGxsRowYIDmzp2r1NRUJSQkSDr/Fcvx48e1ePFiSeeLSHx8vF544QVdeeWVFUdVvL295XRyRjcANDSLxaKnhnZSkJ+n/vjJXi1Yf1inCor117t7ytPOWphoeNUuI8OHD1dOTo5mzJihjIwMdevWTatWrVJUVJQkKSMjo9KaI6+99prKysr0yCOP6JFHHqnYPnr0aC1atKj27wAAUCMThrRXKz9PPfHuN/pwe7pOFZbq1ZF95ONZ7Y8GoFaqvc6IGVhnBADqz1f7svTwkm06V1qunhEtNH90rIL8HGbHQhNQL+uMAACanmuuCNZbE/urhY+HdqSd0R2z1+u7k2fNjoVmhDICAFDvyJZa8YuBigw8v3z8nbM3aMthFkdDw6CMAAAkSe1b++mDhweqd2QL5Z4r1ch5m7VyR7rZsdAMUEYAABVa+Tm0bOKVuqlrqErKXZq0LIW1SFDvKCMAgEq8PGx6ZUQfjR8cLen8WiS/+WCXyspdJidDU0UZAQBcwGa16P9u7aKnh3WRxSIt25Kq8W8k6WxxmdnR0ARRRgAAlzR2ULReHRkjLw+rVu8/qbvnbNCx04Vmx0ITQxkBAPyoG7uG6u0HByjIz6FvM/N128vrlXSEK21QdygjAICf1CuihVY+OkhdwgKUU1Ci+1/fpHe56y/qCGUEAFAl4S289d4vBuimrqEqLTf0xHvf6M+r9qqcm+yhligjAIAq8/G0a/aIPpp0bQdJ0tw1hzRxcZLyi0pNTgZ3RhkBAFSL1WrR1Lgr9NL9veWwW/Xvb7N05+wNSs3hxFbUDGUEAFAjw3qG652HBijY36EDWWc17OV1Wr3/pNmx4IYoIwCAGusZ0UIrHx2snm2dyj1XqjELt+iVr1ixFdVDGQEA1Eqo00vLHxqg+/pGyDCk5z7bp4QlyZxHgiqjjAAAas3Lw6Zn7+qhmXd2l6fNqs92n9Btr6zXwax8s6PBDVBGAAB15v5+kVr+0JUKDfDSoZMFuu3l9fp0V4bZsdDIUUYAAHWqd2RLfTxpsPpHB6qgpFwJS7bp2X99y432cEmUEQBAnQvyc2jphP6a8P2df19d/Z0eeH2zMnLPmZwMjRFlBABQL+w2q357axe9/EBv+Tns2nLklG5+Ya2+2pdldjQ0MpQRAEC9urVHuD5+bLC6hgfodGGpxi7cqpn/2qtSvrbB9ygjAIB61y7IV+//YqDiB0RJkl5bfUj3zd2k9DN8bQPKCACggXh52DTjtm6aPaKP/B12JR89rZtfXKsv9pwwOxpMRhkBADSom7uH6ZNJQ9SjrVNnCks1YXGSpn+wU+dKys2OBpNQRgAADS6ylY/eTRhQcbXN0s2puuWltfrm2Blzg8EUlBEAgCkcdpt+e2sXLZ3Qv2KRtDtnb9ArXx1UuYt72zQnlBEAgKkGdQjSp5OH6ObuoSpzGXrus326b+5GpZ0qNDsaGghlBABguhY+nnrlgT76+z095eewa+uR0xr6wlq9m5TGHYCbAcoIAKBRsFgsuiumrf71+BDFRLXU2eIyPfHeNxq7aCuXADdxlBEAQKMSEeij5Q9eqaeGdpKn3aqv953Ujf9Yo+VbUzlK0kRRRgAAjY7dZlXC1Zdp1aQh6h3ZQvnFZXry/Z2KX7BFxzlK0uRQRgAAjVaHYD+9lzBQ02/uLIfdqrUHshX3/Gq9uemoXFxx02RQRgAAjZrNatHEq9rrX48PUWxUSxWUlOv/Ptylu17doL0ZeWbHQx2gjAAA3EL71n5a/tAAPT2si/wcdqWkntGtL63Tn1ftVWFJmdnxUAuUEQCA27BZLRo7KFpfTL1aQ7uFqtxlaO6aQ7rh+TXc48aNUUYAAG4n1OmlOSNjtGBMrNq08NbxM+c0YXGSHlycxGJpbogyAgBwW9d2ClHi1Kv00NXtZbda9PmeE7ru+dX622f7VFDMVzfuwmK4wUXbeXl5cjqdys3NVUBAgNlxAACN0L7MfD3z0W5t+C5HkhQS4NCTN3XS7b3ayGq1mJyuearq5zdlBADQZBiGoc/3nNCfPtmr1O+/rukV0UJPD+ui3pEtTU7X/FBGAADNVlFpuRasP6xX/n1QBSXlkqRhPcP1yxs6ql2Qr8npmg/KCACg2cvKK9JfP9un95KPSZLsVovu6xehSdddrmB/L5PTNX2UEQAAvrc7PVfPfbZPX+87KUny9rBp/OBoPXh1ewV4eZicrumijAAA8D82HcrRs//6VtvTzkiSWvh4aOKQ9oofECV/Skmdo4wAAHARhmHos90n9Nxn3+q7kwWSJKe3h8YPjtboge3k9KaU1BXKCAAAP6Ks3KWPv8nQi/8+oEPflxJ/L7vGDorWuEHt1MLH0+SE7o8yAgBAFZS7DH2yM0MvfXlAB7LOSpJ8PW0a3jdSYwe1U0Sgj8kJ3RdlBACAanC5DH26O1MvfnlA32bmSzp/L5yh3UI1cUh79YxoYW5AN0QZAQCgBgzD0Or9JzVv7WGtO5hdsb1fu0CNHxKt6zoFy27jbipVQRkBAKCW9qTnad66Q/poR7pKy89/XIYGeOm+fhG6r2+kQp2sVfJjKCMAANSRE3lFWrThiJZvTdOpghJJ57/Cua5TsB7oH6mrLm/N/W8ugjICAEAdKy4r12e7T2jppqPafPhUxfY2Lbx1e+9w3dG7rToE+5mYsHGhjAAAUI8OZuVr6eZUvZ98THlFZRXbe7R16o7ebTSsZ7iC/BwmJjQfZQQAgAZQVFquL/ae0Afbjmv1/pMqc53/WLVZLeofHaih3UIV1zVUIQHN7/wSyggAAA0s52yxPtqRrg9SjmvHsdxKz/WJbKGbuoXq+s4hig7ylcXS9M8xoYwAAGCiozkF+mx3pj7dlaltqWcqPRcR6K2rO7bWVZe31sAOQfJz2M0JWc8oIwAANBKZuUVK3JOpT3dnasvhUxWXCUuS3WpRn6iW6h8dqL7tAtUnqmWTKSf1WkZmz56t5557ThkZGeratatmzZqlIUOGXHL86tWrNXXqVO3evVvh4eH69a9/rYSEhCq/HmUEANBUFBSXadOhHK3Zf1Kr95/UkZzCSs9bLVKX8AD1bReoXhEt1DU8QNFBfrK54aXDVf38rnb1Wr58uSZPnqzZs2dr0KBBeu211zR06FDt2bNHkZGRF4w/fPiwbr75Zk2cOFFLlizR+vXr9fDDD6t169a66667qvvyAAC4NV+HXdd1DtF1nUMknf86Z+N3Odpy5JS2HjmltFPntOt4nnYdz6vYx9vDpi7hAeoaHqDOYQFqH+Sr9q39FOTn2STOPan2kZH+/furT58+mjNnTsW2zp076/bbb9fMmTMvGP/kk09q5cqV2rt3b8W2hIQE7dixQxs3bqzSa3JkBADQXGTmFmnrkVNKOnJKu9LztCc9T+dKyy861t/Lrvat/dQ+yFfhLbwU6vRWWICXQp3nH4E+nqYuxlYvR0ZKSkqUnJysp556qtL2uLg4bdiw4aL7bNy4UXFxcZW23XjjjZo/f75KS0vl4eFxwT7FxcUqLi6u9GYAAGgOQp1eGtYzXMN6hks6f1fhw9kF2p2eq53HcrU/66wOnTyr42fOKb+oTDvSzmhH2pmL/i6LRfJ32BXg7SHn9w8/h12edqs8bVZ52KzysFvkYbPqzt5t1b2tswHf6X9Uq4xkZ2ervLxcISEhlbaHhIQoMzPzovtkZmZedHxZWZmys7MVFhZ2wT4zZ87UM888U51oAAA0STarRR2C/dQh2E+39WpTsb2otFxHcwp16ORZHc4pUGZukTJyi3Qi7/w/s88WyzCkvKIy5RWV6djpcz/6Or0jW7pHGfnB/34/ZRjGj35ndbHxF9v+g2nTpmnq1KkVP+fl5SkiIqImUQEAaJK8PGy6ItRfV4T6X/T50nKXzhSWKvdcqfKKvv/nuVLlF5WptNz1/cNQSdn5/325icvYV6uMBAUFyWazXXAUJCsr64KjHz8IDQ296Hi73a5WrVpddB+HwyGHo3kvoQsAQG142Kxq7e9Qa//G/3lqrc5gT09PxcTEKDExsdL2xMREDRw48KL7DBgw4ILxn3/+uWJjYy96vggAAGheqlVGJGnq1KmaN2+eFixYoL1792rKlClKTU2tWDdk2rRpio+PrxifkJCgo0ePaurUqdq7d68WLFig+fPn61e/+lXdvQsAAOC2qn3OyPDhw5WTk6MZM2YoIyND3bp106pVqxQVFSVJysjIUGpqasX46OhorVq1SlOmTNErr7yi8PBwvfjii6wxAgAAJLEcPAAAqCdV/fyu9tc0AAAAdYkyAgAATEUZAQAApqKMAAAAU1FGAACAqSgjAADAVJQRAABgKsoIAAAwFWUEAACYqtrLwZvhh0Vi8/LyTE4CAACq6ofP7Z9a7N0tykh+fr4kKSIiwuQkAACguvLz8+V0Oi/5vFvcm8blcik9PV3+/v6yWCx19nvz8vIUERGhtLQ07nlTz5jrhsE8NwzmuWEwzw2nvubaMAzl5+crPDxcVuulzwxxiyMjVqtVbdu2rbffHxAQwF/0BsJcNwzmuWEwzw2DeW449THXP3ZE5AecwAoAAExFGQEAAKZq1mXE4XDo6aeflsPhMDtKk8dcNwzmuWEwzw2DeW44Zs+1W5zACgAAmq5mfWQEAACYjzICAABMRRkBAACmoowAAABTNesyMnv2bEVHR8vLy0sxMTFau3at2ZHcxsyZM9W3b1/5+/srODhYt99+u/bt21dpjGEY+v3vf6/w8HB5e3vrZz/7mXbv3l1pTHFxsR577DEFBQXJ19dXP//5z3Xs2LGGfCtuZebMmbJYLJo8eXLFNua57hw/flwjR45Uq1at5OPjo169eik5Obnieea69srKyvTb3/5W0dHR8vb2Vvv27TVjxgy5XK6KMcxzzaxZs0bDhg1TeHi4LBaLPvzww0rP19W8nj59WqNGjZLT6ZTT6dSoUaN05syZ2oU3mqm3337b8PDwMF5//XVjz549xuOPP274+voaR48eNTuaW7jxxhuNhQsXGrt27TK2b99u3HLLLUZkZKRx9uzZijHPPvus4e/vb7z//vvGzp07jeHDhxthYWFGXl5exZiEhASjTZs2RmJiorFt2zbjmmuuMXr27GmUlZWZ8bYatS1bthjt2rUzevToYTz++OMV25nnunHq1CkjKirKGDNmjLF582bj8OHDxhdffGEcPHiwYgxzXXt//OMfjVatWhkff/yxcfjwYePdd981/Pz8jFmzZlWMYZ5rZtWqVcb06dON999/35BkfPDBB5Wer6t5vemmm4xu3boZGzZsMDZs2GB069bNuPXWW2uVvdmWkX79+hkJCQmVtnXq1Ml46qmnTErk3rKysgxJxurVqw3DMAyXy2WEhoYazz77bMWYoqIiw+l0Gq+++qphGIZx5swZw8PDw3j77bcrxhw/ftywWq3Gp59+2rBvoJHLz883Lr/8ciMxMdG4+uqrK8oI81x3nnzySWPw4MGXfJ65rhu33HKLMW7cuErb7rzzTmPkyJGGYTDPdeV/y0hdzeuePXsMScamTZsqxmzcuNGQZHz77bc1ztssv6YpKSlRcnKy4uLiKm2Pi4vThg0bTErl3nJzcyVJgYGBkqTDhw8rMzOz0hw7HA5dffXVFXOcnJys0tLSSmPCw8PVrVs3/hz+xyOPPKJbbrlF119/faXtzHPdWblypWJjY3XPPfcoODhYvXv31uuvv17xPHNdNwYPHqwvv/xS+/fvlyTt2LFD69at08033yyJea4vdTWvGzdulNPpVP/+/SvGXHnllXI6nbWae7e4UV5dy87OVnl5uUJCQiptDwkJUWZmpkmp3JdhGJo6daoGDx6sbt26SVLFPF5sjo8ePVoxxtPTUy1btrxgDH8O//H2229r27Zt2rp16wXPMc9159ChQ5ozZ46mTp2q3/zmN9qyZYsmTZokh8Oh+Ph45rqOPPnkk8rNzVWnTp1ks9lUXl6uP/3pT7r//vsl8Xe6vtTVvGZmZio4OPiC3x8cHFyruW+WZeQHFoul0s+GYVywDT/t0Ucf1TfffKN169Zd8FxN5pg/h/9IS0vT448/rs8//1xeXl6XHMc8157L5VJsbKz+/Oc/S5J69+6t3bt3a86cOYqPj68Yx1zXzvLly7VkyRK99dZb6tq1q7Zv367JkycrPDxco0ePrhjHPNePupjXi42v7dw3y69pgoKCZLPZLmhxWVlZF7RG/LjHHntMK1eu1FdffaW2bdtWbA8NDZWkH53j0NBQlZSU6PTp05cc09wlJycrKytLMTExstvtstvtWr16tV588UXZ7faKeWKeay8sLExdunSptK1z585KTU2VxN/puvLEE0/oqaee0n333afu3btr1KhRmjJlimbOnCmJea4vdTWvoaGhOnHixAW//+TJk7Wa+2ZZRjw9PRUTE6PExMRK2xMTEzVw4ECTUrkXwzD06KOPasWKFfr3v/+t6OjoSs9HR0crNDS00hyXlJRo9erVFXMcExMjDw+PSmMyMjK0a9cu/hy+d91112nnzp3avn17xSM2NlYjRozQ9u3b1b59e+a5jgwaNOiCy9P379+vqKgoSfydriuFhYWyWit/9NhstopLe5nn+lFX8zpgwADl5uZqy5YtFWM2b96s3Nzc2s19jU99dXM/XNo7f/58Y8+ePcbkyZMNX19f48iRI2ZHcwu/+MUvDKfTaXz99ddGRkZGxaOwsLBizLPPPms4nU5jxYoVxs6dO43777//opeRtW3b1vjiiy+Mbdu2Gddee22zvzzvp/z31TSGwTzXlS1bthh2u93405/+ZBw4cMBYunSp4ePjYyxZsqRiDHNde6NHjzbatGlTcWnvihUrjKCgIOPXv/51xRjmuWby8/ONlJQUIyUlxZBkPP/880ZKSkrFkhV1Na833XST0aNHD2Pjxo3Gxo0bje7du3Npb2288sorRlRUlOHp6Wn06dOn4rJU/DRJF30sXLiwYozL5TKefvppIzQ01HA4HMZVV11l7Ny5s9LvOXfunPHoo48agYGBhre3t3HrrbcaqampDfxu3Mv/lhHmue589NFHRrdu3QyHw2F06tTJmDt3bqXnmevay8vLMx5//HEjMjLS8PLyMtq3b29Mnz7dKC4urhjDPNfMV199ddH/Lo8ePdowjLqb15ycHGPEiBGGv7+/4e/vb4wYMcI4ffp0rbJbDMMwan5cBQAAoHaa5TkjAACg8aCMAAAAU1FGAACAqSgjAADAVJQRAABgKsoIAAAwFWUEAACYijICAABMRRkBAACmoowAAABTUUYAAICpKCMAAMBU/w/GCBTYaXSEewAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_alpha_bar_schedule(T, t, s=0.008):\n",
    "    \"\"\"\n",
    "    Generate a cosine schedule for diffusion betas.\n",
    "    \n",
    "    Args:\n",
    "    - T (int): The total number of diffusion timesteps.\n",
    "    - s (float): A small constant to ensure the betas do not reach 0, which could cause numerical stability issues.\n",
    "    \n",
    "    Returns:\n",
    "    - np.array: An array of length T with the beta values for each timestep.\n",
    "    \"\"\"\n",
    "    def f_t(t):\n",
    "        return np.square(np.cos(((t/T + s) * np.pi / 2) / (1 + s)))\n",
    "    f_0 = f_t(0)\n",
    "    return f_t(t) / f_0\n",
    "\n",
    "alpha_bar = [cosine_alpha_bar_schedule(1000, t) for t in range(1000)]\n",
    "plt.plot(alpha_bar)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2024 The Google Research Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"Diffusion for discrete state spaces.\"\"\"\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def make_diffusion(diffusion_config, model_config, num_edges, future_len, device):\n",
    "    \"\"\"HParams -> diffusion object.\"\"\"\n",
    "    return CategoricalDiffusion(\n",
    "        betas=get_diffusion_betas(diffusion_config, device),\n",
    "        model_prediction=model_config['model_prediction'],\n",
    "        model_output=model_config['model_output'],\n",
    "        transition_mat_type=model_config['transition_mat_type'],\n",
    "        transition_bands=model_config['transition_bands'],\n",
    "        loss_type=model_config['loss_type'],\n",
    "        hybrid_coeff=model_config['hybrid_coeff'],\n",
    "        num_edges=num_edges,\n",
    "        model_name=model_config['name'],\n",
    "        future_len=future_len,\n",
    "        device=device\n",
    ")\n",
    "\n",
    "\n",
    "def get_diffusion_betas(spec, device):\n",
    "    \"\"\"Get betas from the hyperparameters.\"\"\"\n",
    "    \n",
    "    if spec['type'] == 'linear':\n",
    "        # Used by Ho et al. for DDPM, https://arxiv.org/abs/2006.11239.\n",
    "        # To be used with Gaussian diffusion models in continuous and discrete\n",
    "        # state spaces.\n",
    "        # To be used with transition_mat_type = 'gaussian'\n",
    "        return torch.linspace(spec['start'], spec['stop'], spec['num_timesteps']).to(device)\n",
    "    elif spec['type'] == 'cosine':\n",
    "        # Schedule proposed by Hoogeboom et al. https://arxiv.org/abs/2102.05379\n",
    "        # To be used with transition_mat_type = 'uniform'.\n",
    "        steps = torch.linspace(0, 1, spec['num_timesteps'] + 1, dtype=torch.float64)\n",
    "        alpha_bar = torch.square(torch.cos(((steps + 0.008) / 1.008) * torch.pi / 2))\n",
    "        betas = torch.minimum(1 - alpha_bar[1:] / alpha_bar[:-1], torch.tensor(0.999))\n",
    "        return betas.to(device)\n",
    "    elif spec['type'] == 'jsd':  # 1/T, 1/(T-1), 1/(T-2), ..., 1\n",
    "        # Proposed by Sohl-Dickstein et al., https://arxiv.org/abs/1503.03585\n",
    "        # To be used with absorbing state models.\n",
    "        # ensures that the probability of decaying to the absorbing state\n",
    "        # increases linearly over time, and is 1 for t = T-1 (the final time).\n",
    "        # To be used with transition_mat_type = 'absorbing'\n",
    "        return 1. / torch.linspace(spec['num_timesteps'], 1, spec['num_timesteps']).to(device)\n",
    "    else:\n",
    "        raise NotImplementedError(spec['type'])\n",
    "\n",
    "\n",
    "class CategoricalDiffusion:\n",
    "    \"\"\"Discrete state space diffusion process.\n",
    "\n",
    "    Time convention: noisy data is labeled x_0, ..., x_{T-1}, and original data\n",
    "    is labeled x_start (or x_{-1}). This convention differs from the papers,\n",
    "    which use x_1, ..., x_T for noisy data and x_0 for original data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *, betas, model_prediction, model_output,\n",
    "               transition_mat_type, transition_bands, loss_type, hybrid_coeff,\n",
    "               num_edges, torch_dtype=torch.float32, model_name=None, future_len=None, device=None):\n",
    "\n",
    "        self.model_prediction = model_prediction  # *x_start*, xprev\n",
    "        self.model_output = model_output  # logits or *logistic_pars*\n",
    "        self.loss_type = loss_type  # kl, *hybrid*, cross_entropy_x_start\n",
    "        self.hybrid_coeff = hybrid_coeff\n",
    "        self.torch_dtype = torch_dtype\n",
    "        self.model_name = model_name\n",
    "        self.device = device\n",
    "\n",
    "        # Data \\in {0, ..., num_edges-1}\n",
    "        self.num_classes = 2 # 0 or 1\n",
    "        self.num_edges = num_edges\n",
    "        self.future_len = future_len\n",
    "        # self.class_weights = torch.tensor([self.future_len / self.num_edges, 1 - self.future_len / self.num_edges], dtype=torch.float64)\n",
    "        self.class_weights = torch.tensor([0.4, 0.6], dtype=torch.float64)\n",
    "        self.class_probs = torch.tensor([1 - self.future_len / self.num_edges, self.future_len / self.num_edges], dtype=torch.float64)\n",
    "        self.transition_bands = transition_bands\n",
    "        self.transition_mat_type = transition_mat_type\n",
    "        self.eps = 1.e-6\n",
    "\n",
    "        if not isinstance(betas, torch.Tensor):\n",
    "            raise ValueError('expected betas to be a torch tensor')\n",
    "        if not ((betas > 0).all() and (betas <= 1).all()):\n",
    "            raise ValueError('betas must be in (0, 1]')\n",
    "\n",
    "        # Computations here in float64 for accuracy\n",
    "        self.betas = betas.to(dtype=torch.float64).to(self.device, non_blocking=True)\n",
    "        self.num_timesteps, = betas.shape\n",
    "\n",
    "        # Construct transition matrices for q(x_t|x_{t-1})\n",
    "        # NOTE: t goes from {0, ..., T-1}\n",
    "        if self.transition_mat_type == 'uniform':\n",
    "            q_one_step_mats = [self._get_transition_mat(t) \n",
    "                            for t in range(0, self.num_timesteps)]\n",
    "        elif self.transition_mat_type == 'gaussian':\n",
    "            q_one_step_mats = [self._get_gaussian_transition_mat(t)\n",
    "                            for t in range(0, self.num_timesteps)]\n",
    "        elif self.transition_mat_type == 'absorbing':\n",
    "            q_one_step_mats = [self._get_absorbing_transition_mat(t)\n",
    "                            for t in range(0, self.num_timesteps)]\n",
    "        elif self.transition_mat_type == 'marginal_prior':\n",
    "            q_one_step_mats = [self._get_prior_distribution_transition_mat(t)\n",
    "                               for t in range(0, self.num_timesteps)]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"transition_mat_type must be 'gaussian', 'uniform', 'absorbing', 'marginal_prior'\"\n",
    "                f\", but is {self.transition_mat_type}\"\n",
    "                )\n",
    "\n",
    "        self.q_onestep_mats = torch.stack(q_one_step_mats, axis=0).to(self.device, non_blocking=True)\n",
    "        assert self.q_onestep_mats.shape == (self.num_timesteps,\n",
    "                                            self.num_classes,\n",
    "                                            self.num_classes)\n",
    "\n",
    "        # Construct transition matrices for q(x_t|x_start)\n",
    "        q_mat_t = self.q_onestep_mats[0]\n",
    "        q_mats = [q_mat_t]\n",
    "        for t in range(1, self.num_timesteps):\n",
    "            # Q_{1...t} = Q_{1 ... t-1} Q_t = Q_1 Q_2 ... Q_t\n",
    "            q_mat_t = torch.tensordot(q_mat_t, self.q_onestep_mats[t],\n",
    "                                    dims=[[1], [0]])\n",
    "            q_mats.append(q_mat_t)\n",
    "        self.q_mats = torch.stack(q_mats, axis=0)\n",
    "        assert self.q_mats.shape == (self.num_timesteps, self.num_classes,\n",
    "                                    self.num_classes), self.q_mats.shape\n",
    "        \n",
    "        for t in range(0, self.num_timesteps, 9):\n",
    "            print(self.q_mats[t])\n",
    "\n",
    "        # Don't precompute transition matrices for q(x_{t-1} | x_t, x_start)\n",
    "        # Can be computed from self.q_mats and self.q_one_step_mats.\n",
    "        # Only need transpose of q_onestep_mats for posterior computation.\n",
    "        self.transpose_q_onestep_mats = torch.transpose(self.q_onestep_mats, dim0=1, dim1=2)\n",
    "        del self.q_onestep_mats\n",
    "\n",
    "    def _get_full_transition_mat(self, t):\n",
    "        \"\"\"Computes transition matrix for q(x_t|x_{t-1}).\n",
    "\n",
    "        Contrary to the band diagonal version, this method constructs a transition\n",
    "        matrix with uniform probability to all other states.\n",
    "\n",
    "        Args:\n",
    "            t: timestep. integer scalar.\n",
    "\n",
    "        Returns:\n",
    "            Q_t: transition matrix. shape = (num_classes, num_classes).\n",
    "        \"\"\"\n",
    "        beta_t = self.betas[t]\n",
    "        # Create a matrix filled with beta_t/num_classes\n",
    "        mat = torch.full((self.num_classes, self.num_classes), \n",
    "                            fill_value=beta_t / float(self.num_classes),\n",
    "                            dtype=torch.float64)\n",
    "\n",
    "        # Create a diagonal matrix with values to be set on the diagonal of mat\n",
    "        diag_val = 1. - beta_t * (self.num_classes - 1.) / self.num_classes\n",
    "        diag_matrix = torch.diag(torch.full((self.num_classes,), diag_val, dtype=torch.float64))\n",
    "\n",
    "        # Set the diagonal values\n",
    "        mat.fill_diagonal_(diag_val)\n",
    "\n",
    "        return mat\n",
    "\n",
    "    def _get_transition_mat(self, t):\n",
    "        r\"\"\"Computes transition matrix for q(x_t|x_{t-1}).\n",
    "\n",
    "        This method constructs a transition\n",
    "        matrix Q with\n",
    "        Q_{ij} = beta_t / num_classes       if |i-j| <= self.transition_bands\n",
    "                1 - \\sum_{l \\neq i} Q_{il} if i==j.\n",
    "                0                          else.\n",
    "\n",
    "        Args:\n",
    "        t: timestep. integer scalar (or numpy array?)\n",
    "\n",
    "        Returns:\n",
    "        Q_t: transition matrix. shape = (num_classes, num_classes).\n",
    "        \"\"\"\n",
    "        if self.transition_bands is None:\n",
    "            return self._get_full_transition_mat(t)\n",
    "        # Assumes num_off_diags < num_classes\n",
    "        beta_t = self.betas[t]\n",
    "        \n",
    "        mat = torch.zeros((self.num_classes, self.num_classes),\n",
    "                        dtype=torch.float64)\n",
    "        off_diag = torch.full((self.num_classes - 1,), fill_value=beta_t / float(self.num_classes), dtype=torch.float64)\n",
    "\n",
    "        for k in range(1, self.transition_bands + 1):\n",
    "            mat += torch.diag(off_diag, k)\n",
    "            mat += torch.diag(off_diag, -k)\n",
    "            off_diag = off_diag[:-1]\n",
    "\n",
    "        # Add diagonal values such that rows sum to one\n",
    "        diag = 1. - mat.sum(dim=1)\n",
    "        mat += torch.diag(diag)\n",
    "        \n",
    "        return mat\n",
    "\n",
    "    def _get_gaussian_transition_mat(self, t):\n",
    "        r\"\"\"Computes transition matrix for q(x_t|x_{t-1}).\n",
    "\n",
    "        This method constructs a transition matrix Q with\n",
    "        decaying entries as a function of how far off diagonal the entry is.\n",
    "        Normalization option 1:\n",
    "        Q_{ij} =  ~ softmax(-val^2/beta_t)   if |i-j| <= self.transition_bands\n",
    "                    1 - \\sum_{l \\neq i} Q_{il}  if i==j.\n",
    "                    0                          else.\n",
    "\n",
    "        Normalization option 2:\n",
    "        tilde{Q}_{ij} =  softmax(-val^2/beta_t)   if |i-j| <= self.transition_bands\n",
    "                            0                        else.\n",
    "\n",
    "        Q_{ij} =  tilde{Q}_{ij} / sum_l{tilde{Q}_{lj}}\n",
    "\n",
    "        Args:\n",
    "            t: timestep. integer scalar (or numpy array?)\n",
    "\n",
    "        Returns:\n",
    "            Q_t: transition matrix. shape = (num_classes, num_classes).\n",
    "        \"\"\"\n",
    "        transition_bands = self.transition_bands if self.transition_bands else self.num_classes - 1\n",
    "\n",
    "        beta_t = self.betas[t]\n",
    "\n",
    "        mat = torch.zeros((self.num_classes, self.num_classes),\n",
    "                        dtype=torch.float64).to(self.device, non_blocking=True)\n",
    "\n",
    "        # Make the values correspond to a similar type of gaussian as in the\n",
    "        # gaussian diffusion case for continuous state spaces.\n",
    "        values = torch.linspace(torch.tensor(0.), torch.tensor(self.num_classes-1), self.num_classes, dtype=torch.float64).to(self.device, non_blocking=True)\n",
    "        values = values * 2./ (self.num_classes - 1.)\n",
    "        values = values[:transition_bands+1]\n",
    "        values = -values * values / beta_t\n",
    "        \n",
    "        # To reverse the tensor 'values' starting from the second element\n",
    "        reversed_values = values[1:].flip(dims=[0])\n",
    "        # Concatenating the reversed values with the original values\n",
    "        values = torch.cat([reversed_values, values], dim=0)\n",
    "        values = F.softmax(values, dim=0)\n",
    "        values = values[transition_bands:]\n",
    "        \n",
    "        for k in range(1, transition_bands + 1):\n",
    "            off_diag = torch.full((self.num_classes - k,), values[k], dtype=torch.float64).to(self.device, non_blocking=True)\n",
    "\n",
    "            mat += torch.diag(off_diag, k)\n",
    "            mat += torch.diag(off_diag, -k)\n",
    "\n",
    "        # Add diagonal values such that rows and columns sum to one.\n",
    "        # Technically only the ROWS need to sum to one\n",
    "        # NOTE: this normalization leads to a doubly stochastic matrix,\n",
    "        # which is necessary if we want to have a uniform stationary distribution.\n",
    "        diag = 1. - mat.sum(dim=1)\n",
    "        mat += torch.diag_embed(diag)\n",
    "\n",
    "        return mat.to(self.device, non_blocking=True)\n",
    "\n",
    "    def _get_absorbing_transition_mat(self, t):\n",
    "        \"\"\"Computes transition matrix for q(x_t|x_{t-1}).\n",
    "\n",
    "        Has an absorbing state for pixelvalues self.num_classes//2.\n",
    "\n",
    "        Args:\n",
    "        t: timestep. integer scalar.\n",
    "\n",
    "        Returns:\n",
    "        Q_t: transition matrix. shape = (num_classes, num_classes).\n",
    "        \"\"\"\n",
    "        beta_t = self.betas[t]\n",
    "\n",
    "        diag = torch.full((self.num_classes,), 1. - beta_t, dtype=torch.float64).to(self.device, non_blocking=True)\n",
    "        mat = torch.diag(diag)\n",
    "\n",
    "        # Add beta_t to the num_classes/2-th column for the absorbing state\n",
    "        mat[:, self.num_classes // 2] += beta_t\n",
    "\n",
    "        return mat\n",
    "    \n",
    "    def _get_prior_distribution_transition_mat(self, t):\n",
    "        \"\"\"Computes transition matrix for q(x_t|x_{t-1}).\n",
    "        Use cosine schedule for these transition matrices.\n",
    "\n",
    "        Args:\n",
    "        t: timestep. integer scalar.\n",
    "\n",
    "        Returns:\n",
    "        Q_t: transition matrix. shape = (num_classes, num_classes).\n",
    "        \"\"\"\n",
    "        beta_t = self.betas[t]\n",
    "        mat = torch.zeros((self.num_classes, self.num_classes), dtype=torch.float64).to(self.device, non_blocking=True)\n",
    "\n",
    "        '''for i in range(self.num_classes):\n",
    "            for j in range(self.num_classes):\n",
    "                if i != j:\n",
    "                    mat[i, j] = beta_t * self.class_probs[j]\n",
    "                else:\n",
    "                    mat[i, j] = 1 - beta_t + beta_t * self.class_probs[j]'''\n",
    "\n",
    "        mat = beta_t * self.class_probs + (1 - beta_t) * torch.eye(2, device=self.device)\n",
    "        \n",
    "        return mat\n",
    "    \n",
    "    def _get_custom_transition_mat(self, t):\n",
    "        # TODO: return a matrix [[1 - a_t a_t], [a_t, 1 - a_t]], with a_t = t/T\n",
    "        pass\n",
    "\n",
    "    def _at(self, a, t, x):\n",
    "        \"\"\"\n",
    "        Extract coefficients at specified timesteps t and conditioning data x in PyTorch.\n",
    "\n",
    "        Args:\n",
    "        a: torch.Tensor: PyTorch tensor of constants indexed by time, dtype should be pre-set.\n",
    "        t: torch.Tensor: PyTorch tensor of time indices, shape = (batch_size,).\n",
    "        x: torch.Tensor: PyTorch tensor of shape (bs, ...) of int32 or int64 type.\n",
    "            (Noisy) data. Should not be of one-hot representation, but have integer\n",
    "            values representing the class values. --> NOT A LOT NEEDS TO CHANGE, MY CLASS VALUES ARE SIMPLY 0 AND 1\n",
    "\n",
    "        Returns:\n",
    "        a[t, x]: torch.Tensor: PyTorch tensor.\n",
    "        \"\"\"\n",
    "        ### Original ###\n",
    "        # x.shape = (bs, height, width, channels)\n",
    "        # t_broadcast_shape = (bs, 1, 1, 1)\n",
    "        # a.shape = (num_timesteps, num_pixel_vals, num_pixel_vals)\n",
    "        # out.shape = (bs, height, width, channels, num_pixel_vals)\n",
    "        # out[i, j, k, l, m] = a[t[i, j, k, l], x[i, j, k, l], m]\n",
    "        \n",
    "        ### New ###\n",
    "        # x.shape = (bs, num_edges, channels=1) \n",
    "        # t_broadcast_shape = (bs, 1, 1)\n",
    "        # a.shape = (num_timesteps, num_classes, num_classes) \n",
    "        # out.shape = (bs, num_edges, channels, num_classes) \n",
    "        \n",
    "        # Convert `a` to the desired dtype if not already\n",
    "        a = a.type(self.torch_dtype)\n",
    "\n",
    "        # Prepare t for broadcasting by adding necessary singleton dimensions\n",
    "        t_broadcast = t.view(-1, *((1,) * (x.ndim - 1))).to(self.device, non_blocking=True)\n",
    "\n",
    "        # Advanced indexing in PyTorch to select elements\n",
    "        return a[t_broadcast, x.long()].to(self.device, non_blocking=True)\n",
    "\n",
    "    def _at_onehot(self, a, t, x):\n",
    "        \"\"\"Extract coefficients at specified timesteps t and conditioning data x.\n",
    "\n",
    "        Args:\n",
    "        a: torch.Tensor: PyTorch tensor of constants indexed by time, dtype should be pre-set.\n",
    "        t: torch.Tensor: PyTorch tensor of time indices, shape = (batch_size,).\n",
    "        x: torch.Tensor: PyTorch tensor of shape (bs, ...) of float32 type.\n",
    "            (Noisy) data. Should be of one-hot-type representation.\n",
    "\n",
    "        Returns:\n",
    "        out: torch.tensor: output of dot(x, a[t], axis=[[-1], [1]]).\n",
    "            shape = (bs, num_edges, channels=1, num_classes)\n",
    "        \"\"\"\n",
    "        a = a.type(self.torch_dtype)\n",
    "        \n",
    "        ### Final ###\n",
    "        # t.shape = (bs)\n",
    "        # x.shape = (bs, num_edges, num_classes)\n",
    "        # a[t].shape = (bs, num_classes, num_classes)\n",
    "        # out.shape = (bs, num_edges, num_classes)\n",
    "\n",
    "        a_t = a[t]\n",
    "        out = torch.einsum('bik,bkj->bij', x, a_t).to(self.device, non_blocking=True)\n",
    "        \n",
    "        return out.to(self.device, non_blocking=True)\n",
    "\n",
    "    def q_probs(self, x_start, t):\n",
    "        \"\"\"Compute probabilities of q(x_t | x_start).\n",
    "\n",
    "        Args:\n",
    "        x_start: torch.tensor: tensor of shape (bs, ...) of int32 or int64 type.\n",
    "            Should not be of one hot representation, but have integer values\n",
    "            representing the class values.\n",
    "        t: torch.tensor: torch tensor of shape (bs,).\n",
    "\n",
    "        Returns:\n",
    "        probs: torch.tensor: shape (bs, x_start.shape[1:],\n",
    "                                                num_classes).\n",
    "        \"\"\"\n",
    "        return self._at(self.q_mats, t, x_start)\n",
    "\n",
    "    def q_sample(self, x_start, t, noise):\n",
    "        \"\"\"\n",
    "        Sample from q(x_t | x_start) (i.e. add noise to the data) using Gumbel softmax trick.\n",
    "\n",
    "        Args:\n",
    "        x_start: torch.tensor: original clean data, in integer form (not onehot).\n",
    "            shape = (bs, num_edges).\n",
    "        t: torch.tensor: timestep of the diffusion process, shape (bs,).\n",
    "        noise: torch.tensor: uniform noise on [0, 1) used to sample noisy data.\n",
    "            shape should match (*x_start.shape, num_classes).\n",
    "\n",
    "        Returns:\n",
    "        sample: torch.tensor: same shape as x_start. noisy data.\n",
    "        \"\"\"\n",
    "        assert noise.shape == x_start.shape + (self.num_classes,)\n",
    "        logits = torch.log(self.q_probs(x_start, t) + self.eps)\n",
    "\n",
    "        # To avoid numerical issues, clip the noise to a minimum value\n",
    "        noise = torch.clamp(noise, min=torch.finfo(noise.dtype).tiny, max=1.)\n",
    "        gumbel_noise = -torch.log(-torch.log(noise)).to(self.device, non_blocking=True)\n",
    "        return torch.argmax(logits + gumbel_noise, dim=-1)\n",
    "    \n",
    "    def _get_logits_from_logistic_pars(self, loc, log_scale):\n",
    "        \"\"\"\n",
    "        Computes logits for an underlying logistic distribution.\n",
    "\n",
    "        Args:\n",
    "        loc: torch.tensor: location parameter of logistic distribution.\n",
    "        log_scale: torch.tensor: log scale parameter of logistic distribution.\n",
    "\n",
    "        Returns:\n",
    "        logits: torch.tensor: logits corresponding to logistic distribution\n",
    "        \"\"\"\n",
    "        loc = loc.unsqueeze(-1)\n",
    "        log_scale = log_scale.unsqueeze(-1)\n",
    "\n",
    "        # Adjust the scale such that if it's zero, the probabilities have a scale\n",
    "        # that is neither too wide nor too narrow.\n",
    "        inv_scale = torch.exp(- (log_scale - 2.))\n",
    "\n",
    "        bin_width = 2. / (self.num_classes - 1.)\n",
    "        bin_centers = torch.linspace(-1., 1., self.num_classes)\n",
    "\n",
    "        bin_centers = bin_centers.unsqueeze(0)  # Add batch dimension\n",
    "        bin_centers = bin_centers - loc\n",
    "\n",
    "        log_cdf_min = -F.softplus(-inv_scale * (bin_centers - 0.5 * bin_width))\n",
    "        log_cdf_plus = -F.softplus(-inv_scale * (bin_centers + 0.5 * bin_width))\n",
    "\n",
    "        logits = torch.log(torch.exp(log_cdf_plus) - torch.exp(log_cdf_min) + self.eps)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def q_posterior_logits(self, x_start, x_t, t, x_start_logits):\n",
    "        \"\"\"Compute logits of q(x_{t-1} | x_t, x_start) in PyTorch.\"\"\"\n",
    "        \n",
    "        if x_start_logits:\n",
    "            assert x_start.shape == x_t.shape + (self.num_classes,), (x_start.shape, x_t.shape)\n",
    "        else:\n",
    "            assert x_start.shape == x_t.shape, (x_start.shape, x_t.shape)\n",
    "            \n",
    "        fact1 = self._at(self.transpose_q_onestep_mats, t, x_t)\n",
    "        if x_start_logits:\n",
    "            fact2 = self._at_onehot(self.q_mats, t-1, F.softmax(x_start, dim=-1))\n",
    "            tzero_logits = x_start\n",
    "        else:\n",
    "            fact2 = self._at(self.q_mats, t-1, x_start)\n",
    "            tzero_logits = torch.log(F.one_hot(x_start.to(torch.int64), num_classes=self.num_classes) + self.eps)\n",
    "\n",
    "        out = torch.log(fact1 + self.eps) + torch.log(fact2 + self.eps)\n",
    "\n",
    "        t_broadcast = t.unsqueeze(1).unsqueeze(2)  # Adds new dimensions: [batch_size, 1, 1]\n",
    "        t_broadcast = t_broadcast.expand(-1, tzero_logits.size(1), tzero_logits.size(-1)).to(self.device, non_blocking=True)   # tzero_logits.size(1) = num_edges, tzero_logits.size(-1) = num_classes\n",
    "\n",
    "        return torch.where(t_broadcast == 0, tzero_logits, out) # (bs, num_edges, num_classes)\n",
    "\n",
    "    def p_logits(self, model_fn, x, t, edge_features=None, edge_index=None, condition=None):\n",
    "        \"\"\"Compute logits of p(x_{t-1} | x_t) in PyTorch.\n",
    "\n",
    "        Args:\n",
    "            model_fn (function): The model function that takes input `x` and `t` and returns the model output.\n",
    "            x (torch.Tensor): The input tensor of shape (batch_size, input_size) representing the noised input at time t.\n",
    "            t (torch.Tensor): The time tensor of shape (batch_size,) representing the time step.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing two tensors:\n",
    "                - model_logits (torch.Tensor): The logits of p(x_{t-1} | x_t) of shape (batch_size, input_size, num_classes).\n",
    "                - pred_x_start_logits (torch.Tensor): The logits of p(x_{t-1} | x_start) of shape (batch_size, input_size, num_classes).\n",
    "        \"\"\"\n",
    "        assert t.shape == (x.shape[0],)\n",
    "        model_output = model_fn(edge_features, edge_index, t, condition=condition)\n",
    "\n",
    "        if self.model_output == 'logits':\n",
    "            model_logits = model_output\n",
    "        elif self.model_output == 'logistic_pars':\n",
    "            loc, log_scale = model_output\n",
    "            model_logits = self._get_logits_from_logistic_pars(loc, log_scale)\n",
    "        else:\n",
    "            raise NotImplementedError(self.model_output)\n",
    "\n",
    "        if self.model_prediction == 'x_start':\n",
    "            pred_x_start_logits = model_logits\n",
    "            t_broadcast = t.unsqueeze(1).unsqueeze(2)  # Adds new dimensions: [batch_size, 1, 1]\n",
    "            t_broadcast = t_broadcast.expand(-1, pred_x_start_logits.size(1), pred_x_start_logits.size(-1)).to(self.device, non_blocking=True)   # pred_x_start_logits.size(1) = num_edges, pred_x_start_logits.size(-1) = num_classes\n",
    "            model_logits = torch.where(t_broadcast == 0, pred_x_start_logits,\n",
    "                                       self.q_posterior_logits(x_start=pred_x_start_logits, x_t=x, t=t, x_start_logits=True))\n",
    "            \n",
    "        elif self.model_prediction == 'xprev':\n",
    "            pred_x_start_logits = model_logits\n",
    "            raise NotImplementedError(self.model_prediction)\n",
    "        \n",
    "        assert (model_logits.shape == pred_x_start_logits.shape == x.shape + (self.num_classes,))\n",
    "        return model_logits, pred_x_start_logits    # (bs, num_eedges, 2)\n",
    "    \n",
    "    # === Sampling ===\n",
    "\n",
    "    def p_sample(self, model_fn, x, t, noise, edge_features=None, edge_index=None, condition=None):\n",
    "        \"\"\"Sample one timestep from the model p(x_{t-1} | x_t).\"\"\"\n",
    "        # Get model logits\n",
    "        model_logits, pred_x_start_logits = self.p_logits(model_fn=model_fn, x=x, t=t, edge_features=edge_features, edge_index=edge_index, condition=condition)\n",
    "        assert noise.shape == model_logits.shape, noise.shape\n",
    "\n",
    "        # No noise when t == 0\n",
    "        nonzero_mask = (t != 0).float().reshape(x.shape[0], *([1] * (len(x.shape) - 1)))\n",
    "        # For numerical precision clip the noise to a minimum value\n",
    "        noise = torch.clamp(noise, min=torch.finfo(noise.dtype).eps, max=1.)\n",
    "        gumbel_noise = -torch.log(-torch.log(noise))\n",
    "\n",
    "        sample = torch.argmax(model_logits + nonzero_mask * gumbel_noise, dim=-1)\n",
    "\n",
    "        assert sample.shape == x.shape\n",
    "        assert pred_x_start_logits.shape == model_logits.shape\n",
    "        return sample, F.softmax(pred_x_start_logits, dim=-1)\n",
    "\n",
    "    def p_sample_loop(self, model_fn, shape, num_timesteps=None, return_x_init=False, edge_features=None, edge_index=None, line_graph=None, condition=None):\n",
    "        \"\"\"Ancestral sampling.\"\"\"\n",
    "        if num_timesteps is None:\n",
    "            num_timesteps = self.num_timesteps\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        if self.transition_mat_type in ['gaussian', 'uniform', 'marginal_prior']:\n",
    "            x_init = torch.randint(0, self.num_classes, size=shape, device=device)\n",
    "        elif self.transition_mat_type == 'absorbing':\n",
    "            x_init = torch.full(shape, fill_value=self.num_classes // 2, dtype=torch.int32, device=device)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid transition_mat_type {self.transition_mat_type}\")\n",
    "\n",
    "        x = x_init.clone()  # (bs, num_edges)\n",
    "        edge_attr = x_init.float()\n",
    "        #new_line_graph_x = line_graph.x.clone()\n",
    "        #new_line_graph_x[:, :, 0] = edge_attr\n",
    "        new_edge_features = edge_features.clone()\n",
    "        new_edge_features[:, :, 0] = edge_attr\n",
    "        \n",
    "        for i in range(num_timesteps):\n",
    "            t = torch.full([shape[0]], self.num_timesteps - 1 - i, dtype=torch.long, device=device)\n",
    "            noise = torch.rand(x.shape + (self.num_classes,), device=device, dtype=torch.float32)\n",
    "            x, _ = self.p_sample(model_fn=model_fn, x=x, t=t, noise=noise, edge_features=new_edge_features, edge_index=edge_index, condition=condition)\n",
    "            new_edge_features[:, :, 0] = x.float()\n",
    "\n",
    "        if return_x_init:\n",
    "            return x_init, x\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "  # === Log likelihood / loss calculation ===\n",
    "        \n",
    "    def cross_entropy_x_start(self, x_start, pred_x_start_logits, class_weights):\n",
    "        \"\"\"Calculate binary weighted cross entropy between x_start and predicted x_start logits.\n",
    "\n",
    "        Args:\n",
    "            x_start (torch.Tensor): original clean data, expected binary labels (0 or 1), shape (bs, num_edges)\n",
    "            pred_x_start_logits (torch.Tensor): logits as predicted by the model\n",
    "            class_weights (torch.Tensor): tensor with weights for class 0 and class 1\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: scalar tensor representing the mean binary weighted cross entropy loss.\n",
    "        \"\"\"\n",
    "        # Calculate binary cross-entropy with logits\n",
    "        x_start = x_start.long().to(self.device, non_blocking=True)\n",
    "        pred_x_start_logits = pred_x_start_logits.permute(0, 2, 1).float() # (bs, num_edges, num_classes) -> (bs, num_classes, num_edges)\n",
    "        ce = F.cross_entropy(pred_x_start_logits, x_start, weight=class_weights.float().to(self.device, non_blocking=True), reduction='mean')\n",
    "\n",
    "        return ce\n",
    "\n",
    "    def training_losses(self, model_fn, condition=None, *, x_start, edge_features, edge_index, line_graph=None):\n",
    "        \"\"\"Training loss calculation.\"\"\"\n",
    "        # Add noise to data\n",
    "        noise = torch.rand(x_start.shape + (self.num_classes,), dtype=torch.float32)\n",
    "        t = torch.randint(0, self.num_timesteps, (x_start.shape[0],))\n",
    "\n",
    "        # t starts at zero. so x_0 is the first noisy datapoint, not the datapoint itself.\n",
    "        x_t = self.q_sample(x_start=x_start, t=t, noise=noise)  # (bs, num_edges)\n",
    "        # print(\"x_start:\", torch.argwhere(x_start == 1)[:, 1])\n",
    "        # print(\"Timestep:\", t.item())\n",
    "        # print(\"Noised x:\", torch.argwhere(x_t == 1)[:, 1])\n",
    "        # print(\"Len noised x:\", torch.argwhere(x_t == 1)[:, 1].shape[0])\n",
    "        \n",
    "        edge_attr_t = x_t.float()\n",
    "        # new_line_graph_x = line_graph.x.clone()\n",
    "        new_edge_features = edge_features.clone()\n",
    "        for i in range(edge_attr_t.shape[0]):\n",
    "            # new_line_graph_x[i, :, 0] = edge_attr_t[i]  # Update the edge attributes in the line graph with the noised trajectory x_t\n",
    "            new_edge_features[i, :, 0] = edge_attr_t[i]\n",
    "\n",
    "\n",
    "        # Calculate the loss\n",
    "        if self.loss_type == 'kl':\n",
    "            losses, pred_x_start_logits = self.vb_terms_bpd(model_fn=model_fn, x_start=x_start, x_t=x_t, t=t,\n",
    "                                                               edge_features=new_edge_features, edge_index=edge_index, condition=condition)\n",
    "            \n",
    "            pred_x_start_logits = pred_x_start_logits.squeeze(2)    # (bs, num_edges, channels, classes) -> (bs, num_edges, classes)\n",
    "            # NOTE: Currently only works for batch size of 1\n",
    "            pred_x_start_logits = pred_x_start_logits.squeeze(0)    # (bs, num_edges, classes) -> (num_edges, classes)\n",
    "            pred = pred_x_start_logits.argmax(dim=1)                # (num_edges, classes) -> (num_edges,)\n",
    "            \n",
    "            return losses, pred\n",
    "            \n",
    "        elif self.loss_type == 'cross_entropy_x_start':\n",
    "            \n",
    "            _, pred_x_start_logits = self.p_logits(model_fn, x=x_t, t=t, edge_features=new_edge_features, edge_index=edge_index, condition=condition)\n",
    "            losses = self.cross_entropy_x_start(x_start=x_start, pred_x_start_logits=pred_x_start_logits, class_weights=self.class_weights)\n",
    "            \n",
    "            pred_x_start_logits = pred_x_start_logits.squeeze(2)    # (bs, num_edges, channels, classes) -> (bs, num_edges, classes)\n",
    "            \n",
    "            if (self.model_name == 'edge_encoder') | (self.model_name == 'edge_encoder_residual'):\n",
    "                # NOTE: Currently only works for batch size of 1\n",
    "                pred_x_start_logits = pred_x_start_logits.squeeze(0)    # (bs, num_edges, classes) -> (num_edges, classes)\n",
    "                pred = pred_x_start_logits.argmax(dim=1)    # (num_edges, classes) -> (num_edges,)\n",
    "            elif self.model_name == 'edge_encoder_mlp':\n",
    "                pred = pred_x_start_logits.argmax(dim=2)\n",
    "            \n",
    "            return losses, pred\n",
    "            \n",
    "        else:\n",
    "            raise NotImplementedError(self.loss_type)\n",
    "\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import h5py\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, file_path, history_len, future_len, edge_features=None, device=None, embedding_dim=None):\n",
    "        self.file_path = file_path\n",
    "        self.history_len = history_len\n",
    "        self.future_len = future_len\n",
    "        self.edge_features = edge_features\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.device = device\n",
    "        self.num_edge_features = 1\n",
    "        if 'coordinates' in self.edge_features:\n",
    "            self.num_edge_features += 4\n",
    "        if 'edge_orientations' in self.edge_features:\n",
    "            self.num_edge_features += 1\n",
    "        if 'pos_encoding' in self.edge_features:\n",
    "            self.num_edge_features += self.embedding_dim\n",
    "        self.trajectories, self.nodes, self.edges, self.edge_coordinates = self.load_new_format(file_path, self.device)\n",
    "        \n",
    "        self.edge_coordinates = torch.tensor(self.edge_coordinates, dtype=torch.float64, device=self.device)\n",
    "        self.positional_encoding = self.generate_positional_encodings().float()\n",
    "        \n",
    "    @staticmethod\n",
    "    def load_new_format(file_path, device):\n",
    "        paths = []\n",
    "        with h5py.File(file_path, 'r') as new_hf:\n",
    "            node_coordinates = torch.tensor(new_hf['graph']['node_coordinates'][:], dtype=torch.float, device=device)\n",
    "            # Normalize the coordinates to (0, 1) if any of the coordinates is larger than 1\n",
    "            if node_coordinates.max() > 1:\n",
    "                max_values = node_coordinates.max(0)[0]\n",
    "                min_values = node_coordinates.min(0)[0]\n",
    "                node_coordinates[:, 0] = (node_coordinates[:, 0] - min_values[0]) / (max_values[0] - min_values[0])\n",
    "                node_coordinates[:, 1] = (node_coordinates[:, 1] - min_values[1]) / (max_values[1] - min_values[1])\n",
    "            #edges = torch.tensor(new_hf['graph']['edges'][:], dtype=torch.long, device=device)\n",
    "            edges = new_hf['graph']['edges'][:]\n",
    "            edge_coordinates = node_coordinates[edges]\n",
    "            nodes = [(i, {'pos': torch.tensor(pos, device=device)}) for i, pos in enumerate(node_coordinates)]\n",
    "            #edges = [(torch.tensor(edge[0], device=device), torch.tensor(edge[1], device=device)) for edge in edges]\n",
    "            edges = [tuple(edge) for edge in edges]\n",
    "\n",
    "            for i in tqdm(new_hf['trajectories'].keys()):\n",
    "                path_group = new_hf['trajectories'][i]\n",
    "                path = {attr: torch.tensor(path_group[attr][()], device=device) for attr in path_group.keys() if attr in ['coordinates', 'edge_idxs', 'edge_orientations']}\n",
    "                paths.append(path)\n",
    "            \n",
    "        return paths, nodes, edges, edge_coordinates\n",
    "    \n",
    "    # @staticmethod\n",
    "    def build_graph(self):\n",
    "        graph = nx.Graph()\n",
    "        graph.add_nodes_from(self.nodes)\n",
    "        indexed_edges = [((start, end), index) for index, (start, end) in enumerate(self.edges)]\n",
    "        for (start, end), index in indexed_edges:\n",
    "            graph.add_edge(start, end, index=index, default_orientation=(start, end))\n",
    "        return graph\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        trajectory = self.trajectories[idx]\n",
    "    \n",
    "        edge_idxs = trajectory['edge_idxs']\n",
    "        if 'edge_orientations' in self.edge_features:\n",
    "            edge_orientations = trajectory['edge_orientations']\n",
    "        \n",
    "        # Calculate the required padding length\n",
    "        total_len = self.history_len + self.future_len\n",
    "        padding_length = max(total_len - len(edge_idxs), 0)\n",
    "        \n",
    "        # Pad edge indices, orientations, and coordinates\n",
    "        edge_idxs = torch.nn.functional.pad(edge_idxs, (0, padding_length), value=-1)\n",
    "        if 'edge_orientations' in self.edge_features:\n",
    "            edge_orientations = torch.nn.functional.pad(edge_orientations, (0, padding_length), value=0)\n",
    "        \n",
    "        # Split into history and future\n",
    "        history_indices = edge_idxs[:self.history_len]\n",
    "        future_indices = edge_idxs[self.history_len:self.history_len + self.future_len]\n",
    "\n",
    "        # Extract and generate features\n",
    "        history_edge_features, future_edge_features = self.generate_edge_features(history_indices, future_indices, self.edge_coordinates)\n",
    "\n",
    "        return {\n",
    "            \"history_indices\": history_indices,\n",
    "            \"future_indices\": future_indices,\n",
    "            \"history_edge_features\": history_edge_features,\n",
    "            \"future_edge_features\": future_edge_features,\n",
    "        }\n",
    "\n",
    "    def generate_edge_features(self, history_indices, future_indices, history_edge_orientations=None, future_edge_orientations=None):\n",
    "        # Binary on/off edges\n",
    "        valid_history_mask = history_indices >= 0\n",
    "        valid_future_mask = future_indices >= 0\n",
    "        \n",
    "        history_one_hot_edges = torch.nn.functional.one_hot(history_indices[valid_history_mask], num_classes=len(self.edges))\n",
    "        future_one_hot_edges = torch.nn.functional.one_hot(future_indices[valid_future_mask], num_classes=len(self.edges))\n",
    "        \n",
    "        # Sum across the time dimension to count occurrences of each edge\n",
    "        history_one_hot_edges = history_one_hot_edges.sum(dim=0)  # (num_edges,)\n",
    "        future_one_hot_edges = future_one_hot_edges.sum(dim=0)  # (num_edges,)\n",
    "        \n",
    "        # Basic History edge features = coordinates, binary encoding\n",
    "        history_edge_features = history_one_hot_edges.view(-1, 1).float()\n",
    "        future_edge_features = future_one_hot_edges.view(-1, 1).float()\n",
    "        if 'coordinates' in self.edge_features:\n",
    "            history_edge_features = torch.cat((history_edge_features, torch.flatten(self.edge_coordinates, start_dim=1).float()), dim=1)\n",
    "            future_edge_features = torch.cat((future_edge_features, torch.flatten(self.edge_coordinates, start_dim=1).float()), dim=1)\n",
    "        if 'edge_orientations' in self.edge_features:\n",
    "            history_edge_features = torch.cat((history_edge_features, history_edge_orientations.float()), dim=1)\n",
    "            future_edge_features = torch.cat((future_edge_features, future_edge_orientations.float()), dim=1)\n",
    "        if 'pos_encoding' in self.edge_features:\n",
    "            encoding_tensor = torch.zeros((len(self.edges), self.embedding_dim), dtype=torch.float64, device=self.device)\n",
    "            for i, index in enumerate(history_indices):\n",
    "                encoding_tensor[index] = self.positional_encoding[i]\n",
    "            history_edge_features = torch.cat((history_edge_features, encoding_tensor.float()), dim=1)    \n",
    "        \n",
    "        return history_edge_features, future_edge_features\n",
    "    \n",
    "    def generate_positional_encodings(self):\n",
    "        position = torch.arange(self.history_len)\n",
    "        angle_rates = 1 / torch.pow(10000, (2 * (torch.arange(self.embedding_dim) // 2)) / self.embedding_dim)\n",
    "        angle_rads = position.float().unsqueeze(1) * angle_rates.unsqueeze(0)\n",
    "        sines = torch.sin(angle_rads[:, 0::2])\n",
    "        cosines = torch.cos(angle_rads[:, 1::2])\n",
    "        \n",
    "        return torch.cat((sines.float(), cosines.float()), dim=-1).to(self.device, non_blocking=True)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.trajectories)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    history_indices = torch.stack([item['history_indices'] for item in batch])\n",
    "    future_indices = torch.stack([item['future_indices'] for item in batch])\n",
    "    history_edge_features = torch.stack([item['history_edge_features'] for item in batch])\n",
    "    future_edge_features = torch.stack([item['future_edge_features'] for item in batch])\n",
    "\n",
    "    return {\n",
    "        \"history_indices\": history_indices,\n",
    "        \"future_indices\": future_indices,\n",
    "        \"history_edge_features\": history_edge_features,\n",
    "        \"future_edge_features\": future_edge_features,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import F1Score\n",
    "from torch_geometric.utils import from_networkx\n",
    "#from dataset.trajctory_dataset import TrajectoryDataset, collate_fn\n",
    "#from .d3pm_diffusion import make_diffusion\n",
    "#from .d3pm_edge_encoder import Edge_Encoder\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import wandb\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "\n",
    "class Graph_Diffusion_Model(nn.Module):\n",
    "    def __init__(self, data_config, diffusion_config, model_config, train_config, test_config, wandb_config, model):\n",
    "        super(Graph_Diffusion_Model, self).__init__()\n",
    "        \n",
    "        # Data\n",
    "        self.data_config = data_config\n",
    "        self.train_data_path = self.data_config['train_data_path']\n",
    "        self.val_data_path = self.data_config['val_data_path']\n",
    "        self.history_len = self.data_config['history_len']\n",
    "        self.future_len = self.data_config['future_len']\n",
    "        self.num_classes = self.data_config['num_classes']\n",
    "        self.edge_features = self.data_config['edge_features']\n",
    "        self.pos_encoding_dim = self.data_config['pos_encoding_dim']\n",
    "        \n",
    "        # Diffusion\n",
    "        self.diffusion_config = diffusion_config\n",
    "        self.num_timesteps = self.diffusion_config['num_timesteps']\n",
    "        \n",
    "        # Model\n",
    "        self.model_config = model_config\n",
    "        self.model = model # Edge_Encoder\n",
    "        self.hidden_channels = self.model_config['hidden_channels']\n",
    "        self.time_embedding_dim = self.model_config['time_embedding_dim']\n",
    "        self.condition_dim = self.model_config['condition_dim']\n",
    "        self.num_layers = self.model_config['num_layers']\n",
    "        \n",
    "        # Training\n",
    "        self.train_config = train_config\n",
    "        self.lr = self.train_config['lr']\n",
    "        self.lr_decay_parameter = self.train_config['lr_decay']\n",
    "        self.learning_rate_warmup_steps = self.train_config['learning_rate_warmup_steps']\n",
    "        self.num_epochs = self.train_config['num_epochs']\n",
    "        self.gradient_accumulation = self.train_config['gradient_accumulation']\n",
    "        self.gradient_accumulation_steps = self.train_config['gradient_accumulation_steps']\n",
    "        self.batch_size = self.train_config['batch_size'] if not self.gradient_accumulation else self.train_config['batch_size'] * self.gradient_accumulation_steps\n",
    "        \n",
    "        # Testing\n",
    "        self.test_config = test_config\n",
    "        self.test_batch_size = self.test_config['batch_size']\n",
    "        self.model_path = self.test_config['model_path']\n",
    "        self.eval_every_steps = self.test_config['eval_every_steps']\n",
    "        \n",
    "        # WandB\n",
    "        self.wandb_config = wandb_config\n",
    "        wandb.init(\n",
    "            settings=wandb.Settings(start_method=\"fork\"),\n",
    "            project=self.wandb_config['project'],\n",
    "            entity=self.wandb_config['entity'],\n",
    "            notes=self.wandb_config['notes'],\n",
    "            job_type=self.wandb_config['job_type'],\n",
    "            config={**self.data_config, **self.diffusion_config, **self.model_config, **self.train_config}\n",
    "        )\n",
    "        self.exp_name = self.wandb_config['exp_name']\n",
    "        wandb.run.name = self.exp_name\n",
    "\n",
    "        # Logging\n",
    "        self.dataset = self.data_config['dataset']\n",
    "        self.model_dir = os.path.join(\"experiments\", self.exp_name)\n",
    "        os.makedirs(self.model_dir,exist_ok=True)\n",
    "        log_name = '{}.log'.format(time.strftime('%Y-%m-%d-%H-%M'))\n",
    "        log_name = f\"{self.dataset}_{log_name}\"\n",
    "        \n",
    "        self.log = logging.getLogger()\n",
    "        self.log.setLevel(logging.INFO)\n",
    "        log_dir = os.path.join(self.model_dir, log_name)\n",
    "        file_handler = logging.FileHandler(log_dir)\n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        file_handler.setFormatter(formatter)\n",
    "        self.log.addHandler(file_handler)\n",
    "        \n",
    "        self.log_loss_every_steps = self.train_config['log_loss_every_steps']        \n",
    "        \n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Build Components\n",
    "        self._build_train_dataloader()\n",
    "        self._build_val_dataloader()\n",
    "        self._build_model()\n",
    "        self._build_optimizer()\n",
    "        \n",
    "        # Move model to GPU\n",
    "        \n",
    "        self.model.to(self.device, non_blocking=True)\n",
    "        print(\"device\", self.device)\n",
    "        \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Trains the diffusion-based trajectory prediction model.\n",
    "\n",
    "        This function performs the training of the diffusion-based trajectory prediction model. It iterates over the specified number of epochs and updates the model's parameters based on the training data. The training process includes forward propagation, loss calculation, gradient computation, and parameter updates.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "        dif = make_diffusion(self.diffusion_config, self.model_config, num_edges=self.num_edges, future_len=self.future_len, device=self.device)\n",
    "        def model_fn(x, edge_index, t, condition=None):\n",
    "            if self.model_config['name'] == 'edge_encoder':\n",
    "                return self.model.forward(x, edge_index, t, condition, mode='future')\n",
    "            elif self.model_config['name'] == 'edge_encoder_residual':\n",
    "                return self.model.forward(x, edge_index, t, condition, mode='future')\n",
    "            elif self.model_config['name'] == 'edge_encoder_mlp':\n",
    "                return self.model.forward(x, t=t, condition=condition, mode='future')\n",
    "                \n",
    "        for epoch in tqdm(range(self.num_epochs)):\n",
    "            current_lr = self.scheduler.get_last_lr()[0]\n",
    "            wandb.log({\"epoch\": epoch, \"learning_rate\": current_lr})\n",
    "            \n",
    "            total_loss = 0\n",
    "            ground_truth_fut = []\n",
    "            pred_fut = []\n",
    "            #with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "                #with record_function(\"model_training\"):\n",
    "            if self.gradient_accumulation:\n",
    "                for data in self.train_data_loader:\n",
    "                    history_edge_features = data[\"history_edge_features\"]\n",
    "                    future_edge_indices_one_hot = data[\"future_edge_features\"][:, :, 0]\n",
    "                    \n",
    "                    self.optimizer.zero_grad()\n",
    "                    for i in range(min(self.gradient_accumulation_steps, history_edge_features.size(0))):\n",
    "                        # Calculate history condition c\n",
    "                        \n",
    "                        if self.model_config['name'] == 'edge_encoder':\n",
    "                            c = self.model.forward(x=history_edge_features[i].unsqueeze(0), edge_index=self.edge_index, mode='history')\n",
    "                        elif self.model_config['name'] == 'edge_encoder_residual':\n",
    "                            c = self.model.forward(x=history_edge_features[i].unsqueeze(0), edge_index=self.edge_index, mode='history')\n",
    "                        elif self.model_config['name'] == 'edge_encoder_mlp':\n",
    "                            c = self.model.forward(x=history_edge_features[i].unsqueeze(0), mode='history')\n",
    "                        else:\n",
    "                            raise NotImplementedError(self.model_config['name'])\n",
    "                        \n",
    "                        x_start = future_edge_indices_one_hot[i].unsqueeze(0)   # (1, num_edges)\n",
    "                        # Get loss and predictions\n",
    "                        loss, preds = dif.training_losses(model_fn, c, x_start=x_start, edge_features=history_edge_features[i].unsqueeze(0), edge_index=self.edge_index, line_graph=None)   # preds are of shape (num_edges,)\n",
    "                        \n",
    "                        total_loss += loss / self.gradient_accumulation_steps\n",
    "                        (loss / self.gradient_accumulation_steps).backward() # Gradient accumulation\n",
    "                        \n",
    "                        if epoch % 10 == 0:\n",
    "                            ground_truth_fut.append(x_start.detach().to('cpu'))\n",
    "                            pred_fut.append(preds.detach().to('cpu'))\n",
    "                        \n",
    "                    \n",
    "                    self.optimizer.step()\n",
    "                    \n",
    "            else:\n",
    "                for data in self.train_data_loader:\n",
    "                    history_edge_features = data[\"history_edge_features\"]\n",
    "                    future_edge_indices_one_hot = data[\"future_edge_features\"][:, :, 0]\n",
    "                    \n",
    "                    batch_size = future_edge_indices_one_hot.size(0)\n",
    "                    if self.model_config['name'] == 'edge_encoder_mlp':\n",
    "                        if batch_size == self.batch_size:\n",
    "                            future_edge_indices_one_hot = future_edge_indices_one_hot.view(self.batch_size, self.num_edges)\n",
    "                        else:\n",
    "                            future_edge_indices_one_hot = future_edge_indices_one_hot.view(batch_size, self.num_edges)\n",
    "                    \n",
    "                    self.optimizer.zero_grad()\n",
    "                    # Calculate history condition c\n",
    "                    if self.model_config['name'] == 'edge_encoder':\n",
    "                        c = self.model.forward(x=history_edge_features, edge_index=self.edge_index, mode='history')\n",
    "                    elif self.model_config['name'] == 'edge_encoder_residual':\n",
    "                        c = self.model.forward(x=history_edge_features, edge_index=self.edge_index, mode='history')\n",
    "                    elif self.model_config['name'] == 'edge_encoder_mlp':\n",
    "                        c = self.model.forward(x=history_edge_features, mode='history')\n",
    "                    else:\n",
    "                        raise NotImplementedError(self.model_config['name'])\n",
    "                    \n",
    "                    x_start = future_edge_indices_one_hot\n",
    "                    # Get loss and predictions\n",
    "                    loss, preds = dif.training_losses(model_fn, c, x_start=x_start, edge_features=history_edge_features, edge_index=self.edge_index, line_graph=None)\n",
    "                                        \n",
    "                    total_loss += loss\n",
    "                    loss.backward()\n",
    "                    \n",
    "                    self.optimizer.step()\n",
    "                    if epoch % 10 == 0:\n",
    "                        ground_truth_fut.append(x_start.detach().to('cpu'))\n",
    "                        pred_fut.append(preds.detach().to('cpu'))\n",
    "            \n",
    "            self.scheduler.step()\n",
    "                    \n",
    "            if epoch % self.log_loss_every_steps == 0:\n",
    "                avg_loss = total_loss / len(self.train_data_loader)\n",
    "                wandb.log({\"epoch\": epoch, \"average_loss\": avg_loss.item()})\n",
    "                self.log.info(f\"Epoch {epoch} Average Loss: {avg_loss.item()}\")\n",
    "                print(\"Epoch:\", epoch+1)\n",
    "                print(\"Loss:\", avg_loss.item())\n",
    "                if epoch % 10 == 0:\n",
    "                    f1_score = F1Score(task='binary', average='macro', num_classes=2)\n",
    "                    f1_epoch = f1_score(torch.flatten(torch.cat(pred_fut)).detach().to('cpu'), torch.flatten(torch.cat(ground_truth_fut)).detach().to('cpu'))\n",
    "                    print(\"F1:\", f1_epoch.item())\n",
    "                    wandb.log({\"epoch\": epoch, \"average_F1_score\": f1_epoch.item()})\n",
    "                \n",
    "            if (epoch + 1) % self.eval_every_steps == 0:\n",
    "                print(\"Evaluating on test set...\")\n",
    "                sample_list, ground_truth_hist, ground_truth_fut = self.get_samples(task='predict')\n",
    "                fut_ratio, f1, avg_sample_length = self.eval(sample_list, ground_truth_hist, ground_truth_fut)\n",
    "                print(\"Samples\", sample_list)\n",
    "                print(\"Ground truth\", ground_truth_fut)\n",
    "                print(\"Test F1 Score\", f1.item())\n",
    "                wandb.log({\"Test F1 Score\": f1.item()})\n",
    "                wandb.log({\"Test Future ratio\": fut_ratio})\n",
    "                wandb.log({\"Average test sample length\": avg_sample_length})\n",
    "                        \n",
    "            if self.train_config['save_model'] and (epoch + 1) % self.train_config['save_model_every_steps'] == 0:\n",
    "                self.save_model()\n",
    "            \n",
    "    def get_samples(self, load_model=False, model_path=None, task='predict', number_samples=1, save=False):\n",
    "        \"\"\"\n",
    "        Retrieves samples from the model.\n",
    "\n",
    "        Args:\n",
    "            load_model (bool, optional): Whether to load a pre-trained model. Defaults to False.\n",
    "            model_path (str, optional): The path to the pre-trained model. Required if `load_model` is True.\n",
    "            task (str, optional): The task to perform. Defaults to 'predict'. Other possible value: 'generate' to generate realistic trajectories\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing three lists:\n",
    "                - sample_list (list): A list of samples generated by the model.\n",
    "                - ground_truth_hist (list): A list of ground truth history edge indices.\n",
    "                - ground_truth_fut (list): A list of ground truth future trajectory indices.\n",
    "        \"\"\"\n",
    "        \n",
    "        if load_model:\n",
    "            if model_path is None:\n",
    "                raise ValueError(\"Model path must be provided to load model.\")\n",
    "            self.load_model(model_path)\n",
    "        \n",
    "        if self.test_config['number_samples'] is not None:\n",
    "            number_samples = self.test_config['number_samples']\n",
    "        \n",
    "        def model_fn(x, edge_index, t, condition=None):\n",
    "            if self.model_config['name'] == 'edge_encoder':\n",
    "                return self.model.forward(x, edge_index, t, condition, mode='future')\n",
    "            elif self.model_config['name'] == 'edge_encoder_residual':\n",
    "                return self.model.forward(x, edge_index, t, condition, mode='future')\n",
    "            elif self.model_config['name'] == 'edge_encoder_mlp':\n",
    "                return self.model.forward(x=x, t=t, condition=condition, mode='future')\n",
    "        \n",
    "        sample_list = []\n",
    "        ground_truth_hist = []\n",
    "        ground_truth_fut = []\n",
    "        \n",
    "        if task == 'predict':\n",
    "            for data in tqdm(self.val_dataloader):\n",
    "                history_edge_features = data[\"history_edge_features\"]\n",
    "\n",
    "                history_edge_indices = data[\"history_indices\"]\n",
    "\n",
    "                future_trajectory_indices = data[\"future_indices\"]\n",
    "                # with torch.no_grad():\n",
    "                if self.model_config['name'] == 'edge_encoder':\n",
    "                    c = self.model.forward(x=self.line_graph.x, edge_index=self.line_graph.edge_index, mode='history')\n",
    "                elif self.model_config['name'] == 'edge_encoder_residual':\n",
    "                    c = self.model.forward(x=self.line_graph.x, edge_index=self.line_graph.edge_index, mode='history')\n",
    "                elif self.model_config['name'] == 'edge_encoder_mlp':\n",
    "                    c = self.model.forward(x=history_edge_features, mode='history')\n",
    "            \n",
    "                if number_samples > 1:\n",
    "                    new_seed = torch.seed() + torch.randint(0, 100000, (1,)).item()\n",
    "                    torch.manual_seed(new_seed)\n",
    "                    sample_sublist = []\n",
    "                    for _ in range(number_samples):\n",
    "                        samples = make_diffusion(self.diffusion_config, self.model_config, \n",
    "                                                num_edges=self.num_edges, future_len=self.future_len).p_sample_loop(model_fn=model_fn,\n",
    "                                                                                        shape=(self.test_batch_size, self.num_edges),\n",
    "                                                                                        edge_features=history_edge_features,\n",
    "                                                                                        edge_index=self.edge_index,\n",
    "                                                                                        line_graph=None,\n",
    "                                                                                        condition=c)\n",
    "                        samples = torch.where(samples == 1)[1]\n",
    "                        sample_sublist.append(samples.detach().to('cpu'))\n",
    "                    sample_list.append(sample_sublist)\n",
    "                elif number_samples == 1:\n",
    "                    samples = make_diffusion(self.diffusion_config, self.model_config, \n",
    "                                            num_edges=self.num_edges, future_len=self.future_len, device=self.device).p_sample_loop(model_fn=model_fn,\n",
    "                                                                                    shape=(self.test_batch_size, self.num_edges), \n",
    "                                                                                    edge_features=history_edge_features,\n",
    "                                                                                    edge_index=self.edge_index,\n",
    "                                                                                    line_graph=None,\n",
    "                                                                                    condition=c)\n",
    "                    samples = torch.where(samples == 1)[1]\n",
    "                    sample_list.append(samples.detach())\n",
    "                else:\n",
    "                    raise ValueError(\"Number of samples must be greater than 0.\")\n",
    "                ground_truth_hist.append(history_edge_indices.detach().to('cpu'))\n",
    "                ground_truth_fut.append(future_trajectory_indices.detach().to('cpu'))\n",
    "            \n",
    "            if number_samples == 1:\n",
    "                fut_ratio, f1, avg_sample_length = self.eval(sample_list, ground_truth_hist, ground_truth_fut)\n",
    "                wandb.log({\"F1 Score\": f1.item()})\n",
    "                wandb.log({\"Future ratio\": fut_ratio})\n",
    "                wandb.log({\"Average sample length\": avg_sample_length})\n",
    "            \n",
    "            if save:\n",
    "                save_path = os.path.join(self.model_dir, \n",
    "                                 self.exp_name + '_' + self.model_config['name'] + '_' +  self.model_config['transition_mat_type'] + '_' +  self.diffusion_config['type'] + \n",
    "                                 f'_hidden_dim_{self.hidden_channels}_time_dim_{str(self.time_embedding_dim)}_condition_dim_{self.condition_dim}_layers_{self.num_layers}')\n",
    "                torch.save(sample_list, os.path.join(save_path, f'{self.exp_name}_samples.pth'))\n",
    "                torch.save(ground_truth_hist, os.path.join(save_path, f'{self.exp_name}_ground_truth_hist.pth'))\n",
    "                torch.save(ground_truth_fut, os.path.join(save_path, f'{self.exp_name}_ground_truth_fut.pth'))\n",
    "                print(f\"Samples saved at {os.path.join(save_path, f'{self.exp_name}_samples.pth')}!\")\n",
    "            else:\n",
    "                return sample_list, ground_truth_hist, ground_truth_fut\n",
    "        \n",
    "        elif task == 'generate':\n",
    "            # Generate realistic trajectories without condition\n",
    "            # Edge encoder model needs to be able to funciton with no edge_attr and no condition\n",
    "            # Add generate mode to p_logits, p_sample, and p_sample_loop\n",
    "            return\n",
    "        \n",
    "        else:\n",
    "            raise NotImplementedError(task)\n",
    "    \n",
    "    def visualize_sample_density(self, samples, ground_truth_hist, ground_truth_fut, number_plots=5, number_samples=10):\n",
    "        \"\"\"\n",
    "        Visualize the density of the samples generated by the model.\n",
    "\n",
    "        :param samples: A list of predicted edge indices.\n",
    "        :param ground_truth_hist: A list of actual history edge indices.\n",
    "        :param ground_truth_fut: A list of actual future edge indices.\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        samples, ground_truth_hist, ground_truth_fut = self.get_samples(load_model=True, model_path=self.test_config['model_path'], number_samples=number_samples)\n",
    "        save_dir = f'{os.path.join(self.model_dir, f'{self.exp_name}', 'plots')}'\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(self.nodes)\n",
    "        all_edges = {tuple(self.edges[idx]) for idx in range(len(self.edges))}\n",
    "        G.add_edges_from(all_edges)\n",
    "\n",
    "        pos = nx.get_node_attributes(G, 'pos')\n",
    "\n",
    "        for i in range(min(number_plots, len(samples))):\n",
    "            plt.figure(figsize=(18, 8))            \n",
    "\n",
    "            for plot_num, (title, edge_indices) in enumerate([\n",
    "                ('Ground Truth History', ground_truth_hist[i][0]),\n",
    "                ('Ground Truth Future', ground_truth_fut[i][0]),\n",
    "                ('Predicted Future', samples[i])\n",
    "            ]):\n",
    "                plt.subplot(1, 3, plot_num + 1)\n",
    "                plt.title(title)\n",
    "\n",
    "                # Draw all edges as muted gray\n",
    "                nx.draw_networkx_edges(G, pos, edgelist=all_edges, width=0.5, alpha=0.3, edge_color='gray')\n",
    "\n",
    "                # Draw subgraph edges with specified color\n",
    "                edge_color = 'gray' if plot_num == 0 else 'green' if plot_num == 1 else 'red'\n",
    "                node_color = 'skyblue'\n",
    "                if plot_num == 2:\n",
    "                    edge_counts = np.zeros(len(all_edges))\n",
    "                    for sample in samples[i]:\n",
    "                        for edge in sample:\n",
    "                            edge_counts[edge] += 1\n",
    "                    max_count = np.max(edge_counts)\n",
    "                    edge_widths = edge_counts / max_count\n",
    "                    \n",
    "                    nx.draw_networkx_nodes(G, pos, node_color=node_color, node_size=500)\n",
    "                    nx.draw_networkx_edges(G, pos, edgelist=all_edges, edge_color='red', width=edge_widths*5, alpha=edge_widths/np.max(edge_widths))\n",
    "                    nx.draw_networkx_labels(G, pos, font_size=15)\n",
    "                else:\n",
    "                    subgraph_edges = {tuple(self.edges[idx]) for idx in edge_indices if idx < len(self.edges)}\n",
    "                    nx.draw_networkx_nodes(G, pos, node_color=node_color, node_size=500)\n",
    "                    nx.draw_networkx_edges(G, pos, edgelist=subgraph_edges, width=3, alpha=1.0, edge_color=edge_color)\n",
    "                    nx.draw_networkx_labels(G, pos, font_size=15)\n",
    "            # Save plot\n",
    "            plt.savefig(os.path.join(save_dir, f'sample_{i+1}.png'))\n",
    "            plt.close()  # Close the figure to free memory\n",
    "    \n",
    "    def visualize_predictions(self, samples, ground_truth_hist, ground_truth_fut, number_plots=5):\n",
    "        \"\"\"\n",
    "        Visualize the predictions of the model along with ground truth data.\n",
    "\n",
    "        :param samples: A list of predicted edge indices.\n",
    "        :param ground_truth_hist: A list of actual history edge indices.\n",
    "        :param ground_truth_fut: A list of actual future edge indices.\n",
    "        :param number_plots: Number of samples to visualize.\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        save_dir = f'{os.path.join(self.model_dir, f'{self.exp_name}', 'plots')}'\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(self.nodes)\n",
    "        all_edges = {tuple(self.edges[idx]) for idx in range(len(self.edges))}\n",
    "        G.add_edges_from(all_edges)\n",
    "        \n",
    "        pos = nx.get_node_attributes(G, 'pos')  # Retrieve node positions stored in node attributes\n",
    "\n",
    "        for i in range(min(number_plots, len(samples))):\n",
    "            plt.figure(figsize=(18, 8))            \n",
    "\n",
    "            for plot_num, (title, edge_indices) in enumerate([\n",
    "                ('Ground Truth History', ground_truth_hist[i][0]),\n",
    "                ('Ground Truth Future', ground_truth_fut[i][0]),\n",
    "                ('Predicted Future', samples[i])\n",
    "            ]):\n",
    "                plt.subplot(1, 3, plot_num + 1)\n",
    "                plt.title(title)\n",
    "                subgraph_edges = {tuple(self.edges[idx]) for idx in edge_indices if idx < len(self.edges)}\n",
    "\n",
    "                # Draw all edges as muted gray\n",
    "                nx.draw_networkx_edges(G, pos, edgelist=all_edges, width=0.5, alpha=0.3, edge_color='gray')\n",
    "\n",
    "                # Draw subgraph edges with specified color\n",
    "                edge_color = 'gray' if plot_num == 0 else 'green' if plot_num == 1 else 'red'\n",
    "                node_color = 'skyblue'# if plot_num == 0 else 'lightgreen' if plot_num == 1 else 'orange'\n",
    "                nx.draw_networkx_nodes(G, pos, node_color=node_color, node_size=500)\n",
    "                nx.draw_networkx_edges(G, pos, edgelist=subgraph_edges, width=3, alpha=1.0, edge_color=edge_color)\n",
    "                nx.draw_networkx_labels(G, pos, font_size=15)\n",
    "            # Save plot\n",
    "            plt.savefig(os.path.join(save_dir, f'sample_{i+1}.png'))\n",
    "            plt.close()  # Close the figure to free memory\n",
    "    \n",
    "    def eval(self, sample_list, ground_truth_hist, ground_truth_fut):\n",
    "        \"\"\"\n",
    "        Evaluate the model's performance.\n",
    "\n",
    "        :param sample_list: A list of predicted edge indices.\n",
    "        :param ground_truth_hist: A list of actual history edge indices.\n",
    "        :param ground_truth_fut: A list of actual future edge indices.\n",
    "        \"\"\"\n",
    "        def calculate_fut_ratio(sample_list, ground_truth_fut):\n",
    "            \"\"\"\n",
    "            Calculates the ratio of samples in `sample_list` that have at least one or two edges in common with the ground truth future trajectory.\n",
    "\n",
    "            Args:\n",
    "                sample_list (list): A list of samples.\n",
    "                ground_truth_fut (list): A list of ground truth future trajectories.\n",
    "\n",
    "            Returns:\n",
    "                tuple: A tuple containing the ratios of samples that have at least one or two edges in common with the ground truth future trajectory.\n",
    "            \"\"\"\n",
    "            count_1 = 0\n",
    "            count_2 = 0\n",
    "            total = len(sample_list)\n",
    "\n",
    "            for i, sample in enumerate(sample_list):\n",
    "                edges_count = sum(1 for edge in ground_truth_fut[i][0] if edge in sample)\n",
    "                if edges_count >= 1:\n",
    "                    count_1 += 1\n",
    "                if edges_count >= 2:\n",
    "                    count_2 += 1\n",
    "\n",
    "            ratio_1 = count_1 / total\n",
    "            ratio_2 = count_2 / total\n",
    "            return ratio_1, ratio_2\n",
    "        \n",
    "        def calculate_sample_f1(sample_list, ground_truth_fut):\n",
    "            \"\"\"\n",
    "            Calculates the F1 score for a given list of samples and ground truth futures.\n",
    "\n",
    "            Args:\n",
    "                sample_list (list): A list of samples.\n",
    "                ground_truth_fut (list): A list of ground truth futures.\n",
    "\n",
    "            Returns:\n",
    "                float: The F1 score.\n",
    "\n",
    "            \"\"\"\n",
    "            one_hot_samples = [torch.zeros(self.num_edges) for _ in range(len(sample_list))]\n",
    "            one_hot_futures = [torch.zeros(self.num_edges) for _ in range(len(ground_truth_fut))]\n",
    "            for i, one_hot_sample in enumerate(one_hot_samples):\n",
    "                for edge_index, edge in enumerate(self.edges):\n",
    "                    if edge_index in sample_list[i]:\n",
    "                        one_hot_sample[edge_index] = 1\n",
    "            for i, one_hot_fut in enumerate(one_hot_futures):\n",
    "                for edge_index, edge in enumerate(self.edges):\n",
    "                    if edge_index in ground_truth_fut[i]:\n",
    "                        one_hot_fut[edge_index] = 1\n",
    "            metric = F1Score(task='binary', average='macro', num_classes=2)\n",
    "            f1 = metric(torch.cat(one_hot_samples), torch.cat(one_hot_futures))\n",
    "\n",
    "            return f1\n",
    "        \n",
    "        def calculate_avg_sample_length(sample_list):\n",
    "            \"\"\"\n",
    "            Calculate the average sample length.\n",
    "\n",
    "            Args:\n",
    "                sample_list (list): A list of samples.\n",
    "\n",
    "            Returns:\n",
    "                float: The average sample length.\n",
    "            \"\"\"\n",
    "            return sum(len(sample) for sample in sample_list) / len(sample_list)\n",
    "        \n",
    "        fut_ratio = calculate_fut_ratio(sample_list, ground_truth_fut)\n",
    "        f1 = calculate_sample_f1(sample_list, ground_truth_fut)\n",
    "        avg_sample_length = calculate_avg_sample_length(sample_list)\n",
    "        \n",
    "        return fut_ratio, f1, avg_sample_length\n",
    "    \n",
    "    def save_model(self):\n",
    "        save_path = os.path.join(self.model_dir, \n",
    "                                 self.exp_name + '_' + self.model_config['name'] + '_' +  self.model_config['transition_mat_type'] + '_' +  self.diffusion_config['type'] + \n",
    "                                 f'_hidden_dim_{self.hidden_channels}_time_dim_{str(self.time_embedding_dim)}_condition_dim_{self.condition_dim}_layers_{self.num_layers}.pth')\n",
    "        torch.save(self.model.state_dict(), save_path)\n",
    "        self.log.info(f\"Model saved at {save_path}!\")\n",
    "        print(f\"Model saved at {save_path}\")\n",
    "        \n",
    "    def load_model(self, model_path):\n",
    "        self.model.load_state_dict(torch.load(model_path))\n",
    "        self.log.info(\"Model loaded!\")\n",
    "    \n",
    "    def _build_optimizer(self):\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        \n",
    "        def lr_lambda(epoch):\n",
    "            if epoch < self.learning_rate_warmup_steps:\n",
    "                return 1.0\n",
    "            else:\n",
    "                decay_lr = self.lr_decay_parameter ** (epoch - self.learning_rate_warmup_steps)\n",
    "                return max(decay_lr, 2e-5 / self.lr)\n",
    "            \n",
    "        self.scheduler = torch.optim.lr_scheduler.LambdaLR(self.optimizer, lr_lambda)\n",
    "        print(\"> Optimizer and Scheduler built!\")\n",
    "        \n",
    "        \"\"\"print(\"Parameters to optimize:\")\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(name)\"\"\"\n",
    "        \n",
    "    def _build_train_dataloader(self):\n",
    "        print(\"Loading Training Dataset...\")\n",
    "        self.train_dataset = TrajectoryDataset(self.train_data_path, self.history_len, self.future_len, self.edge_features, device=self.device, embedding_dim=self.pos_encoding_dim)\n",
    "        self.G = self.train_dataset.build_graph()\n",
    "        self.nodes = self.G.nodes\n",
    "        self.edges = self.G.edges(data=True)\n",
    "        self.num_edges = self.G.number_of_edges()\n",
    "        self.indexed_edges = self.train_dataset.edges\n",
    "        self.num_edge_features = self.train_dataset.num_edge_features\n",
    "        \n",
    "        # Build the line graph and corresponding edge index\n",
    "        self.edge_index = self._build_edge_index()\n",
    "                \n",
    "        self.train_data_loader = DataLoader(self.train_dataset, \n",
    "                                            batch_size=self.batch_size, \n",
    "                                            shuffle=True, \n",
    "                                            collate_fn=collate_fn, \n",
    "                                            num_workers=0,\n",
    "                                            pin_memory=False)\n",
    "                        \n",
    "        print(\"> Training Dataset loaded!\\n\")\n",
    "        \n",
    "    def _build_edge_index(self):\n",
    "        print(\"Building edge index for line graph...\")\n",
    "        edge_index = torch.tensor([[e[0], e[1]] for e in self.edges], dtype=torch.long).t().contiguous()\n",
    "        edge_to_index = {tuple(e[:2]): e[2]['index'] for e in self.edges}\n",
    "        line_graph_edges = []\n",
    "        edge_list = edge_index.t().tolist()\n",
    "        for i, (u1, v1) in tqdm(enumerate(edge_list), total=len(edge_list), desc=\"Processing edges\"):\n",
    "            for j, (u2, v2) in enumerate(edge_list):\n",
    "                if i != j and (u1 == u2 or u1 == v2 or v1 == u2 or v1 == v2):\n",
    "                    line_graph_edges.append((edge_to_index[(u1, v1)], edge_to_index[(u2, v2)]))\n",
    "\n",
    "        # Create the edge index for the line graph\n",
    "        edge_index = torch.tensor(line_graph_edges, dtype=torch.long).t().contiguous()\n",
    "        print(\"> Edge index built!\\n\")\n",
    "        \n",
    "        return edge_index.to(self.device, non_blocking=True)\n",
    "    \n",
    "    def _build_val_dataloader(self):\n",
    "        self.val_dataset = TrajectoryDataset(self.val_data_path, self.history_len, self.future_len, self.edge_features, device=self.device, embedding_dim=self.pos_encoding_dim)\n",
    "        self.val_dataloader = DataLoader(self.val_dataset, batch_size=self.test_batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "        print(\"> Test Dataset loaded!\")\n",
    "        \n",
    "    def _build_model(self):\n",
    "        self.model = self.model(self.model_config, self.history_len, self.future_len, self.num_classes,\n",
    "                                num_edges=self.num_edges, hidden_channels=self.hidden_channels, num_edge_features=self.num_edge_features, num_timesteps=self.num_timesteps)\n",
    "        print(\"> Model built!\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def get_timestep_embedding(timesteps, embedding_dim, max_time=1000., device=None):\n",
    "    \"\"\"\n",
    "    Build sinusoidal embeddings (from Fairseq).\n",
    "\n",
    "    This matches the implementation in tensor2tensor, but differs slightly\n",
    "    from the description in Section 3.5 of \"Attention Is All You Need\".\n",
    "\n",
    "    Args:\n",
    "        timesteps: torch.Tensor: generate embedding vectors at these timesteps\n",
    "        embedding_dim: int: dimension of the embeddings to generate\n",
    "        max_time: float: largest time input\n",
    "\n",
    "    Returns:\n",
    "        embedding vectors with shape `(len(timesteps), embedding_dim)`\n",
    "    \"\"\"\n",
    "    timesteps = timesteps.to(device)\n",
    "    assert timesteps.dim() == 1  # Ensure timesteps is a 1D tensor\n",
    "\n",
    "    # Scale timesteps by the maximum time\n",
    "    timesteps = timesteps.float() * (1000. / max_time)\n",
    "\n",
    "    half_dim = embedding_dim // 2\n",
    "    emb = torch.log(torch.tensor(10000.0, device=device)) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32, device=device) * -emb)\n",
    "    emb = timesteps[:, None] * emb[None, :]\n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "\n",
    "    if embedding_dim % 2 == 1:  # Add zero-padding if embedding dimension is odd\n",
    "        zero_pad = torch.zeros((timesteps.shape[0], 1), dtype=torch.float32)\n",
    "        emb = torch.cat([emb, zero_pad], dim=1)\n",
    "\n",
    "    assert emb.shape == (timesteps.shape[0], embedding_dim)\n",
    "    return emb.to(device)\n",
    "\n",
    "class Edge_Encoder_MLP(nn.Module):\n",
    "    def __init__(self, model_config, history_len, future_len, num_classes, num_edges, hidden_channels, num_edge_features, num_timesteps):\n",
    "        super(Edge_Encoder_MLP, self).__init__()\n",
    "        # Config\n",
    "        self.config = model_config\n",
    "        \n",
    "        # Data\n",
    "        self.num_edges = num_edges\n",
    "        self.num_edge_features = num_edge_features\n",
    "        self.history_len = history_len\n",
    "        self.future_len = future_len\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Time embedding\n",
    "        self.max_time = num_timesteps\n",
    "        self.time_embedding_dim = self.config['time_embedding_dim']\n",
    "        self.time_linear0 = nn.Linear(self.time_embedding_dim, self.time_embedding_dim)\n",
    "        self.time_linear1 = nn.Linear(self.time_embedding_dim, self.time_embedding_dim)\n",
    "    \n",
    "        # Model\n",
    "        # GNN layers\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_layers = self.config['num_layers']\n",
    "        self.lin_layers = nn.ModuleList()\n",
    "        self.lin_layers.append(nn.Linear(self.num_edge_features, self.hidden_channels))\n",
    "        for _ in range(1, self.num_layers):\n",
    "            self.lin_layers.append(nn.Linear(self.hidden_channels, self.hidden_channels))\n",
    "        \n",
    "        # Output layers for each task\n",
    "        self.condition_dim = self.config['condition_dim']\n",
    "        self.history_encoder = nn.Linear(self.hidden_channels, self.condition_dim)  # To encode history to c\n",
    "        self.future_decoder = nn.Linear(self.hidden_channels + self.condition_dim + self.time_embedding_dim,\n",
    "                                        self.hidden_channels)  # To predict future edges\n",
    "        self.adjust_to_class_shape = nn.Linear(self.hidden_channels, self.num_classes)\n",
    "\n",
    "    def forward(self, x, t=None, condition=None, mode=None):\n",
    "        \"\"\"\n",
    "        Forward pass through the model\n",
    "        Args:\n",
    "            x: torch.Tensor: input tensor: noised future trajectory indices / history trajectory indices\n",
    "            t: torch.Tensor: timestep tensor\n",
    "        \"\"\"    \n",
    "        \n",
    "        # GNN forward pass\n",
    "        \n",
    "        # Edge Embedding        \n",
    "        for layer in self.lin_layers:\n",
    "            x = F.relu(layer(x))\n",
    "\n",
    "        if mode == 'history':\n",
    "            c = self.history_encoder(x) # (bs, num_edges, condition_dim)\n",
    "            return c\n",
    "        \n",
    "        elif mode == 'future':\n",
    "            # Time embedding\n",
    "            t_emb = get_timestep_embedding(t, embedding_dim=self.time_embedding_dim, max_time=self.max_time, device=x.device)\n",
    "            t_emb = self.time_linear0(t_emb)\n",
    "            t_emb = F.silu(t_emb)  # SiLU activation, equivalent to Swish\n",
    "            t_emb = self.time_linear1(t_emb)\n",
    "            t_emb = F.silu(t_emb)   # (bs, time_embedding_dim)\n",
    "            t_emb = t_emb.unsqueeze(1).repeat(1, x.size(1), 1) # (bs, num_edges, time_embedding_dim)\n",
    "            \n",
    "            #Concatenation\n",
    "            x = torch.cat((x, t_emb), dim=2) # Concatenate with time embedding\n",
    "            x = torch.cat((x, condition), dim=2) # Concatenate with condition c, (bs, num_edges, hidden_channels + condition_dim + time_embedding_dim)\n",
    "            \n",
    "            logits = self.future_decoder(x) # (bs, num_edges, hidden_channels)\n",
    "            logits = self.adjust_to_class_shape(logits) # (bs, num_edges, num_classes=2)\n",
    "\n",
    "            return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:8d8l861c) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ethereal-bush-1661</strong> at: <a href='https://wandb.ai/joeschmit99/trajectory_prediction_using_denoising_diffusion_models/runs/8d8l861c/workspace' target=\"_blank\">https://wandb.ai/joeschmit99/trajectory_prediction_using_denoising_diffusion_models/runs/8d8l861c/workspace</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240712_163320-8d8l861c/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:8d8l861c). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/models/wandb/run-20240712_163420-grzmssq3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/joeschmit99/trajectory_prediction_using_denoising_diffusion_models/runs/grzmssq3/workspace' target=\"_blank\">flowing-frog-1662</a></strong> to <a href='https://wandb.ai/joeschmit99/trajectory_prediction_using_denoising_diffusion_models' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/joeschmit99/trajectory_prediction_using_denoising_diffusion_models' target=\"_blank\">https://wandb.ai/joeschmit99/trajectory_prediction_using_denoising_diffusion_models</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/joeschmit99/trajectory_prediction_using_denoising_diffusion_models/runs/grzmssq3/workspace' target=\"_blank\">https://wandb.ai/joeschmit99/trajectory_prediction_using_denoising_diffusion_models/runs/grzmssq3/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Training Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2314237/1124105301.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nodes = [(i, {'pos': torch.tensor(pos, device=device)}) for i, pos in enumerate(node_coordinates)]\n",
      "100%|| 2/2 [00:00<00:00, 411.41it/s]\n",
      "/tmp/ipykernel_2314237/1124105301.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.edge_coordinates = torch.tensor(self.edge_coordinates, dtype=torch.float64, device=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building edge index for line graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing edges: 100%|| 16784/16784 [01:18<00:00, 214.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Edge index built!\n",
      "\n",
      "> Training Dataset loaded!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2/2 [00:00<00:00, 350.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Test Dataset loaded!\n",
      "> Model built!\n",
      "> Optimizer and Scheduler built!\n",
      "device cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_config = {\"dataset\": \"synthetic_20_traj\",\n",
    "    \"train_data_path\": '/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/data/tdrive_2.h5',\n",
    "    \"val_data_path\": '/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/data/tdrive_2.h5',\n",
    "    \"history_len\": 5,\n",
    "    \"future_len\": 2,\n",
    "    \"num_classes\": 2,\n",
    "    \"pos_encoding_dim\": 16,\n",
    "    \"edge_features\": ['one_hot_edges', 'coordinates', 'pos_encoding']\n",
    "    }\n",
    "\n",
    "diffusion_config = {\"type\": 'linear', # Options: 'linear', 'cosine', 'jsd'\n",
    "    \"start\": 0.4,  # 1e-4 gauss, 0.02 uniform\n",
    "    \"stop\": 0.8,  # 0.02 gauss, 1. uniform\n",
    "    \"num_timesteps\": 100}\n",
    "\n",
    "model_config = {\"name\": \"edge_encoder_mlp\",\n",
    "    \"hidden_channels\": 32,\n",
    "    \"time_embedding_dim\": 16,\n",
    "    \"condition_dim\": 16,\n",
    "    \"out_ch\": 1,\n",
    "    \"num_heads\": 2,\n",
    "    \"num_layers\": 2,\n",
    "    \"theta\": 1.0, # controls strength of conv layers in residual model\n",
    "    \"dropout\": 0.1,\n",
    "    \"model_output\": \"logits\",\n",
    "    \"model_prediction\": \"x_start\",  # Options: 'x_start','xprev'\n",
    "    \"transition_mat_type\": 'gaussian',  # Options: 'gaussian', 'uniform', 'absorbing', 'marginal_prior'\n",
    "    \"transition_bands\": 0,\n",
    "    \"loss_type\": \"cross_entropy_x_start\",  # Options: kl, cross_entropy_x_start, hybrid\n",
    "    \"hybrid_coeff\": 0.001,  # Only used for hybrid loss type.\n",
    "    }\n",
    "\n",
    "train_config = {\"batch_size\": 1,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"lr\": 0.01,\n",
    "    \"gradient_accumulation\": False,\n",
    "    \"gradient_accumulation_steps\": 32,\n",
    "    \"num_epochs\": 20,\n",
    "    \"learning_rate_warmup_steps\": 200, # previously 10000\n",
    "    \"lr_decay\": 0.9995, # previously 0.9999\n",
    "    \"log_loss_every_steps\": 1,\n",
    "    \"save_model\": False,\n",
    "    \"save_model_every_steps\": 200}\n",
    "\n",
    "test_config = {\"batch_size\": 1, # currently only 1 works\n",
    "    \"model_path\": '/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/experiments/geolife_residual/geolife_residual_edge_encoder_residual_marginal_prior_cosine_hidden_dim_32_time_dim_16_condition_dim_16_layers_2.pth',\n",
    "    \"number_samples\": 1,\n",
    "    \"eval_every_steps\": 1000\n",
    "  }\n",
    "\n",
    "wandb_config = {\"exp_name\": \"synthetic_d3pm_test\",\n",
    "    \"project\": \"trajectory_prediction_using_denoising_diffusion_models\",\n",
    "    \"entity\": \"joeschmit99\",\n",
    "    \"job_type\": \"test\",\n",
    "    \"notes\": \"\",\n",
    "    \"tags\": [\"synthetic\", \"edge_encoder\"]} \n",
    "\n",
    "if model_config[\"name\"] == 'edge_encoder':\n",
    "    encoder_model = Edge_Encoder\n",
    "elif model_config[\"name\"] == 'edge_encoder_mlp':\n",
    "    encoder_model = Edge_Encoder_MLP\n",
    "elif model_config[\"name\"] == 'edge_encoder_residual':\n",
    "    encoder_model = Edge_Encoder_Residual\n",
    "\n",
    "model = Graph_Diffusion_Model(data_config, diffusion_config, model_config, train_config, test_config, wandb_config, encoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.9995e-01, 4.5396e-05],\n",
      "        [4.5396e-05, 9.9995e-01]], dtype=torch.float64)\n",
      "tensor([[9.9928e-01, 7.2025e-04],\n",
      "        [7.2025e-04, 9.9928e-01]], dtype=torch.float64)\n",
      "tensor([[0.9979, 0.0021],\n",
      "        [0.0021, 0.9979]], dtype=torch.float64)\n",
      "tensor([[0.9951, 0.0049],\n",
      "        [0.0049, 0.9951]], dtype=torch.float64)\n",
      "tensor([[0.9905, 0.0095],\n",
      "        [0.0095, 0.9905]], dtype=torch.float64)\n",
      "tensor([[0.9830, 0.0170],\n",
      "        [0.0170, 0.9830]], dtype=torch.float64)\n",
      "tensor([[0.9718, 0.0282],\n",
      "        [0.0282, 0.9718]], dtype=torch.float64)\n",
      "tensor([[0.9559, 0.0441],\n",
      "        [0.0441, 0.9559]], dtype=torch.float64)\n",
      "tensor([[0.9346, 0.0654],\n",
      "        [0.0654, 0.9346]], dtype=torch.float64)\n",
      "tensor([[0.9073, 0.0927],\n",
      "        [0.0927, 0.9073]], dtype=torch.float64)\n",
      "tensor([[0.8741, 0.1259],\n",
      "        [0.1259, 0.8741]], dtype=torch.float64)\n",
      "tensor([[0.8355, 0.1645],\n",
      "        [0.1645, 0.8355]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Loss: 0.6083023548126221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 1/20 [00:03<01:14,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 2/20 [00:07<01:03,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n",
      "Loss: 0.29798123240470886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 3/20 [00:10<00:58,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n",
      "Loss: 0.061139725148677826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 4/20 [00:13<00:53,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\n",
      "Loss: 0.004217584151774645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 5/20 [00:16<00:48,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n",
      "Loss: 0.0025691716000437737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 6/20 [00:20<00:46,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6\n",
      "Loss: 0.00388436671346426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 7/20 [00:23<00:43,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7\n",
      "Loss: 0.005231514573097229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 8/20 [00:26<00:39,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8\n",
      "Loss: 0.006667426787316799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 9/20 [00:29<00:34,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9\n",
      "Loss: 0.007937410846352577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 10/20 [00:32<00:31,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\n",
      "Loss: 0.008875744417309761\n",
      "Epoch: 11\n",
      "Loss: 0.009847098961472511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 11/20 [00:36<00:28,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 12/20 [00:39<00:25,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12\n",
      "Loss: 0.01043463684618473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|   | 13/20 [00:42<00:22,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13\n",
      "Loss: 0.010754773393273354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 14/20 [00:45<00:19,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14\n",
      "Loss: 0.010819250717759132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 15/20 [00:49<00:16,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15\n",
      "Loss: 0.010675135999917984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 16/20 [00:52<00:13,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16\n",
      "Loss: 0.010404972359538078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 17/20 [00:55<00:09,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17\n",
      "Loss: 0.00989924743771553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 18/20 [00:58<00:06,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18\n",
      "Loss: 0.009163632988929749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 19/20 [01:01<00:03,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19\n",
      "Loss: 0.008507838472723961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [01:04<00:00,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20\n",
      "Loss: 0.007653871551156044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d3pm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

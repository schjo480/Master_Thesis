{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'T' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 131\u001b[0m\n\u001b[1;32m    125\u001b[0m         mat \u001b[38;5;241m=\u001b[39m beta_t \u001b[38;5;241m*\u001b[39m class_probs \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta_t) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;241m2\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mat\n\u001b[1;32m    130\u001b[0m q_one_step_mats \u001b[38;5;241m=\u001b[39m [_get_gaussian_transition_mat(t)\n\u001b[0;32m--> 131\u001b[0m                             \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[43mT\u001b[49m)]\n\u001b[1;32m    132\u001b[0m q_onestep_mats \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(q_one_step_mats, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m q_onestep_mats\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (T,\n\u001b[1;32m    134\u001b[0m                                     \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    135\u001b[0m                                     \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'T' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "def get_diffusion_betas(spec, device):\n",
    "    \"\"\"Get betas from the hyperparameters.\"\"\"\n",
    "    \n",
    "    if spec['type'] == 'linear':\n",
    "        # Used by Ho et al. for DDPM, https://arxiv.org/abs/1006.11239.\n",
    "        # To be used with Gaussian diffusion models in continuous and discrete\n",
    "        # state spaces.\n",
    "        # To be used with transition_mat_type = 'gaussian'\n",
    "        return torch.linspace(spec['start'], spec['stop'], spec['num_timesteps']).to(device)\n",
    "    elif spec['type'] == 'cosine':\n",
    "        # Schedule proposed by Hoogeboom et al. https://arxiv.org/abs/2102.05379\n",
    "        # To be used with transition_mat_type = 'uniform'.\n",
    "        steps = torch.linspace(0, 1, spec['num_timesteps'] + 1, dtype=torch.float64)\n",
    "        alpha_bar = torch.square(torch.cos(((steps + 0.008) / 1.008) * torch.pi / 2))\n",
    "        betas = torch.minimum(1 - alpha_bar[1:] / alpha_bar[:-1], torch.tensor(0.999))\n",
    "        return betas.to(device)\n",
    "    elif spec['type'] == 'jsd':  # 1/T, 1/(T-1), 1/(T-2), ..., 1\n",
    "        # Proposed by Sohl-Dickstein et al., https://arxiv.org/abs/1503.03585\n",
    "        # To be used with absorbing state models.\n",
    "        # ensures that the probability of decaying to the absorbing state\n",
    "        # increases linearly over time, and is 1 for t = T-1 (the final time).\n",
    "        # To be used with transition_mat_type = 'absorbing'\n",
    "        return 1. / torch.linspace(spec['num_timesteps'], 1, spec['num_timesteps']).to(device)\n",
    "    else:\n",
    "        raise NotImplementedError(spec['type'])\n",
    "    \n",
    "    \n",
    "def _get_gaussian_transition_mat(t):\n",
    "    r\"\"\"Computes transition matrix for q(x_t|x_{t-1}).\n",
    "\n",
    "    This method constructs a transition matrix Q with\n",
    "    decaying entries as a function of how far off diagonal the entry is.\n",
    "    Normalization option 1:\n",
    "    Q_{ij} =  ~ softmax(-val^2/beta_t)   if |i-j| <= transition_bands\n",
    "                1 - \\sum_{l \\neq i} Q_{il}  if i==j.\n",
    "                0                          else.\n",
    "\n",
    "    Normalization option 2:\n",
    "    tilde{Q}_{ij} =  softmax(-val^2/beta_t)   if |i-j| <= transition_bands\n",
    "                        0                        else.\n",
    "\n",
    "    Q_{ij} =  tilde{Q}_{ij} / sum_l{tilde{Q}_{lj}}\n",
    "\n",
    "    Args:\n",
    "        t: timestep. integer scalar (or numpy array?)\n",
    "\n",
    "    Returns:\n",
    "        Q_t: transition matrix. shape = (num_classes, num_classes).\n",
    "    \"\"\"\n",
    "    num_classes = 2\n",
    "    device = 'cpu'\n",
    "    transition_bands = 1\n",
    "    spec = {'type': 'linear', 'start': 0.4, 'stop': 1.0, 'num_timesteps': T}\n",
    "    betas = get_diffusion_betas(spec, device=device)\n",
    "    transition_bands = transition_bands if transition_bands else num_classes - 1\n",
    "\n",
    "    beta_t = betas[t]\n",
    "\n",
    "    mat = torch.zeros((num_classes, num_classes),\n",
    "                    dtype=torch.float64).to(device, non_blocking=True)\n",
    "\n",
    "    # Make the values correspond to a similar type of gaussian as in the\n",
    "    # gaussian diffusion case for continuous state spaces.\n",
    "    values = torch.linspace(torch.tensor(0.), torch.tensor(num_classes-1), num_classes, dtype=torch.float64).to(device, non_blocking=True)\n",
    "    #print(values)   # [0, 1]\n",
    "    values = values * 2./ (num_classes - 1.)\n",
    "    #print(values)   # [0, 2]\n",
    "    values = values[:transition_bands+1]\n",
    "    #print(values)   # [0, 2]\n",
    "    values = -values * values / beta_t\n",
    "    #print(values)   # [0, -6300]\n",
    "    \n",
    "    # To reverse the tensor 'values' starting from the second element\n",
    "    reversed_values = values[1:].flip(dims=[0])\n",
    "    #print(reversed_values)  # [-6300]\n",
    "    # Concatenating the reversed values with the original values\n",
    "    values = torch.cat([reversed_values, values], dim=0)\n",
    "    #print(values)   # [-6300, 0, -6300]\n",
    "    values = F.softmax(values, dim=0)\n",
    "    #print(values)   # [0, 1, 0]\n",
    "    values = values[transition_bands:]\n",
    "    #print(values)   # [1, 0]\n",
    "    \n",
    "    for k in range(1, transition_bands + 1):\n",
    "        off_diag = torch.full((num_classes - k,), values[k], dtype=torch.float64).to(device, non_blocking=True)\n",
    "\n",
    "        mat += torch.diag(off_diag, k)\n",
    "        mat += torch.diag(off_diag, -k)\n",
    "\n",
    "    # Add diagonal values such that rows and columns sum to one.\n",
    "    # Technically only the ROWS need to sum to one\n",
    "    # NOTE: this normalization leads to a doubly stochastic matrix,\n",
    "    # which is necessary if we want to have a uniform stationary distribution.\n",
    "    diag = 1. - mat.sum(dim=1)\n",
    "    mat += torch.diag_embed(diag)\n",
    "\n",
    "    return mat.to(device, non_blocking=True)\n",
    "\n",
    "def _get_prior_distribution_transition_mat(t):\n",
    "        \"\"\"Computes transition matrix for q(x_t|x_{t-1}).\n",
    "        Use cosine schedule for these transition matrices.\n",
    "\n",
    "        Args:\n",
    "        t: timestep. integer scalar.\n",
    "\n",
    "        Returns:\n",
    "        Q_t: transition matrix. shape = (num_classes, num_classes).\n",
    "        \"\"\"\n",
    "        device = 'cpu'\n",
    "        spec = {'type': 'cosine', 'start': 0.4, 'stop': 0.8, 'num_timesteps': T}\n",
    "        betas = get_diffusion_betas(spec, device=device)\n",
    "        beta_t = betas[t]\n",
    "        num_classes = 2\n",
    "        class_probs = torch.tensor([1 - 5/11000, 5/11000], device=device)\n",
    "        mat = torch.zeros((num_classes, num_classes), dtype=torch.float64).to(device, non_blocking=True)\n",
    "\n",
    "        '''for i in range(num_classes):\n",
    "            for j in range(num_classes):\n",
    "                if i != j:\n",
    "                    mat[i, j] = beta_t * class_probs[j]\n",
    "                else:\n",
    "                    mat[i, j] = 1 - beta_t + beta_t * class_probs[j]'''\n",
    "        mat = beta_t * class_probs + (1 - beta_t) * torch.eye(2, device=device)\n",
    "        \n",
    "        return mat\n",
    "\n",
    "\n",
    "q_one_step_mats = [_get_gaussian_transition_mat(t)\n",
    "                            for t in range(0, T)]\n",
    "q_onestep_mats = torch.stack(q_one_step_mats, axis=0).to('cpu', non_blocking=True)\n",
    "assert q_onestep_mats.shape == (T,\n",
    "                                    2,\n",
    "                                    2)\n",
    "\n",
    "# Construct transition matrices for q(x_t|x_start)\n",
    "q_mat_t = q_onestep_mats[0]\n",
    "q_mats = [q_mat_t]\n",
    "for t in range(1, T):\n",
    "    # Q_{1...t} = Q_{1 ... t-1} Q_t = Q_1 Q_2 ... Q_t\n",
    "    q_mat_t = torch.tensordot(q_mat_t, q_onestep_mats[t],\n",
    "                            dims=[[1], [0]])\n",
    "    q_mats.append(q_mat_t)\n",
    "q_mats = torch.stack(q_mats, axis=0)\n",
    "\n",
    "for t in range(0, T, 9):\n",
    "    print(q_mats[t])\n",
    "    # print(_get_gaussian_transition_mat(t))\n",
    "    # print(_get_prior_distribution_transition_mat(t))\n",
    "\n",
    "'''import matplotlib.pyplot as plt\n",
    "\n",
    "spec = {'type': 'linear', 'start': 1.0, 'stop': 100.0, 'num_timesteps': 100}\n",
    "betas = get_diffusion_betas(spec, device='cpu')\n",
    "plt.plot(betas)\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9000, 0.1000],\n",
      "         [0.9000, 0.1000]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "e_marginals = torch.tensor([0.9, 0.1], dtype=torch.float64)\n",
    "print(e_marginals.unsqueeze(0).expand(2, -1).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m alphas \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m betas\n\u001b[1;32m     32\u001b[0m alpha_bar \u001b[38;5;241m=\u001b[39m onp\u001b[38;5;241m.\u001b[39mcumprod(alphas)\n\u001b[0;32m---> 33\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mplot(betas)\n\u001b[1;32m     34\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(alpha_bar)\n\u001b[1;32m     35\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha_bar\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as onp\n",
    "def get_diffusion_betas(spec):\n",
    "  \"\"\"Get betas from the hyperparameters.\"\"\"\n",
    "  if spec['type'] == 'linear':\n",
    "    # Used by Ho et al. for DDPM, https://arxiv.org/abs/2006.11239.\n",
    "    # To be used with Gaussian diffusion models in continuous and discrete\n",
    "    # state spaces.\n",
    "    # To be used with transition_mat_type = 'gaussian'\n",
    "    return onp.linspace(spec['start'], spec['stop'], spec['num_timesteps'])\n",
    "  elif spec['type'] == 'cosine':\n",
    "    # Schedule proposed by Hoogeboom et al. https://arxiv.org/abs/2102.05379\n",
    "    # To be used with transition_mat_type = 'uniform'.\n",
    "    steps = (\n",
    "        onp.arange(spec['num_timesteps'] + 1, dtype=onp.float64) /\n",
    "        spec['num_timesteps'])\n",
    "    alpha_bar = onp.cos((steps + 0.008) / 1.008 * onp.pi / 2)\n",
    "    betas = onp.minimum(1 - alpha_bar[1:] / alpha_bar[:-1], 0.999)\n",
    "    return betas\n",
    "  elif spec['type'] == 'jsd':  # 1/T, 1/(T-1), 1/(T-2), ..., 1\n",
    "    # Proposed by Sohl-Dickstein et al., https://arxiv.org/abs/1503.03585\n",
    "    # To be used with absorbing state models.\n",
    "    # ensures that the probability of decaying to the absorbing state\n",
    "    # increases linearly over time, and is 1 for t = T-1 (the final time).\n",
    "    # To be used with transition_mat_type = 'absorbing'\n",
    "    return 1. / onp.linspace(spec['num_timesteps'], 1., spec['num_timesteps'])\n",
    "  else:\n",
    "    raise NotImplementedError(spec['type'])\n",
    "  \n",
    "spec = {'type': 'linear', 'start': 0.4, 'stop': 0.8, 'num_timesteps': 100}\n",
    "betas = get_diffusion_betas(spec)\n",
    "alphas = 1 - betas\n",
    "alpha_bar = onp.cumprod(alphas)\n",
    "plt.plot(betas)\n",
    "plt.plot(alpha_bar)\n",
    "plt.legend(['betas', 'alpha_bar'])\n",
    "plt.show()\n",
    "\n",
    "import scipy\n",
    "def _get_gaussian_transition_mat(t):\n",
    "    r\"\"\"Computes transition matrix for q(x_t|x_{t-1}).\n",
    "\n",
    "    This method constructs a transition matrix Q with\n",
    "    decaying entries as a function of how far off diagonal the entry is.\n",
    "    Normalization option 1:\n",
    "    Q_{ij} =  ~ softmax(-val^2/beta_t)   if |i-j| <= transition_bands\n",
    "             1 - \\sum_{l \\neq i} Q_{il}  if i==j.\n",
    "             0                          else.\n",
    "\n",
    "    Normalization option 2:\n",
    "    tilde{Q}_{ij} =  softmax(-val^2/beta_t)   if |i-j| <= transition_bands\n",
    "                     0                        else.\n",
    "\n",
    "    Q_{ij} =  tilde{Q}_{ij} / sum_l{tilde{Q}_{lj}}\n",
    "\n",
    "    Args:\n",
    "      t: timestep. integer scalar (or numpy array?)\n",
    "\n",
    "    Returns:\n",
    "      Q_t: transition matrix. shape = (num_pixel_vals, num_pixel_vals).\n",
    "    \"\"\"\n",
    "    transition_bands = 2 - 1\n",
    "    betas = get_diffusion_betas(spec)\n",
    "    beta_t = betas[t]\n",
    "\n",
    "    mat = onp.zeros((2, 2),\n",
    "                    dtype=onp.float64)\n",
    "\n",
    "    # Make the values correspond to a similar type of gaussian as in the\n",
    "    # gaussian diffusion case for continuous state spaces.\n",
    "    values = onp.linspace(start=0., stop=1., num=2,\n",
    "                          endpoint=True, dtype=onp.float64)\n",
    "    print(values)\n",
    "    values = values * 2./ (2 - 1.)\n",
    "    print(values)\n",
    "    values = values[:transition_bands+1]\n",
    "    print(values)\n",
    "    values = -values * values / beta_t\n",
    "    print(values)\n",
    "\n",
    "    values = onp.concatenate([values[:0:-1], values], axis=0)\n",
    "    print(values)\n",
    "    values = scipy.special.softmax(values, axis=0)\n",
    "    print(values)\n",
    "    values = values[transition_bands:]\n",
    "    print(values)\n",
    "    for k in range(1, transition_bands + 1):\n",
    "      off_diag = onp.full(shape=(2 - k,),\n",
    "                          fill_value=values[k],\n",
    "                          dtype=onp.float64)\n",
    "\n",
    "      mat += onp.diag(off_diag, k=k)\n",
    "      mat += onp.diag(off_diag, k=-k)\n",
    "\n",
    "    # Add diagonal values such that rows and columns sum to one.\n",
    "    # Technically only the ROWS need to sum to one\n",
    "    # NOTE: this normalization leads to a doubly stochastic matrix,\n",
    "    # which is necessary if we want to have a uniform stationary distribution.\n",
    "    diag = 1. - mat.sum(1)\n",
    "    mat += onp.diag(diag, k=0)\n",
    "\n",
    "    return mat\n",
    "  \n",
    "_get_gaussian_transition_mat(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m alphas \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m betas\n\u001b[1;32m     23\u001b[0m alpha_bar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcumprod(alphas)\n\u001b[0;32m---> 24\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mplot(betas)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#plt.plot(alphas)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(alpha_bar)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_beta_schedule(T, s=0.008):\n",
    "    \"\"\"\n",
    "    Generate a cosine schedule for diffusion betas.\n",
    "    \n",
    "    Args:\n",
    "    - T (int): The total number of diffusion timesteps.\n",
    "    - s (float): A small constant to ensure the betas do not reach 0, which could cause numerical stability issues.\n",
    "    \n",
    "    Returns:\n",
    "    - np.array: An array of length T with the beta values for each timestep.\n",
    "    \"\"\"\n",
    "    steps = np.arange(T, dtype=np.float64)\n",
    "    x = s + (1 - s) * np.cos(0.5 * np.pi * steps / T)\n",
    "    betas = 1 - x / x.max()\n",
    "    return betas\n",
    "\n",
    "# Example usage\n",
    "T = 1000  # Total number of diffusion steps\n",
    "betas = cosine_beta_schedule(T)\n",
    "alphas = 1 - betas\n",
    "alpha_bar = np.cumprod(alphas)\n",
    "plt.plot(betas)\n",
    "#plt.plot(alphas)\n",
    "plt.plot(alpha_bar)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def cosine_beta_schedule(timesteps, s=0.008):\n",
    "    \"\"\"\n",
    "    Cosine schedule as described in https://arxiv.org/abs/2102.09672.\n",
    "\n",
    "    Parameters:\n",
    "    - timesteps: int, the number of timesteps for the schedule.\n",
    "    - s: float, small constant to prevent numerical issues.\n",
    "\n",
    "    Returns:\n",
    "    - betas: torch.Tensor, beta values for each timestep.\n",
    "    - alphas: torch.Tensor, alpha values for each timestep.\n",
    "    - alpha_bars: torch.Tensor, cumulative product of alphas for each timestep.\n",
    "    \"\"\"\n",
    "    steps = timesteps + 1\n",
    "    x = torch.linspace(0, timesteps, steps)\n",
    "    alphas_cumprod = torch.cos((x / timesteps + s) / (1 + s) * torch.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "\n",
    "    betas = 1 - alphas_cumprod[1:] / alphas_cumprod[:-1]\n",
    "    alphas = 1 - betas\n",
    "    alpha_bars = torch.cumprod(alphas, dim=0)\n",
    "\n",
    "    return betas, alphas, alpha_bars\n",
    "\n",
    "# Example usage\n",
    "timesteps = 100  # Number of timesteps\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "betas, alphas, alpha_bars = cosine_beta_schedule(timesteps)\n",
    "betas = betas.to(device)\n",
    "alphas = alphas.to(device)\n",
    "alpha_bars = alpha_bars.to(device)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(betas)\n",
    "plt.plot(alpha_bars)\n",
    "plt.legend(['betas', 'alpha_bar'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.],\n",
      "        [0., 1.]], dtype=torch.float64)\n",
      "tensor([[1., 0.],\n",
      "        [0., 1.]], dtype=torch.float64)\n",
      "tensor([[ 1.0000e+00, 2.7013e-181],\n",
      "        [2.7013e-181,  1.0000e+00]], dtype=torch.float64)\n",
      "tensor([[ 1.0000e+00, 1.1120e-119],\n",
      "        [1.1120e-119,  1.0000e+00]], dtype=torch.float64)\n",
      "tensor([[1.0000e+00, 1.9474e-86],\n",
      "        [1.9474e-86, 1.0000e+00]], dtype=torch.float64)\n",
      "tensor([[1.0000e+00, 5.9673e-65],\n",
      "        [5.9673e-65, 1.0000e+00]], dtype=torch.float64)\n",
      "tensor([[1.0000e+00, 2.1169e-49],\n",
      "        [2.1169e-49, 1.0000e+00]], dtype=torch.float64)\n",
      "tensor([[1.0000e+00, 3.3204e-37],\n",
      "        [3.3204e-37, 1.0000e+00]], dtype=torch.float64)\n",
      "tensor([[1.0000e+00, 5.0076e-27],\n",
      "        [5.0076e-27, 1.0000e+00]], dtype=torch.float64)\n",
      "tensor([[1.0000e+00, 4.3916e-18],\n",
      "        [4.3916e-18, 1.0000e+00]], dtype=torch.float64)\n",
      "tensor([[1.0000e+00, 7.1885e-10],\n",
      "        [7.1885e-10, 1.0000e+00]], dtype=torch.float64)\n",
      "tensor([[0.9769, 0.0231],\n",
      "        [0.0231, 0.9769]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"import matplotlib.pyplot as plt\\n\\nspec = {'type': 'linear', 'start': 1.0, 'stop': 100.0, 'num_timesteps': 100}\\nbetas = get_diffusion_betas(spec, device='cpu')\\nplt.plot(betas)\\nplt.show()\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "T = 100\n",
    "\n",
    "def get_diffusion_betas(spec, device):\n",
    "    \"\"\"Get betas from the hyperparameters.\"\"\"\n",
    "    \n",
    "    if spec['type'] == 'linear':\n",
    "        # Used by Ho et al. for DDPM, https://arxiv.org/abs/1006.11239.\n",
    "        # To be used with Gaussian diffusion models in continuous and discrete\n",
    "        # state spaces.\n",
    "        # To be used with transition_mat_type = 'gaussian'\n",
    "        return torch.linspace(spec['start'], spec['stop'], spec['num_timesteps']).to(device)\n",
    "    elif spec['type'] == 'cosine':\n",
    "        # Schedule proposed by Hoogeboom et al. https://arxiv.org/abs/2102.05379\n",
    "        # To be used with transition_mat_type = 'uniform'.\n",
    "        steps = torch.linspace(0, 1, spec['num_timesteps'] + 1, dtype=torch.float64)\n",
    "        betas, alphas, alpha_bars = cosine_beta_schedule(spec['num_timesteps'])\n",
    "        return betas.to(device)\n",
    "    elif spec['type'] == 'jsd':  # 1/T, 1/(T-1), 1/(T-2), ..., 1\n",
    "        # Proposed by Sohl-Dickstein et al., https://arxiv.org/abs/1503.03585\n",
    "        # To be used with absorbing state models.\n",
    "        # ensures that the probability of decaying to the absorbing state\n",
    "        # increases linearly over time, and is 1 for t = T-1 (the final time).\n",
    "        # To be used with transition_mat_type = 'absorbing'\n",
    "        return 1. / torch.linspace(spec['num_timesteps'], 1, spec['num_timesteps']).to(device)\n",
    "    else:\n",
    "        raise NotImplementedError(spec['type'])\n",
    "    \n",
    "    \n",
    "def _get_gaussian_transition_mat(t):\n",
    "    r\"\"\"Computes transition matrix for q(x_t|x_{t-1}).\n",
    "\n",
    "    This method constructs a transition matrix Q with\n",
    "    decaying entries as a function of how far off diagonal the entry is.\n",
    "    Normalization option 1:\n",
    "    Q_{ij} =  ~ softmax(-val^2/beta_t)   if |i-j| <= transition_bands\n",
    "                1 - \\sum_{l \\neq i} Q_{il}  if i==j.\n",
    "                0                          else.\n",
    "\n",
    "    Normalization option 2:\n",
    "    tilde{Q}_{ij} =  softmax(-val^2/beta_t)   if |i-j| <= transition_bands\n",
    "                        0                        else.\n",
    "\n",
    "    Q_{ij} =  tilde{Q}_{ij} / sum_l{tilde{Q}_{lj}}\n",
    "\n",
    "    Args:\n",
    "        t: timestep. integer scalar (or numpy array?)\n",
    "\n",
    "    Returns:\n",
    "        Q_t: transition matrix. shape = (num_classes, num_classes).\n",
    "    \"\"\"\n",
    "    num_classes = 2\n",
    "    device = 'cpu'\n",
    "    transition_bands = 1\n",
    "    spec = {'type': 'cosine', 'start': 0.4, 'stop': 1.0, 'num_timesteps': T}\n",
    "    betas = get_diffusion_betas(spec, device=device)\n",
    "    # transition_bands = transition_bands if transition_bands else num_classes - 1\n",
    "\n",
    "    beta_t = betas[t]\n",
    "\n",
    "    mat = torch.zeros((num_classes, num_classes),\n",
    "                    dtype=torch.float64).to(device, non_blocking=True)\n",
    "\n",
    "    # Make the values correspond to a similar type of gaussian as in the\n",
    "    # gaussian diffusion case for continuous state spaces.\n",
    "    values = torch.linspace(torch.tensor(0.), torch.tensor(num_classes-1), num_classes, dtype=torch.float64).to(device, non_blocking=True)\n",
    "    #print(values)   # [0, 1]\n",
    "    values = values * 2./ (num_classes - 1.)\n",
    "    #print(values)   # [0, 2]\n",
    "    values = values[:transition_bands+1]\n",
    "    #print(values)   # [0, 2]\n",
    "    values = -values * values / beta_t\n",
    "    #print(values)   # [0, -6300]\n",
    "    \n",
    "    # To reverse the tensor 'values' starting from the second element\n",
    "    reversed_values = values[1:].flip(dims=[0])\n",
    "    #print(reversed_values)  # [-6300]\n",
    "    # Concatenating the reversed values with the original values\n",
    "    values = torch.cat([reversed_values, values], dim=0)\n",
    "    #print(values)   # [-6300, 0, -6300]\n",
    "    values = F.softmax(values, dim=0)\n",
    "    #print(values)   # [0, 1, 0]\n",
    "    values = values[transition_bands:]\n",
    "    #print(values)   # [1, 0]\n",
    "    \n",
    "    for k in range(1, transition_bands + 1):\n",
    "        off_diag = torch.full((num_classes - k,), values[k], dtype=torch.float64).to(device, non_blocking=True)\n",
    "\n",
    "        mat += torch.diag(off_diag, k)\n",
    "        mat += torch.diag(off_diag, -k)\n",
    "\n",
    "    # Add diagonal values such that rows and columns sum to one.\n",
    "    # Technically only the ROWS need to sum to one\n",
    "    # NOTE: this normalization leads to a doubly stochastic matrix,\n",
    "    # which is necessary if we want to have a uniform stationary distribution.\n",
    "    diag = 1. - mat.sum(dim=1)\n",
    "    mat += torch.diag_embed(diag)\n",
    "\n",
    "    return mat.to(device, non_blocking=True)\n",
    "\n",
    "def _get_prior_distribution_transition_mat(t):\n",
    "        \"\"\"Computes transition matrix for q(x_t|x_{t-1}).\n",
    "        Use cosine schedule for these transition matrices.\n",
    "\n",
    "        Args:\n",
    "        t: timestep. integer scalar.\n",
    "\n",
    "        Returns:\n",
    "        Q_t: transition matrix. shape = (num_classes, num_classes).\n",
    "        \"\"\"\n",
    "        device = 'cpu'\n",
    "        spec = {'type': 'cosine', 'start': 0.4, 'stop': 0.8, 'num_timesteps': T}\n",
    "        betas = get_diffusion_betas(spec, device=device)\n",
    "        beta_t = betas[t]\n",
    "        num_classes = 2\n",
    "        class_probs = torch.tensor([1 - 5/11000, 5/11000], device=device)\n",
    "        mat = torch.zeros((num_classes, num_classes), dtype=torch.float64).to(device, non_blocking=True)\n",
    "\n",
    "        '''for i in range(num_classes):\n",
    "            for j in range(num_classes):\n",
    "                if i != j:\n",
    "                    mat[i, j] = beta_t * class_probs[j]\n",
    "                else:\n",
    "                    mat[i, j] = 1 - beta_t + beta_t * class_probs[j]'''\n",
    "        mat = beta_t * class_probs + (1 - beta_t) * torch.eye(2, device=device)\n",
    "        \n",
    "        return mat\n",
    "\n",
    "\n",
    "q_one_step_mats = [_get_gaussian_transition_mat(t)\n",
    "                            for t in range(0, T)]\n",
    "q_onestep_mats = torch.stack(q_one_step_mats, axis=0).to('cpu', non_blocking=True)\n",
    "assert q_onestep_mats.shape == (T,\n",
    "                                    2,\n",
    "                                    2)\n",
    "\n",
    "# Construct transition matrices for q(x_t|x_start)\n",
    "q_mat_t = q_onestep_mats[0]\n",
    "q_mats = [q_mat_t]\n",
    "for t in range(1, T):\n",
    "    # Q_{1...t} = Q_{1 ... t-1} Q_t = Q_1 Q_2 ... Q_t\n",
    "    q_mat_t = torch.tensordot(q_mat_t, q_onestep_mats[t],\n",
    "                            dims=[[1], [0]])\n",
    "    q_mats.append(q_mat_t)\n",
    "q_mats = torch.stack(q_mats, axis=0)\n",
    "\n",
    "for t in range(0, T, 9):\n",
    "    print(q_mats[t])\n",
    "    # print(_get_gaussian_transition_mat(t))\n",
    "    # print(_get_prior_distribution_transition_mat(t))\n",
    "\n",
    "'''import matplotlib.pyplot as plt\n",
    "\n",
    "spec = {'type': 'linear', 'start': 1.0, 'stop': 100.0, 'num_timesteps': 100}\n",
    "betas = get_diffusion_betas(spec, device='cpu')\n",
    "plt.plot(betas)\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transition_matrix(t, device='cpu'):\n",
    "    \"\"\"\n",
    "    Generates a 2x2 transition matrix for a discrete diffusion process at timestep t.\n",
    "\n",
    "    Parameters:\n",
    "    - t: int, current timestep.\n",
    "    - device: torch.device, the device to place the tensor on.\n",
    "\n",
    "    Returns:\n",
    "    - transition_matrix: torch.Tensor, a 2x2 transition matrix.\n",
    "    \"\"\"\n",
    "    betas, _, alpha_bars = cosine_beta_schedule(T)\n",
    "    spec = {'type': 'cosine', 'start': 0.00001, 'stop': 0.001, 'num_timesteps': T}\n",
    "    betas = get_diffusion_betas(spec, device=device)\n",
    "    alphas = 1 - betas\n",
    "    alpha_bars = torch.cumprod(alphas, dim=0)\n",
    "    alpha_bar_t = alpha_bars[t].to(device)\n",
    "    \n",
    "    # Compute the transition probabilities\n",
    "    transition_matrix = torch.tensor([[alpha_bar_t, 1 - alpha_bar_t],\n",
    "                                      [1 - alpha_bar_t, alpha_bar_t]], device=device)\n",
    "    \n",
    "    return transition_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.9937e-01, 6.3127e-04],\n",
      "        [6.3127e-04, 9.9937e-01]])\n",
      "tensor([[0.9976, 0.0024],\n",
      "        [0.0024, 0.9976]])\n",
      "tensor([[0.9943, 0.0057],\n",
      "        [0.0057, 0.9943]])\n",
      "tensor([[0.9889, 0.0111],\n",
      "        [0.0111, 0.9889]])\n",
      "tensor([[0.9811, 0.0189],\n",
      "        [0.0189, 0.9811]])\n",
      "tensor([[0.9705, 0.0295],\n",
      "        [0.0295, 0.9705]])\n",
      "tensor([[0.9568, 0.0432],\n",
      "        [0.0432, 0.9568]])\n",
      "tensor([[0.9399, 0.0601],\n",
      "        [0.0601, 0.9399]])\n",
      "tensor([[0.9196, 0.0804],\n",
      "        [0.0804, 0.9196]])\n",
      "tensor([[0.8962, 0.1038],\n",
      "        [0.1038, 0.8962]])\n",
      "tensor([[0.8698, 0.1302],\n",
      "        [0.1302, 0.8698]])\n",
      "tensor([[0.8409, 0.1591],\n",
      "        [0.1591, 0.8409]])\n",
      "tensor([[0.8100, 0.1900],\n",
      "        [0.1900, 0.8100]])\n",
      "tensor([[0.7777, 0.2223],\n",
      "        [0.2223, 0.7777]])\n",
      "tensor([[0.7448, 0.2552],\n",
      "        [0.2552, 0.7448]])\n",
      "tensor([[0.7120, 0.2880],\n",
      "        [0.2880, 0.7120]])\n",
      "tensor([[0.6803, 0.3197],\n",
      "        [0.3197, 0.6803]])\n",
      "tensor([[0.6503, 0.3497],\n",
      "        [0.3497, 0.6503]])\n",
      "tensor([[0.6226, 0.3774],\n",
      "        [0.3774, 0.6226]])\n",
      "tensor([[0.5978, 0.4022],\n",
      "        [0.4022, 0.5978]])\n",
      "tensor([[0.5761, 0.4239],\n",
      "        [0.4239, 0.5761]])\n",
      "tensor([[0.5577, 0.4423],\n",
      "        [0.4423, 0.5577]])\n",
      "tensor([[0.5425, 0.4575],\n",
      "        [0.4575, 0.5425]])\n",
      "tensor([[0.5305, 0.4695],\n",
      "        [0.4695, 0.5305]])\n",
      "tensor([[0.5211, 0.4789],\n",
      "        [0.4789, 0.5211]])\n",
      "tensor([[0.5142, 0.4858],\n",
      "        [0.4858, 0.5142]])\n",
      "tensor([[0.5092, 0.4908],\n",
      "        [0.4908, 0.5092]])\n",
      "tensor([[0.5057, 0.4943],\n",
      "        [0.4943, 0.5057]])\n",
      "tensor([[0.5034, 0.4966],\n",
      "        [0.4966, 0.5034]])\n",
      "tensor([[0.5020, 0.4980],\n",
      "        [0.4980, 0.5020]])\n",
      "tensor([[0.5011, 0.4989],\n",
      "        [0.4989, 0.5011]])\n",
      "tensor([[0.5006, 0.4994],\n",
      "        [0.4994, 0.5006]])\n",
      "tensor([[0.5003, 0.4997],\n",
      "        [0.4997, 0.5003]])\n",
      "tensor([[0.5001, 0.4999],\n",
      "        [0.4999, 0.5001]])\n",
      "tensor([[0.5001, 0.4999],\n",
      "        [0.4999, 0.5001]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n"
     ]
    }
   ],
   "source": [
    "q_one_step_mats = [get_transition_matrix(t)\n",
    "                            for t in range(0, T)]\n",
    "q_onestep_mats = torch.stack(q_one_step_mats, axis=0).to('cpu', non_blocking=True)\n",
    "assert q_onestep_mats.shape == (T,\n",
    "                                    2,\n",
    "                                    2)\n",
    "\n",
    "# Construct transition matrices for q(x_t|x_start)\n",
    "q_mat_t = q_onestep_mats[0]\n",
    "q_mats = [q_mat_t]\n",
    "for t in range(1, T):\n",
    "    # Q_{1...t} = Q_{1 ... t-1} Q_t = Q_1 Q_2 ... Q_t\n",
    "    q_mat_t = torch.tensordot(q_mat_t, q_onestep_mats[t],\n",
    "                            dims=[[1], [0]])\n",
    "    q_mats.append(q_mat_t)\n",
    "q_mats = torch.stack(q_mats, axis=0)\n",
    "\n",
    "for t in range(0, T, 1):\n",
    "    print(q_mats[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_prior_distribution_transition_mat(t):\n",
    "    \"\"\"Computes transition matrix for q(x_t|x_{t-1}).\n",
    "    Use cosine schedule for these transition matrices.\n",
    "\n",
    "    Args:\n",
    "    t: timestep. integer scalar.\n",
    "\n",
    "    Returns:\n",
    "    Q_t: transition matrix. shape = (num_classes, num_classes).\n",
    "    \"\"\"\n",
    "    device = 'cpu'\n",
    "    spec = {'type': 'Linear', 'start': 0.00001, 'stop': 0.005, 'num_timesteps': T}\n",
    "    betas = get_diffusion_betas(spec, device=device)\n",
    "    beta_t = betas[t]\n",
    "    num_classes = 2\n",
    "    class_probs = torch.tensor([1 - 5/11000, 5/11000], device=device)\n",
    "    mat = torch.zeros((num_classes, num_classes), dtype=torch.float64).to(device, non_blocking=True)\n",
    "\n",
    "    '''for i in range(num_classes):\n",
    "        for j in range(num_classes):\n",
    "            if i != j:\n",
    "                mat[i, j] = beta_t * class_probs[j]\n",
    "            else:\n",
    "                mat[i, j] = 1 - beta_t + beta_t * class_probs[j]'''\n",
    "    mat = beta_t * class_probs + (1 - beta_t) * torch.eye(2, device=device)\n",
    "    \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000e+00, 2.8694e-07],\n",
      "        [6.3099e-04, 9.9937e-01]])\n",
      "tensor([[1.0000e+00, 7.9432e-07],\n",
      "        [1.7467e-03, 9.9825e-01]])\n",
      "tensor([[1.0000e+00, 1.5216e-06],\n",
      "        [3.3461e-03, 9.9665e-01]])\n",
      "tensor([[1.0000e+00, 2.4682e-06],\n",
      "        [5.4276e-03, 9.9457e-01]])\n",
      "tensor([[1.0000e+00, 3.6330e-06],\n",
      "        [7.9891e-03, 9.9201e-01]])\n",
      "tensor([[9.9999e-01, 5.0151e-06],\n",
      "        [1.1028e-02, 9.8897e-01]])\n",
      "tensor([[9.9999e-01, 6.6130e-06],\n",
      "        [1.4542e-02, 9.8546e-01]])\n",
      "tensor([[9.9999e-01, 8.4251e-06],\n",
      "        [1.8527e-02, 9.8147e-01]])\n",
      "tensor([[9.9999e-01, 1.0450e-05],\n",
      "        [2.2979e-02, 9.7702e-01]])\n",
      "tensor([[9.9999e-01, 1.2685e-05],\n",
      "        [2.7895e-02, 9.7211e-01]])\n",
      "tensor([[9.9998e-01, 1.5129e-05],\n",
      "        [3.3268e-02, 9.6673e-01]])\n",
      "tensor([[9.9998e-01, 1.7778e-05],\n",
      "        [3.9095e-02, 9.6091e-01]])\n",
      "tensor([[9.9998e-01, 2.0631e-05],\n",
      "        [4.5369e-02, 9.5463e-01]])\n",
      "tensor([[9.9998e-01, 2.3685e-05],\n",
      "        [5.2084e-02, 9.4792e-01]])\n",
      "tensor([[9.9997e-01, 2.6937e-05],\n",
      "        [5.9234e-02, 9.4077e-01]])\n",
      "tensor([[9.9997e-01, 3.0383e-05],\n",
      "        [6.6812e-02, 9.3319e-01]])\n",
      "tensor([[9.9997e-01, 3.4020e-05],\n",
      "        [7.4810e-02, 9.2519e-01]])\n",
      "tensor([[9.9996e-01, 3.7845e-05],\n",
      "        [8.3221e-02, 9.1678e-01]])\n",
      "tensor([[9.9996e-01, 4.1854e-05],\n",
      "        [9.2037e-02, 9.0796e-01]])\n",
      "tensor([[9.9995e-01, 4.6043e-05],\n",
      "        [1.0125e-01, 8.9875e-01]])\n",
      "tensor([[9.9995e-01, 5.0408e-05],\n",
      "        [1.1085e-01, 8.8915e-01]])\n",
      "tensor([[9.9994e-01, 5.4944e-05],\n",
      "        [1.2082e-01, 8.7918e-01]])\n",
      "tensor([[9.9994e-01, 5.9648e-05],\n",
      "        [1.3117e-01, 8.6883e-01]])\n",
      "tensor([[9.9994e-01, 6.4515e-05],\n",
      "        [1.4187e-01, 8.5813e-01]])\n",
      "tensor([[9.9993e-01, 6.9540e-05],\n",
      "        [1.5292e-01, 8.4708e-01]])\n",
      "tensor([[9.9993e-01, 7.4718e-05],\n",
      "        [1.6430e-01, 8.3570e-01]])\n",
      "tensor([[9.9992e-01, 8.0044e-05],\n",
      "        [1.7602e-01, 8.2398e-01]])\n",
      "tensor([[9.9991e-01, 8.5513e-05],\n",
      "        [1.8804e-01, 8.1196e-01]])\n",
      "tensor([[9.9991e-01, 9.1120e-05],\n",
      "        [2.0037e-01, 7.9963e-01]])\n",
      "tensor([[9.9990e-01, 9.6859e-05],\n",
      "        [2.1299e-01, 7.8701e-01]])\n",
      "tensor([[9.9990e-01, 1.0272e-04],\n",
      "        [2.2589e-01, 7.7411e-01]])\n",
      "tensor([[9.9989e-01, 1.0871e-04],\n",
      "        [2.3906e-01, 7.6094e-01]])\n",
      "tensor([[9.9989e-01, 1.1481e-04],\n",
      "        [2.5247e-01, 7.4753e-01]])\n",
      "tensor([[9.9988e-01, 1.2102e-04],\n",
      "        [2.6613e-01, 7.3387e-01]])\n",
      "tensor([[9.9987e-01, 1.2734e-04],\n",
      "        [2.8002e-01, 7.1998e-01]])\n",
      "tensor([[9.9987e-01, 1.3375e-04],\n",
      "        [2.9411e-01, 7.0589e-01]])\n",
      "tensor([[9.9986e-01, 1.4025e-04],\n",
      "        [3.0841e-01, 6.9159e-01]])\n",
      "tensor([[9.9985e-01, 1.4684e-04],\n",
      "        [3.2289e-01, 6.7711e-01]])\n",
      "tensor([[9.9985e-01, 1.5350e-04],\n",
      "        [3.3755e-01, 6.6245e-01]])\n",
      "tensor([[9.9984e-01, 1.6024e-04],\n",
      "        [3.5236e-01, 6.4764e-01]])\n",
      "tensor([[9.9983e-01, 1.6704e-04],\n",
      "        [3.6732e-01, 6.3268e-01]])\n",
      "tensor([[9.9983e-01, 1.7390e-04],\n",
      "        [3.8240e-01, 6.1760e-01]])\n",
      "tensor([[9.9982e-01, 1.8081e-04],\n",
      "        [3.9760e-01, 6.0240e-01]])\n",
      "tensor([[9.9981e-01, 1.8777e-04],\n",
      "        [4.1290e-01, 5.8710e-01]])\n",
      "tensor([[9.9981e-01, 1.9476e-04],\n",
      "        [4.2828e-01, 5.7172e-01]])\n",
      "tensor([[9.9980e-01, 2.0179e-04],\n",
      "        [4.4373e-01, 5.5627e-01]])\n",
      "tensor([[9.9979e-01, 2.0884e-04],\n",
      "        [4.5923e-01, 5.4076e-01]])\n",
      "tensor([[9.9978e-01, 2.1591e-04],\n",
      "        [4.7478e-01, 5.2522e-01]])\n",
      "tensor([[9.9978e-01, 2.2299e-04],\n",
      "        [4.9035e-01, 5.0965e-01]])\n",
      "tensor([[9.9977e-01, 2.3007e-04],\n",
      "        [5.0593e-01, 4.9407e-01]])\n",
      "tensor([[9.9976e-01, 2.3715e-04],\n",
      "        [5.2150e-01, 4.7850e-01]])\n",
      "tensor([[9.9976e-01, 2.4422e-04],\n",
      "        [5.3705e-01, 4.6295e-01]])\n",
      "tensor([[9.9975e-01, 2.5128e-04],\n",
      "        [5.5256e-01, 4.4744e-01]])\n",
      "tensor([[9.9974e-01, 2.5831e-04],\n",
      "        [5.6803e-01, 4.3197e-01]])\n",
      "tensor([[9.9973e-01, 2.6531e-04],\n",
      "        [5.8342e-01, 4.1658e-01]])\n",
      "tensor([[9.9973e-01, 2.7228e-04],\n",
      "        [5.9874e-01, 4.0126e-01]])\n",
      "tensor([[9.9972e-01, 2.7920e-04],\n",
      "        [6.1396e-01, 3.8604e-01]])\n",
      "tensor([[9.9971e-01, 2.8607e-04],\n",
      "        [6.2907e-01, 3.7093e-01]])\n",
      "tensor([[9.9971e-01, 2.9288e-04],\n",
      "        [6.4405e-01, 3.5595e-01]])\n",
      "tensor([[9.9970e-01, 2.9963e-04],\n",
      "        [6.5889e-01, 3.4111e-01]])\n",
      "tensor([[9.9969e-01, 3.0631e-04],\n",
      "        [6.7358e-01, 3.2642e-01]])\n",
      "tensor([[9.9969e-01, 3.1291e-04],\n",
      "        [6.8810e-01, 3.1190e-01]])\n",
      "tensor([[9.9968e-01, 3.1943e-04],\n",
      "        [7.0243e-01, 2.9757e-01]])\n",
      "tensor([[9.9967e-01, 3.2586e-04],\n",
      "        [7.1657e-01, 2.8343e-01]])\n",
      "tensor([[9.9967e-01, 3.3220e-04],\n",
      "        [7.3050e-01, 2.6950e-01]])\n",
      "tensor([[9.9966e-01, 3.3843e-04],\n",
      "        [7.4420e-01, 2.5580e-01]])\n",
      "tensor([[9.9966e-01, 3.4455e-04],\n",
      "        [7.5767e-01, 2.4233e-01]])\n",
      "tensor([[9.9965e-01, 3.5056e-04],\n",
      "        [7.7089e-01, 2.2911e-01]])\n",
      "tensor([[9.9964e-01, 3.5645e-04],\n",
      "        [7.8384e-01, 2.1616e-01]])\n",
      "tensor([[9.9964e-01, 3.6222e-04],\n",
      "        [7.9652e-01, 2.0348e-01]])\n",
      "tensor([[9.9963e-01, 3.6785e-04],\n",
      "        [8.0890e-01, 1.9110e-01]])\n",
      "tensor([[9.9963e-01, 3.7335e-04],\n",
      "        [8.2099e-01, 1.7901e-01]])\n",
      "tensor([[9.9962e-01, 3.7870e-04],\n",
      "        [8.3277e-01, 1.6723e-01]])\n",
      "tensor([[9.9962e-01, 3.8391e-04],\n",
      "        [8.4422e-01, 1.5578e-01]])\n",
      "tensor([[9.9961e-01, 3.8897e-04],\n",
      "        [8.5534e-01, 1.4466e-01]])\n",
      "tensor([[9.9961e-01, 3.9387e-04],\n",
      "        [8.6611e-01, 1.3389e-01]])\n",
      "tensor([[9.9960e-01, 3.9860e-04],\n",
      "        [8.7653e-01, 1.2347e-01]])\n",
      "tensor([[9.9960e-01, 4.0317e-04],\n",
      "        [8.8658e-01, 1.1342e-01]])\n",
      "tensor([[9.9959e-01, 4.0757e-04],\n",
      "        [8.9625e-01, 1.0375e-01]])\n",
      "tensor([[9.9959e-01, 4.1180e-04],\n",
      "        [9.0554e-01, 9.4457e-02]])\n",
      "tensor([[9.9958e-01, 4.1584e-04],\n",
      "        [9.1444e-01, 8.5562e-02]])\n",
      "tensor([[9.9958e-01, 4.1970e-04],\n",
      "        [9.2293e-01, 7.7069e-02]])\n",
      "tensor([[9.9958e-01, 4.2338e-04],\n",
      "        [9.3101e-01, 6.8988e-02]])\n",
      "tensor([[9.9957e-01, 4.2686e-04],\n",
      "        [9.3867e-01, 6.1326e-02]])\n",
      "tensor([[9.9957e-01, 4.3015e-04],\n",
      "        [9.4591e-01, 5.4089e-02]])\n",
      "tensor([[9.9957e-01, 4.3325e-04],\n",
      "        [9.5271e-01, 4.7287e-02]])\n",
      "tensor([[9.9956e-01, 4.3614e-04],\n",
      "        [9.5908e-01, 4.0924e-02]])\n",
      "tensor([[9.9956e-01, 4.3883e-04],\n",
      "        [9.6499e-01, 3.5007e-02]])\n",
      "tensor([[9.9956e-01, 4.4132e-04],\n",
      "        [9.7046e-01, 2.9543e-02]])\n",
      "tensor([[9.9956e-01, 4.4359e-04],\n",
      "        [9.7546e-01, 2.4535e-02]])\n",
      "tensor([[9.9955e-01, 4.4566e-04],\n",
      "        [9.8001e-01, 1.9990e-02]])\n",
      "tensor([[9.9955e-01, 4.4752e-04],\n",
      "        [9.8409e-01, 1.5911e-02]])\n",
      "tensor([[9.9955e-01, 4.4916e-04],\n",
      "        [9.8770e-01, 1.2303e-02]])\n",
      "tensor([[9.9955e-01, 4.5058e-04],\n",
      "        [9.9083e-01, 9.1687e-03]])\n",
      "tensor([[9.9955e-01, 4.5179e-04],\n",
      "        [9.9349e-01, 6.5114e-03]])\n",
      "tensor([[9.9955e-01, 4.5278e-04],\n",
      "        [9.9567e-01, 4.3338e-03]])\n",
      "tensor([[9.9955e-01, 4.5355e-04],\n",
      "        [9.9736e-01, 2.6378e-03]])\n",
      "tensor([[9.9955e-01, 4.5410e-04],\n",
      "        [9.9857e-01, 1.4253e-03]])\n",
      "tensor([[9.9955e-01, 4.5443e-04],\n",
      "        [9.9930e-01, 6.9729e-04]])\n",
      "tensor([[9.9954e-01, 4.5455e-04],\n",
      "        [9.9955e-01, 4.5455e-04]])\n"
     ]
    }
   ],
   "source": [
    "q_one_step_mats = [_get_prior_distribution_transition_mat(t)\n",
    "                            for t in range(0, T)]\n",
    "q_onestep_mats = torch.stack(q_one_step_mats, axis=0).to('cpu', non_blocking=True)\n",
    "assert q_onestep_mats.shape == (T,\n",
    "                                    2,\n",
    "                                    2)\n",
    "\n",
    "# Construct transition matrices for q(x_t|x_start)\n",
    "q_mat_t = q_onestep_mats[0]\n",
    "q_mats = [q_mat_t]\n",
    "for t in range(1, T):\n",
    "    # Q_{1...t} = Q_{1 ... t-1} Q_t = Q_1 Q_2 ... Q_t\n",
    "    q_mat_t = torch.tensordot(q_mat_t, q_onestep_mats[t],\n",
    "                            dims=[[1], [0]])\n",
    "    q_mats.append(q_mat_t)\n",
    "q_mats = torch.stack(q_mats, axis=0)\n",
    "\n",
    "for t in range(0, T, 1):\n",
    "    print(q_mats[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d3pm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

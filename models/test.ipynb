{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "nodes = [(0, {'pos': (0.1, 0.65)}),\n",
    "         (1, {'pos': (0.05, 0.05)}), \n",
    "         (2, {'pos': (0.2, 0.15)}), \n",
    "         (3, {'pos': (0.55, 0.05)}),\n",
    "         (4, {'pos': (0.8, 0.05)}),\n",
    "         (5, {'pos': (0.9, 0.1)}),\n",
    "         (6, {'pos': (0.75, 0.15)}),\n",
    "         (7, {'pos': (0.5, 0.2)}),\n",
    "         (8, {'pos': (0.3, 0.3)}),\n",
    "         (9, {'pos': (0.2, 0.3)}),\n",
    "         (10, {'pos': (0.3, 0.4)}),\n",
    "         (11, {'pos': (0.65, 0.35)}),\n",
    "         (12, {'pos': (0.8, 0.5)}),\n",
    "         (13, {'pos': (0.5, 0.5)}),\n",
    "         (14, {'pos': (0.4, 0.65)}),\n",
    "         (15, {'pos': (0.15, 0.6)}),\n",
    "         (16, {'pos': (0.3, 0.7)}),\n",
    "         (17, {'pos': (0.5, 0.7)}),\n",
    "         (18, {'pos': (0.8, 0.8)}),\n",
    "         (19, {'pos': (0.4, 0.8)}),\n",
    "         (20, {'pos': (0.25, 0.85)}),\n",
    "         (21, {'pos': (0.1, 0.9)}),\n",
    "         (22, {'pos': (0.2, 0.95)}),\n",
    "         (23, {'pos': (0.45, 0.9)}),\n",
    "         (24, {'pos': (0.95, 0.95)}),\n",
    "         (25, {'pos': (0.9, 0.4)}),\n",
    "         (26, {'pos': (0.95, 0.05)})]\n",
    "edges = [(0, 21), (0, 1), (0, 15), (21, 22), (22, 20), (20, 23), (23, 24), (24, 18), (19, 14), (14, 15), (15, 16), (16, 20), (19, 20), (19, 17), (14, 17), (14, 16), (17, 18), (12, 18), (12, 13), (13, 14), (10, 14), (1, 15), (9, 15), (1, 9), (1, 2), (11, 12), (9, 10), (3, 7), (2, 3), (7, 8), (8, 9), (8, 10), (10, 11), (8, 11), (6, 11), (3, 4), (4, 5), (4, 6), (5, 6), (24, 25), (12, 25), (5, 25), (11, 25), (5, 26)]\n",
    "\n",
    "def visualize_predictions(samples, ground_truth_hist, ground_truth_fut, num_samples=5):\n",
    "        \"\"\"\n",
    "        Visualize the predictions of the model along with ground truth data.\n",
    "\n",
    "        :param samples: A list of predicted edge indices.\n",
    "        :param ground_truth_hist: A list of actual history edge indices.\n",
    "        :param ground_truth_fut: A list of actual future edge indices.\n",
    "        :param num_samples: Number of samples to visualize.\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        import networkx as nx\n",
    "        '''save_dir = f'{os.path.join(model_dir, f'{exp_name}', 'plots')}'\n",
    "        os.makedirs(save_dir, exist_ok=True)'''\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(nodes)\n",
    "        all_edges = {tuple(edges[idx]) for idx in range(len(edges))}\n",
    "        G.add_edges_from(all_edges)\n",
    "        \n",
    "        pos = nx.get_node_attributes(G, 'pos')  # Retrieve node positions stored in node attributes\n",
    "\n",
    "        for i in range(min(num_samples, len(samples))):\n",
    "            plt.figure(figsize=(18, 8))            \n",
    "\n",
    "            for plot_num, (title, edge_indices) in enumerate([\n",
    "                ('Ground Truth History', ground_truth_hist[i]),\n",
    "                ('Ground Truth Future', ground_truth_fut[i]),\n",
    "                ('Predicted Future', samples[i])\n",
    "            ]):\n",
    "                plt.subplot(1, 3, plot_num + 1)\n",
    "                plt.title(title)\n",
    "                subgraph_edges = {tuple(edges[idx]) for idx in edge_indices if idx < len(edges)}\n",
    "\n",
    "                # Draw all edges as muted gray\n",
    "                nx.draw_networkx_edges(G, pos, edgelist=all_edges, width=0.5, alpha=0.3, edge_color='gray')\n",
    "\n",
    "                # Draw subgraph edges with specified color\n",
    "                edge_color = 'gray' if plot_num == 0 else 'green' if plot_num == 1 else 'red'\n",
    "                node_color = 'skyblue'# if plot_num == 0 else 'lightgreen' if plot_num == 1 else 'orange'\n",
    "                nx.draw_networkx_nodes(G, pos, node_color=node_color, node_size=500)\n",
    "                nx.draw_networkx_edges(G, pos, edgelist=subgraph_edges, width=3, alpha=1.0, edge_color=edge_color)\n",
    "                nx.draw_networkx_labels(G, pos, font_size=15)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [[12, 13, 16], [4, 3], [21, 10], [37, 34]]\n",
    "ground_truth_hist = [[1, 0, 3, 4, 5], [32, 25, 17, 7, 6], [11, 15, 20, 26, 23], [22, 30, 29, 27, 35]] \n",
    "ground_truth_fut = [[6, 7], [5, 4], [24, 28], [36, 43]]\n",
    "\n",
    "visualize_predictions(samples, ground_truth_hist, ground_truth_fut, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from tqdm import tqdm\n",
    "TDRIVE_PATH = '/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/data/tdrive.h5'\n",
    "def load_new_format(new_file_path):\n",
    "    paths = []\n",
    "\n",
    "    with h5py.File(new_file_path, 'r') as new_hf:\n",
    "        node_coordinates = new_hf['graph']['node_coordinates'][:]\n",
    "        edges = new_hf['graph']['edges'][:]\n",
    "        \n",
    "        for i in tqdm(new_hf['trajectories'].keys()):\n",
    "                path_group = new_hf['trajectories'][i]\n",
    "                path = {attr: path_group[attr][()] for attr in path_group.keys()}\n",
    "                if 'edge_orientation' in path:\n",
    "                    path['edge_orientations'] = path.pop('edge_orientation')\n",
    "                paths.append(path)\n",
    "    nodes = [(i, {'pos': tuple(pos)}) for i, pos in enumerate(node_coordinates)]\n",
    "    \n",
    "    return paths, nodes, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths, nodes, edges = load_new_format(TDRIVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "lr = 0.01\n",
    "num_epochs = 50000\n",
    "learning_rate_warmup_steps = 2500\n",
    "lr_decay_parameter = 0.9998\n",
    "\n",
    "# Learning rate schedule\n",
    "def lr_lambda(epoch):\n",
    "    if epoch < learning_rate_warmup_steps:\n",
    "        return 1.0\n",
    "    else:\n",
    "        decay_lr = lr_decay_parameter ** (epoch - learning_rate_warmup_steps)\n",
    "        return max(decay_lr, 2e-5 / lr)\n",
    "\n",
    "\n",
    "# Calculate learning rates for each epoch\n",
    "learning_rates = [lr * lr_lambda(epoch) for epoch in range(num_epochs)]\n",
    "\n",
    "# Plot the learning rates\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(learning_rates, label='Learning Rate')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')#\n",
    "plt.yscale('log')\n",
    "plt.title('Learning Rate Schedule Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [(0, {'pos': (0.1, 0.65)}),\n",
    "         (1, {'pos': (0.05, 0.05)}), \n",
    "         (2, {'pos': (0.2, 0.15)}), \n",
    "         (3, {'pos': (0.55, 0.05)}),\n",
    "         (4, {'pos': (0.8, 0.05)}),\n",
    "         (5, {'pos': (0.9, 0.1)}),\n",
    "         (6, {'pos': (0.75, 0.15)}),\n",
    "         (7, {'pos': (0.5, 0.2)}),\n",
    "         (8, {'pos': (0.3, 0.3)}),\n",
    "         (9, {'pos': (0.2, 0.3)}),\n",
    "         (10, {'pos': (0.3, 0.4)}),\n",
    "         (11, {'pos': (0.65, 0.35)}),\n",
    "         (12, {'pos': (0.8, 0.5)}),\n",
    "         (13, {'pos': (0.5, 0.5)}),\n",
    "         (14, {'pos': (0.4, 0.65)}),\n",
    "         (15, {'pos': (0.15, 0.6)}),\n",
    "         (16, {'pos': (0.3, 0.7)}),\n",
    "         (17, {'pos': (0.5, 0.7)}),\n",
    "         (18, {'pos': (0.8, 0.8)}),\n",
    "         (19, {'pos': (0.4, 0.8)}),\n",
    "         (20, {'pos': (0.25, 0.85)}),\n",
    "         (21, {'pos': (0.1, 0.9)}),\n",
    "         (22, {'pos': (0.2, 0.95)}),\n",
    "         (23, {'pos': (0.45, 0.9)}),\n",
    "         (24, {'pos': (0.95, 0.95)}),\n",
    "         (25, {'pos': (0.9, 0.4)}),\n",
    "         (26, {'pos': (0.95, 0.05)}),\n",
    "         (27, {'pos': (0.75, 1.0)})]\n",
    "edges = [(0, 21), (0, 1), (0, 15), (21, 22), (22, 20), (20, 23), (23, 24), (24, 18), (19, 14), (14, 15), (15, 16), (16, 20), (19, 20), (19, 17), (14, 17), (14, 16), (17, 18), (12, 18), (12, 13), (13, 14), (10, 14), (1, 15), (9, 15), (1, 9), (1, 2), (11, 12), (9, 10), (3, 7), (2, 3), (7, 8), (8, 9), (8, 10), (10, 11), (8, 11), (6, 11), (3, 4), (4, 5), (4, 6), (5, 6), (24, 25), (12, 25), (5, 25), (11, 25), (5, 26), (23, 27), (24, 27)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "res = {'sample_list': [tensor([ 0,  2,  7, 11, 15, 20, 23, 24, 26, 29, 30, 34, 35, 36, 37, 39, 45]), tensor([ 0,  2,  7, 23, 24, 26, 29, 30, 34, 35, 36, 37, 39, 45]), tensor([ 0,  2, 23, 24, 30, 34, 37]), tensor([ 0,  2, 23, 24, 26, 29, 30, 34, 36, 37]), tensor([ 0,  2, 23, 24, 26, 29, 30, 34, 35, 36, 37]), tensor([ 0,  2, 23, 24, 30]), tensor([ 4, 12, 17, 18, 19, 21, 24, 40, 41]), tensor([ 0,  2, 23, 24, 26, 29, 30, 34, 35, 36, 37, 45]), tensor([ 0,  2, 23, 24, 30, 34, 36, 37]), tensor([ 4, 12, 17, 18, 21, 24, 40, 41]), tensor([ 0,  2, 23, 24, 26, 29, 30, 34, 36, 37]), tensor([ 4, 12, 17, 18, 19, 21, 24, 40, 41]), tensor([ 0,  2,  7, 11, 15, 20, 23, 24, 26, 29, 30, 34, 35, 36, 37, 39, 45]), tensor([ 0,  2, 23, 24, 26, 29, 30, 34, 35, 36, 37]), tensor([ 4, 12, 17, 18, 19, 21, 24, 40, 41]), tensor([ 4, 12, 17, 18, 19, 21, 24, 40, 41]), tensor([ 0,  2,  7, 23, 24, 26, 29, 30, 34, 35, 36, 37, 39, 45]), tensor([ 0,  2, 23, 24, 30, 34, 37]), tensor([ 0,  2, 23, 24, 26, 29, 30, 34, 36, 37]), tensor([ 0,  2, 23, 24, 26, 29, 30, 34, 36, 37])], 'ground_truth_hist': [tensor([[43, 36, 37, 34, 32]]), tensor([[23, 26, 20, 14, 16]]), tensor([[40, 18, 19, 14, 13]]), tensor([[ 5, 12,  8, 20, 32]]), tensor([[39, 41, 36, 35, 27]]), tensor([[44,  5, 11, 10, 22]]), tensor([[24, 28, 35, 36, 41]]), tensor([[ 9, 19, 18, 40, 41]]), tensor([[35, 27, 29, 30, 22]]), tensor([[39, 42, 33, 30, 22]]), tensor([[41, 40, 18, 19,  8]]), tensor([[ 0,  3,  4, 11, 15]]), tensor([[38, 34, 25, 18, 19]]), tensor([[ 7, 16, 13,  8, 20]]), tensor([[ 3,  4, 11, 15, 19]]), tensor([[10, 15, 14, 16, 17]]), tensor([[26, 32, 34, 38, 41]]), tensor([[45,  7, 17, 25, 33]]), tensor([[37, 34, 32, 26, 22]]), tensor([[ 2, 22, 26, 32, 34]])], 'ground_truth_fut': [tensor([[20, 15]]), tensor([[ 7, 45]]), tensor([[12,  4]]), tensor([[34, 37]]), tensor([[29, 30]]), tensor([[23, 24]]), tensor([[40, 17]]), tensor([[36, 35]]), tensor([[2, 0]]), tensor([[21, 24]]), tensor([[12,  4]]), tensor([[19, 18]]), tensor([[15, 11]]), tensor([[26, 23]]), tensor([[18, 40]]), tensor([[40, 41]]), tensor([[39, 45]]), tensor([[30, 23]]), tensor([[2, 0]]), tensor([[37, 36]])]}\n",
    "samples = res['sample_list']\n",
    "one_hot_samples = [torch.zeros(len(edges)) for _ in range(len(samples))]\n",
    "ground_truth_fut = res['ground_truth_fut']\n",
    "one_hot_futures = [torch.zeros(len(edges)) for _ in range(len(ground_truth_fut))]\n",
    "for i, one_hot_sample in enumerate(one_hot_samples):\n",
    "    for edge_index, edge in enumerate(edges):\n",
    "        if edge_index in samples[i]:\n",
    "            one_hot_sample[edges.index(edge)] = 1\n",
    "for i, one_hot_fut in enumerate(one_hot_futures):\n",
    "    for edge_index, edge in enumerate(edges):\n",
    "        if edge_index in ground_truth_fut[i]:\n",
    "            one_hot_fut[edges.index(edge)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import F1Score\n",
    "metric = F1Score(task='binary', average='micro', num_classes=2)\n",
    "f1 = metric(torch.cat(one_hot_samples), torch.cat(one_hot_futures))\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With 1 sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {'sample_list': [tensor([17, 37, 40]), tensor([ 0,  1,  2,  6,  7, 16, 19, 20, 21, 26, 29, 38, 39, 45]), tensor([15, 18, 19]), tensor([ 0,  1,  2, 16, 20, 21, 26]), tensor([37]), tensor([10, 11, 18, 32, 36]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([11, 18, 32, 36, 39, 40]), tensor([ 0,  1,  2, 13, 21, 24, 27, 28, 29, 30, 34]), tensor([16, 17, 23, 24, 34, 37, 40, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([18, 40]), tensor([15, 18, 19]), tensor([11, 18, 32, 36, 40]), tensor([40, 41]), tensor([15, 18, 19]), tensor([11, 32, 36, 39, 40]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([18]), tensor([15, 18, 19, 45])], 'ground_truth_hist': [tensor([[24, 28, 35, 36, 41]]), tensor([[23, 26, 20, 14, 16]]), tensor([[ 7, 16, 13,  8, 20]]), tensor([[ 5, 12,  8, 20, 32]]), tensor([[43, 36, 37, 34, 32]]), tensor([[38, 34, 25, 18, 19]]), tensor([[35, 27, 29, 30, 22]]), tensor([[41, 40, 18, 19,  8]]), tensor([[39, 42, 33, 30, 22]]), tensor([[39, 41, 36, 35, 27]]), tensor([[37, 34, 32, 26, 22]]), tensor([[40, 18, 19, 14, 13]]), tensor([[ 0,  3,  4, 11, 15]]), tensor([[ 9, 19, 18, 40, 41]]), tensor([[10, 15, 14, 16, 17]]), tensor([[ 3,  4, 11, 15, 19]]), tensor([[26, 32, 34, 38, 41]]), tensor([[ 2, 22, 26, 32, 34]]), tensor([[44,  5, 11, 10, 22]]), tensor([[45,  7, 17, 25, 33]])], 'ground_truth_fut': [tensor([[40, 17]]), tensor([[ 7, 45]]), tensor([[26, 23]]), tensor([[34, 37]]), tensor([[20, 15]]), tensor([[15, 11]]), tensor([[2, 0]]), tensor([[12,  4]]), tensor([[21, 24]]), tensor([[29, 30]]), tensor([[2, 0]]), tensor([[12,  4]]), tensor([[19, 18]]), tensor([[36, 35]]), tensor([[40, 41]]), tensor([[18, 40]]), tensor([[39, 45]]), tensor([[37, 36]]), tensor([[23, 24]]), tensor([[30, 23]])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = res['sample_list']\n",
    "one_hot_samples = [torch.zeros(len(edges)) for _ in range(len(samples))]\n",
    "ground_truth_fut = res['ground_truth_fut']\n",
    "one_hot_futures = [torch.zeros(len(edges)) for _ in range(len(ground_truth_fut))]\n",
    "for i, one_hot_sample in enumerate(one_hot_samples):\n",
    "    for edge_index, edge in enumerate(edges):\n",
    "        if edge_index in samples[i]:\n",
    "            one_hot_sample[edges.index(edge)] = 1\n",
    "for i, one_hot_fut in enumerate(one_hot_futures):\n",
    "    for edge_index, edge in enumerate(edges):\n",
    "        if edge_index in ground_truth_fut[i]:\n",
    "            one_hot_fut[edges.index(edge)] = 1\n",
    "            \n",
    "metric = F1Score(task='binary', average='micro', num_classes=2)\n",
    "f1 = metric(torch.cat(one_hot_samples), torch.cat(one_hot_futures))\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With 10 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {'sample_list': [[tensor([17, 37, 40]), tensor([17, 37, 40]), tensor([17, 37, 40]), tensor([17, 37, 40]), tensor([17, 37, 40]), tensor([17, 37, 40]), tensor([17, 37, 40]), tensor([17, 37, 40]), tensor([17, 37, 40]), tensor([17, 37, 40])], [tensor([ 0,  1,  2,  6,  7, 16, 19, 20, 21, 26, 29, 38, 39, 45]), tensor([ 0,  1,  2,  6,  7, 16, 19, 20, 21, 26, 29, 38, 39, 45]), tensor([ 0,  1,  2,  6,  7, 16, 19, 20, 21, 26, 29, 38, 39, 45]), tensor([ 0,  1,  2,  6,  7, 16, 19, 20, 21, 26, 29, 38, 39, 45]), tensor([ 0,  1,  2,  6,  7, 16, 19, 20, 21, 26, 29, 38, 39, 45]), tensor([ 0,  1,  2,  6,  7, 16, 19, 20, 21, 26, 29, 38, 39, 45]), tensor([ 0,  1,  2,  6,  7, 16, 19, 20, 21, 26, 29, 38, 39, 45]), tensor([ 0,  1,  2,  6,  7, 16, 19, 20, 21, 26, 29, 38, 39, 45]), tensor([ 0,  1,  2,  6,  7, 16, 19, 20, 21, 26, 29, 38, 39, 45]), tensor([ 0,  1,  2,  6,  7, 16, 19, 20, 21, 26, 29, 38, 39, 45])], [tensor([15, 18, 19]), tensor([15, 18, 19]), tensor([15, 18, 19]), tensor([15, 18, 19]), tensor([15, 18, 19]), tensor([15, 18, 19]), tensor([15, 18, 19]), tensor([15, 18, 19]), tensor([15, 18, 19]), tensor([15, 18, 19])], [tensor([ 0,  1,  2, 16, 20, 21, 26]), tensor([ 0,  1,  2, 16, 20, 21, 26]), tensor([ 0,  1,  2, 16, 20, 21, 26]), tensor([ 0,  1,  2, 16, 20, 21, 26]), tensor([ 0,  1,  2, 16, 20, 21, 26]), tensor([ 0,  1,  2, 16, 20, 21, 26]), tensor([ 0,  1,  2, 16, 20, 21, 26]), tensor([ 0,  1,  2, 16, 20, 21, 26]), tensor([ 0,  1,  2, 16, 20, 21, 26]), tensor([ 0,  1,  2, 16, 20, 21, 26])], [tensor([37]), tensor([37]), tensor([37]), tensor([37]), tensor([37]), tensor([37]), tensor([37]), tensor([37]), tensor([37]), tensor([37])], [tensor([10, 11, 18, 32, 36]), tensor([10, 11, 18, 32, 36]), tensor([10, 11, 18, 32, 36]), tensor([10, 11, 18, 32, 36]), tensor([10, 11, 18, 32, 36]), tensor([10, 11, 18, 32, 36]), tensor([10, 11, 18, 32, 36]), tensor([10, 11, 18, 32, 36]), tensor([10, 11, 18, 32, 36]), tensor([10, 11, 18, 32, 36])], [tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45])], [tensor([11, 18, 32, 36, 39, 40]), tensor([11, 18, 32, 36, 39, 40]), tensor([11, 18, 32, 36, 39, 40]), tensor([11, 18, 32, 36, 39, 40]), tensor([11, 18, 32, 36, 39, 40]), tensor([11, 18, 32, 36, 39, 40]), tensor([11, 18, 32, 36, 39, 40]), tensor([11, 18, 32, 36, 39, 40]), tensor([11, 18, 32, 36, 39, 40]), tensor([11, 18, 32, 36, 39, 40])], [tensor([ 0,  1,  2, 13, 21, 24, 27, 28, 29, 30, 34]), tensor([ 0,  1,  2, 13, 21, 24, 27, 28, 29, 30, 34]), tensor([ 0,  1,  2, 13, 21, 24, 27, 28, 29, 30, 34]), tensor([ 0,  1,  2, 13, 21, 24, 27, 28, 29, 30, 34]), tensor([ 0,  1,  2, 13, 21, 24, 27, 28, 29, 30, 34]), tensor([ 0,  1,  2, 13, 21, 24, 27, 28, 29, 30, 34]), tensor([ 0,  1,  2, 13, 21, 24, 27, 28, 29, 30, 34]), tensor([ 0,  1,  2, 13, 21, 24, 27, 28, 29, 30, 34]), tensor([ 0,  1,  2, 13, 21, 24, 27, 28, 29, 30, 34]), tensor([ 0,  1,  2, 13, 21, 24, 27, 28, 29, 30, 34])], [tensor([16, 17, 23, 24, 34, 37, 40, 43, 44, 45]), tensor([16, 17, 23, 24, 34, 37, 40, 43, 44, 45]), tensor([16, 17, 23, 24, 34, 37, 40, 43, 44, 45]), tensor([16, 17, 23, 24, 34, 37, 40, 43, 44, 45]), tensor([16, 17, 23, 24, 34, 37, 40, 43, 44, 45]), tensor([16, 17, 23, 24, 34, 37, 40, 43, 44, 45]), tensor([16, 17, 23, 24, 34, 37, 40, 43, 44, 45]), tensor([16, 17, 23, 24, 34, 37, 40, 43, 44, 45]), tensor([16, 17, 23, 24, 34, 37, 40, 43, 44, 45]), tensor([16, 17, 23, 24, 34, 37, 40, 43, 44, 45])], [tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45])], [tensor([18, 40]), tensor([18, 40]), tensor([18, 40]), tensor([18, 40]), tensor([18, 40]), tensor([18, 40]), tensor([18, 40]), tensor([18, 40]), tensor([18, 40]), tensor([18, 40])], [tensor([15, 18, 19]), tensor([15, 18, 19]), tensor([15, 18, 19]), tensor([15, 18, 19]), tensor([15, 18, 19]), tensor([15, 18, 19]), tensor([15, 18, 19]), tensor([15, 18, 19]), tensor([15, 18, 19]), tensor([15, 18, 19])], [tensor([11, 18, 32, 36, 40]), tensor([11, 18, 32, 36, 40]), tensor([11, 18, 32, 36, 40]), tensor([11, 18, 32, 36, 40]), tensor([11, 18, 32, 36, 40]), tensor([11, 18, 32, 36, 40]), tensor([11, 18, 32, 36, 40]), tensor([11, 18, 32, 36, 40]), tensor([11, 18, 32, 36, 40]), tensor([11, 18, 32, 36, 40])], [tensor([40, 41]), tensor([40, 41]), tensor([40, 41]), tensor([40, 41]), tensor([40, 41]), tensor([40, 41]), tensor([40, 41]), tensor([40, 41]), tensor([40, 41]), tensor([40, 41])], [tensor([15, 18, 19]), tensor([15, 18, 19]), tensor([15, 18, 19]), tensor([15, 18, 19]), tensor([15, 18, 19]), tensor([15, 18, 19]), tensor([15, 18, 19]), tensor([15, 18, 19]), tensor([15, 18, 19]), tensor([15, 18, 19])], [tensor([11, 32, 36, 39, 40]), tensor([11, 32, 36, 39, 40]), tensor([11, 32, 36, 39, 40]), tensor([11, 32, 36, 39, 40]), tensor([11, 32, 36, 39, 40]), tensor([11, 32, 36, 39, 40]), tensor([11, 32, 36, 39, 40]), tensor([11, 32, 36, 39, 40]), tensor([11, 32, 36, 39, 40]), tensor([11, 32, 36, 39, 40])], [tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45])], [tensor([18]), tensor([18]), tensor([18]), tensor([18]), tensor([18]), tensor([18]), tensor([18]), tensor([18]), tensor([18]), tensor([18])], [tensor([15, 18, 19, 45]), tensor([15, 18, 19, 45]), tensor([15, 18, 19, 45]), tensor([15, 18, 19, 45]), tensor([15, 18, 19, 45]), tensor([15, 18, 19, 45]), tensor([15, 18, 19, 45]), tensor([15, 18, 19, 45]), tensor([15, 18, 19, 45]), tensor([15, 18, 19, 45])]], 'ground_truth_hist': [tensor([[24, 28, 35, 36, 41]]), tensor([[23, 26, 20, 14, 16]]), tensor([[ 7, 16, 13,  8, 20]]), tensor([[ 5, 12,  8, 20, 32]]), tensor([[43, 36, 37, 34, 32]]), tensor([[38, 34, 25, 18, 19]]), tensor([[35, 27, 29, 30, 22]]), tensor([[41, 40, 18, 19,  8]]), tensor([[39, 42, 33, 30, 22]]), tensor([[39, 41, 36, 35, 27]]), tensor([[37, 34, 32, 26, 22]]), tensor([[40, 18, 19, 14, 13]]), tensor([[ 0,  3,  4, 11, 15]]), tensor([[ 9, 19, 18, 40, 41]]), tensor([[10, 15, 14, 16, 17]]), tensor([[ 3,  4, 11, 15, 19]]), tensor([[26, 32, 34, 38, 41]]), tensor([[ 2, 22, 26, 32, 34]]), tensor([[44,  5, 11, 10, 22]]), tensor([[45,  7, 17, 25, 33]])], 'ground_truth_fut': [tensor([[40, 17]]), tensor([[ 7, 45]]), tensor([[26, 23]]), tensor([[34, 37]]), tensor([[20, 15]]), tensor([[15, 11]]), tensor([[2, 0]]), tensor([[12,  4]]), tensor([[21, 24]]), tensor([[29, 30]]), tensor([[2, 0]]), tensor([[12,  4]]), tensor([[19, 18]]), tensor([[36, 35]]), tensor([[40, 41]]), tensor([[18, 40]]), tensor([[39, 45]]), tensor([[37, 36]]), tensor([[23, 24]]), tensor([[30, 23]])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [res['sample_list'][i][0] for i in range(len(res['sample_list']))]\n",
    "print(samples)\n",
    "one_hot_samples = [torch.zeros(len(edges)) for _ in range(len(samples))]\n",
    "ground_truth_fut = res['ground_truth_fut']\n",
    "one_hot_futures = [torch.zeros(len(edges)) for _ in range(len(ground_truth_fut))]\n",
    "for i, one_hot_sample in enumerate(one_hot_samples):\n",
    "    for edge_index, edge in enumerate(edges):\n",
    "        if edge_index in samples[i]:\n",
    "            one_hot_sample[edges.index(edge)] = 1\n",
    "for i, one_hot_fut in enumerate(one_hot_futures):\n",
    "    for edge_index, edge in enumerate(edges):\n",
    "        if edge_index in ground_truth_fut[i]:\n",
    "            one_hot_fut[edges.index(edge)] = 1\n",
    "            \n",
    "metric = F1Score(task='binary', average='macro', num_classes=2)\n",
    "f1_tot = 0\n",
    "for i in range(len(res['sample_list'])):\n",
    "    f1 = metric(one_hot_samples[i], one_hot_futures[i])\n",
    "    f1_tot += f1\n",
    "f1 = f1_tot / len(res['sample_list'])\n",
    "print(one_hot_samples[0])\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_10 = [tensor([17, 37, 40]), tensor([ 0,  1,  2,  6,  7, 16, 19, 20, 21, 26, 29, 38, 39, 45]), tensor([15, 18, 19]), tensor([ 0,  1,  2, 16, 20, 21, 26]), tensor([37]), tensor([10, 11, 18, 32, 36]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([11, 18, 32, 36, 39, 40]), tensor([ 0,  1,  2, 13, 21, 24, 27, 28, 29, 30, 34]), tensor([16, 17, 23, 24, 34, 37, 40, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([18, 40]), tensor([15, 18, 19]), tensor([11, 18, 32, 36, 40]), tensor([40, 41]), tensor([15, 18, 19]), tensor([11, 32, 36, 39, 40]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([18]), tensor([15, 18, 19, 45])]\n",
    "sample_1 = [tensor([17, 37, 40]), tensor([ 0,  1,  2,  6,  7, 16, 19, 20, 21, 26, 29, 38, 39, 45]), tensor([15, 18, 19]), tensor([ 0,  1,  2, 16, 20, 21, 26]), tensor([37]), tensor([10, 11, 18, 32, 36]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([11, 18, 32, 36, 39, 40]), tensor([ 0,  1,  2, 13, 21, 24, 27, 28, 29, 30, 34]), tensor([16, 17, 23, 24, 34, 37, 40, 43, 44, 45]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([18, 40]), tensor([15, 18, 19]), tensor([11, 18, 32, 36, 40]), tensor([40, 41]), tensor([15, 18, 19]), tensor([11, 32, 36, 39, 40]), tensor([ 0,  1,  2,  6,  7,  8,  9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 34,\n",
    "        37, 40, 41, 42, 43, 44, 45]), tensor([18]), tensor([15, 18, 19, 45])]\n",
    "for j in range(10):\n",
    "        sample_10 = [res['sample_list'][i][j] for i in range(len(res['sample_list']))]\n",
    "        equal = 0\n",
    "        for i in range(len(sample_10)):\n",
    "                if sample_10[i].equal(sample_1[i]):\n",
    "                        equal += 1\n",
    "                \n",
    "        print(f\"Ratio of equal samples for sample {j}:\", equal/len(sample_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {'sample_list': [tensor([11, 12, 18, 19]), tensor([18, 19]), tensor([18, 19]), tensor([35, 36]), tensor([11, 12]), tensor([11, 12]), tensor([18, 19]), tensor([41]), tensor([24, 35, 36]), tensor([24, 35, 36]), tensor([11, 12, 19]), tensor([20, 21, 40, 41]), tensor([20, 21, 40, 41]), tensor([20, 21, 41]), tensor([35, 36]), tensor([ 0,  2, 40, 41]), tensor([11, 12]), tensor([35, 36]), tensor([11, 12]), tensor([36])],\n",
    "\n",
    "\n",
    "'ground_truth_hist': [tensor([[45,  7, 17, 25, 33]]), tensor([[ 7, 16, 13,  8, 20]]), tensor([[ 0,  3,  4, 11, 15]]), tensor([[43, 36, 37, 34, 32]]), tensor([[40, 18, 19, 14, 13]]), tensor([[41, 40, 18, 19,  8]]), tensor([[10, 15, 14, 16, 17]]), tensor([[ 5, 12,  8, 20, 32]]), tensor([[ 9, 19, 18, 40, 41]]), tensor([[23, 26, 20, 14, 16]]), tensor([[ 3,  4, 11, 15, 19]]), tensor([[37, 34, 32, 26, 22]]), tensor([[35, 27, 29, 30, 22]]), tensor([[39, 42, 33, 30, 22]]), tensor([[24, 28, 35, 36, 41]]), tensor([[ 2, 22, 26, 32, 34]]), tensor([[39, 41, 36, 35, 27]]), tensor([[26, 32, 34, 38, 41]]), tensor([[38, 34, 25, 18, 19]]), tensor([[44,  5, 11, 10, 22]])],\n",
    "\n",
    "\n",
    "'ground_truth_fut': [tensor([[30, 23]]), tensor([[26, 23]]), tensor([[19, 18]]), tensor([[20, 15]]), tensor([[12,  4]]), tensor([[12,  4]]), tensor([[40, 41]]), tensor([[34, 37]]), tensor([[36, 35]]), tensor([[ 7, 45]]), tensor([[18, 40]]), tensor([[2, 0]]), tensor([[2, 0]]), tensor([[21, 24]]), tensor([[40, 17]]), tensor([[37, 36]]), tensor([[29, 30]]), tensor([[39, 45]]), tensor([[15, 11]]), tensor([[23, 24]])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = res['sample_list']\n",
    "one_hot_samples = [torch.zeros(len(edges)) for _ in range(len(samples))]\n",
    "ground_truth_fut = res['ground_truth_fut']\n",
    "one_hot_futures = [torch.zeros(len(edges)) for _ in range(len(ground_truth_fut))]\n",
    "for i, one_hot_sample in enumerate(one_hot_samples):\n",
    "    for edge_index, edge in enumerate(edges):\n",
    "        if edge_index in samples[i]:\n",
    "            one_hot_sample[edges.index(edge)] = 1\n",
    "for i, one_hot_fut in enumerate(one_hot_futures):\n",
    "    for edge_index, edge in enumerate(edges):\n",
    "        if edge_index in ground_truth_fut[i]:\n",
    "            one_hot_fut[edges.index(edge)] = 1\n",
    "            \n",
    "metric = F1Score(task='binary', average='micro', num_classes=2)\n",
    "f1 = metric(torch.cat(one_hot_samples).reshape(20, 46), torch.cat(one_hot_futures).reshape(20, 46))\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cat(one_hot_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(torch.cat(one_hot_samples).reshape(20, 46)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True_Future = tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
    "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
    "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
    "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
    "         0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "Predicted_Future = tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
    "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
    "         0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
    "         0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = F1Score(task='binary', average='macro', num_classes=2)\n",
    "f1 = metric(Predicted_Future, True_Future)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {'sample_list': [tensor([], dtype=torch.int64), tensor([ 7, 22, 23]), tensor([], dtype=torch.int64), tensor([ 4,  5, 34, 36, 37]), tensor([0]), tensor([10, 11, 15, 18, 19]), tensor([0]), tensor([0]), tensor([21, 23, 39, 45]), tensor([ 0, 29, 30, 36]), tensor([0, 4]), tensor([0]), tensor([0]), tensor([17, 35, 40]), tensor([], dtype=torch.int64), tensor([0]), tensor([0]), tensor([ 4,  5, 34, 36, 37]), tensor([21, 23, 24, 39, 40, 45]), tensor([21, 30])], 'ground_truth_hist': [tensor([[24, 28, 35, 36, 41]]), tensor([[23, 26, 20, 14, 16]]), tensor([[ 7, 16, 13,  8, 20]]), tensor([[ 5, 12,  8, 20, 32]]), tensor([[43, 36, 37, 34, 32]]), tensor([[38, 34, 25, 18, 19]]), tensor([[35, 27, 29, 30, 22]]), tensor([[41, 40, 18, 19,  8]]), tensor([[39, 42, 33, 30, 22]]), tensor([[39, 41, 36, 35, 27]]), tensor([[37, 34, 32, 26, 22]]), tensor([[40, 18, 19, 14, 13]]), tensor([[ 0,  3,  4, 11, 15]]), tensor([[ 9, 19, 18, 40, 41]]), tensor([[10, 15, 14, 16, 17]]), tensor([[ 3,  4, 11, 15, 19]]), tensor([[26, 32, 34, 38, 41]]), tensor([[ 2, 22, 26, 32, 34]]), tensor([[44,  5, 11, 10, 22]]), tensor([[45,  7, 17, 25, 33]])], 'ground_truth_fut': [tensor([[40, 17]]), tensor([[ 7, 45]]), tensor([[26, 23]]), tensor([[34, 37]]), tensor([[20, 15]]), tensor([[15, 11]]), tensor([[2, 0]]), tensor([[12,  4]]), tensor([[21, 24]]), tensor([[29, 30]]), tensor([[2, 0]]), tensor([[12,  4]]), tensor([[19, 18]]), tensor([[36, 35]]), tensor([[40, 41]]), tensor([[18, 40]]), tensor([[39, 45]]), tensor([[37, 36]]), tensor([[23, 24]]), tensor([[30, 23]])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = res['sample_list']\n",
    "one_hot_samples = [torch.zeros(len(edges)) for _ in range(len(samples))]\n",
    "ground_truth_fut = res['ground_truth_fut']\n",
    "one_hot_futures = [torch.zeros(len(edges)) for _ in range(len(ground_truth_fut))]\n",
    "for i, one_hot_sample in enumerate(one_hot_samples):\n",
    "    for edge_index, edge in enumerate(edges):\n",
    "        if edge_index in samples[i]:\n",
    "            one_hot_sample[edges.index(edge)] = 1\n",
    "for i, one_hot_fut in enumerate(one_hot_futures):\n",
    "    for edge_index, edge in enumerate(edges):\n",
    "        if edge_index in ground_truth_fut[i]:\n",
    "            one_hot_fut[edges.index(edge)] = 1\n",
    "metric = F1Score(task='binary', average='macro', num_classes=2)\n",
    "f1 = metric(torch.cat(one_hot_samples), torch.cat(one_hot_futures))\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_gaussian_transition_mat(t):\n",
    "        r\"\"\"Computes transition matrix for q(x_t|x_{t-1}).\n",
    "\n",
    "        This method constructs a transition matrix Q with\n",
    "        decaying entries as a function of how far off diagonal the entry is.\n",
    "        Normalization option 1:\n",
    "        Q_{ij} =  ~ softmax(-val^2/beta_t)   if |i-j| <= transition_bands\n",
    "                    1 - \\sum_{l \\neq i} Q_{il}  if i==j.\n",
    "                    0                          else.\n",
    "\n",
    "        Normalization option 2:\n",
    "        tilde{Q}_{ij} =  softmax(-val^2/beta_t)   if |i-j| <= transition_bands\n",
    "                            0                        else.\n",
    "\n",
    "        Q_{ij} =  tilde{Q}_{ij} / sum_l{tilde{Q}_{lj}}\n",
    "\n",
    "        Args:\n",
    "            t: timestep. integer scalar (or numpy array?)\n",
    "\n",
    "        Returns:\n",
    "            Q_t: transition matrix. shape = (num_classes, num_classes).\n",
    "        \"\"\"\n",
    "        \n",
    "        num_classes = 2\n",
    "        transition_bands = num_classes - 1 # 1\n",
    "\n",
    "        betas = torch.linspace(0.9, 1.0, 1000)\n",
    "        beta_t = betas[t]\n",
    "\n",
    "        mat = torch.zeros((num_classes, num_classes),\n",
    "                        dtype=torch.float64)\n",
    "\n",
    "        # Make the values correspond to a similar type of gaussian as in the\n",
    "        # gaussian diffusion case for continuous state spaces.\n",
    "        values = torch.linspace(torch.tensor(0.), torch.tensor(num_classes-1), num_classes, dtype=torch.float64)\n",
    "        values = values * 2./ (num_classes - 1.)\n",
    "        values = values[:transition_bands+1]\n",
    "        values = -values * values / beta_t\n",
    "        \n",
    "        # To reverse the tensor 'values' starting from the second element\n",
    "        reversed_values = values[1:].flip(dims=[0])\n",
    "        # Concatenating the reversed values with the original values\n",
    "        values = torch.cat([reversed_values, values], dim=0)\n",
    "        values = F.softmax(values, dim=0)\n",
    "        values = values[transition_bands:]\n",
    "        \n",
    "        for k in range(1, transition_bands + 1):\n",
    "            off_diag = torch.full((num_classes - k,), values[k], dtype=torch.float64)\n",
    "\n",
    "            mat += torch.diag(off_diag, k)\n",
    "            mat += torch.diag(off_diag, -k)\n",
    "\n",
    "        # Add diagonal values such that rows and columns sum to one.\n",
    "        # Technically only the ROWS need to sum to one\n",
    "        # NOTE: this normalization leads to a doubly stochastic matrix,\n",
    "        # which is necessary if we want to have a uniform stationary distribution.\n",
    "        diag = 1. - mat.sum(dim=1)\n",
    "        mat += torch.diag_embed(diag)\n",
    "\n",
    "        return mat\n",
    "\n",
    "_get_gaussian_transition_mat(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_prior_distribution_transition_mat(t):\n",
    "    \"\"\"Computes transition matrix for q(x_t|x_{t-1}).\n",
    "\n",
    "    Args:\n",
    "    t: timestep. integer scalar.\n",
    "\n",
    "    Returns:\n",
    "    Q_t: transition matrix. shape = (num_classes, num_classes).\n",
    "    \"\"\"\n",
    "    betas = torch.linspace(0.001, 0.2, 1000)\n",
    "    beta_t = betas[t]\n",
    "    steps = torch.linspace(0, 1, 1000 + 1, dtype=torch.float64)\n",
    "    alpha_bar = torch.cos((steps + 0.008) / 1.008 * torch.pi / 2)\n",
    "    betas = torch.minimum(1 - alpha_bar[1:] / alpha_bar[:-1], torch.tensor(0.999))\n",
    "    beta_t = betas[t]\n",
    "    print(beta_t)\n",
    "    num_classes = 2\n",
    "    class_weights = [0.9, 0.1]\n",
    "    mat = torch.zeros((num_classes, num_classes), dtype=torch.float64)\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        for j in range(num_classes):\n",
    "            if i != j:\n",
    "                mat[i, j] = beta_t * class_weights[j]\n",
    "            else:\n",
    "                mat[i, j] = 1 - beta_t + beta_t * class_weights[j]\n",
    "    \n",
    "    return mat\n",
    "\n",
    "_get_prior_distribution_transition_mat(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def cosine_beta_schedule_discrete(timesteps, s=0.008):\n",
    "    \"\"\" Cosine schedule as proposed in https://openreview.net/forum?id=-NEXDKk8gZ. \"\"\"\n",
    "    steps = timesteps + 2\n",
    "    x = np.linspace(0, steps, steps)\n",
    "\n",
    "    alphas_cumprod = np.cos(0.5 * np.pi * ((x / steps) + s) / (1 + s)) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    alphas = (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    betas = 1 - alphas\n",
    "    return torch.tensor(betas, dtype=torch.float64)\n",
    "\n",
    "class PlaceHolder:\n",
    "    def __init__(self, X, E, y):\n",
    "        self.X = X\n",
    "        self.E = E\n",
    "        self.y = y\n",
    "\n",
    "    def type_as(self, x: torch.Tensor):\n",
    "        \"\"\" Changes the device and dtype of X, E, y. \"\"\"\n",
    "        self.X = self.X.type_as(x)\n",
    "        self.E = self.E.type_as(x)\n",
    "        self.y = self.y.type_as(x)\n",
    "        return self\n",
    "\n",
    "    def mask(self, node_mask, collapse=False):\n",
    "        x_mask = node_mask.unsqueeze(-1)          # bs, n, 1\n",
    "        e_mask1 = x_mask.unsqueeze(2)             # bs, n, 1, 1\n",
    "        e_mask2 = x_mask.unsqueeze(1)             # bs, 1, n, 1\n",
    "\n",
    "        if collapse:\n",
    "            self.X = torch.argmax(self.X, dim=-1)\n",
    "            self.E = torch.argmax(self.E, dim=-1)\n",
    "\n",
    "            self.X[node_mask == 0] = - 1\n",
    "            self.E[(e_mask1 * e_mask2).squeeze(-1) == 0] = - 1\n",
    "        else:\n",
    "            self.X = self.X * x_mask\n",
    "            self.E = self.E * e_mask1 * e_mask2\n",
    "            assert torch.allclose(self.E, torch.transpose(self.E, 1, 2))\n",
    "        return self\n",
    "\n",
    "class DiscreteUniformTransition:\n",
    "    def __init__(self, x_classes: int, e_classes: int, y_classes: int):\n",
    "        self.X_classes = x_classes\n",
    "        self.E_classes = e_classes\n",
    "        self.y_classes = y_classes\n",
    "        self.u_x = torch.ones(1, self.X_classes, self.X_classes)\n",
    "        if self.X_classes > 0:\n",
    "            self.u_x = self.u_x / self.X_classes\n",
    "\n",
    "        self.u_e = torch.ones(1, self.E_classes, self.E_classes)\n",
    "        if self.E_classes > 0:\n",
    "            self.u_e = self.u_e / self.E_classes\n",
    "\n",
    "        self.u_y = torch.ones(1, self.y_classes, self.y_classes)\n",
    "        if self.y_classes > 0:\n",
    "            self.u_y = self.u_y / self.y_classes\n",
    "\n",
    "    def get_Qt(self, beta_t, device):\n",
    "        \"\"\" Returns one-step transition matrices for X and E, from step t - 1 to step t.\n",
    "        Qt = (1 - beta_t) * I + beta_t / K\n",
    "\n",
    "        beta_t: (bs)                         noise level between 0 and 1\n",
    "        returns: qx (bs, dx, dx), qe (bs, de, de), qy (bs, dy, dy).\n",
    "        \"\"\"\n",
    "        beta_t = beta_t.unsqueeze(1).unsqueeze(1)\n",
    "        beta_t = beta_t.to(device)\n",
    "        self.u_x = self.u_x.to(device)\n",
    "        self.u_e = self.u_e.to(device)\n",
    "        self.u_y = self.u_y.to(device)\n",
    "\n",
    "        q_x = beta_t * self.u_x + (1 - beta_t) * torch.eye(self.X_classes, device=device).unsqueeze(0)\n",
    "        q_e = beta_t * self.u_e + (1 - beta_t) * torch.eye(self.E_classes, device=device).unsqueeze(0)\n",
    "        q_y = beta_t * self.u_y + (1 - beta_t) * torch.eye(self.y_classes, device=device).unsqueeze(0)\n",
    "\n",
    "        return PlaceHolder(X=q_x, E=q_e, y=q_y)\n",
    "    \n",
    "class MarginalUniformTransition:\n",
    "    def __init__(self, x_marginals, e_marginals, y_classes):\n",
    "        self.X_classes = len(x_marginals)\n",
    "        self.E_classes = len(e_marginals)\n",
    "        self.y_classes = y_classes\n",
    "        self.x_marginals = x_marginals\n",
    "        self.e_marginals = e_marginals\n",
    "\n",
    "        self.u_x = x_marginals.unsqueeze(0).expand(self.X_classes, -1).unsqueeze(0)\n",
    "        self.u_e = e_marginals.unsqueeze(0).expand(self.E_classes, -1).unsqueeze(0)\n",
    "        self.u_y = torch.ones(1, self.y_classes, self.y_classes)\n",
    "        if self.y_classes > 0:\n",
    "            self.u_y = self.u_y / self.y_classes\n",
    "\n",
    "    def get_Qt(self, beta_t, device):\n",
    "        \"\"\" Returns one-step transition matrices for X and E, from step t - 1 to step t.\n",
    "        Qt = (1 - beta_t) * I + beta_t / K\n",
    "\n",
    "        beta_t: (bs)                         noise level between 0 and 1\n",
    "        returns: qx (bs, dx, dx), qe (bs, de, de), qy (bs, dy, dy). \"\"\"\n",
    "        beta_t = beta_t.unsqueeze(1).unsqueeze(1)\n",
    "        print(beta_t[100])\n",
    "        beta_t = beta_t.to(device)\n",
    "        self.u_x = self.u_x.to(device)\n",
    "        self.u_e = self.u_e.to(device)\n",
    "        self.u_y = self.u_y.to(device)\n",
    "\n",
    "        q_x = beta_t * self.u_x + (1 - beta_t) * torch.eye(self.X_classes, device=device).unsqueeze(0)\n",
    "        q_e = beta_t * self.u_e + (1 - beta_t) * torch.eye(self.E_classes, device=device).unsqueeze(0)\n",
    "        q_y = beta_t * self.u_y + (1 - beta_t) * torch.eye(self.y_classes, device=device).unsqueeze(0)\n",
    "\n",
    "        return PlaceHolder(X=q_x, E=q_e, y=q_y)\n",
    "\n",
    "# Example usage\n",
    "timesteps = 1000\n",
    "betas = cosine_beta_schedule_discrete(timesteps)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transition = MarginalUniformTransition(x_marginals=torch.tensor([0.5, 0.5]), e_marginals=torch.tensor([0.9, 0.1]), y_classes=2)\n",
    "beta_t = betas.to(device)\n",
    "q_t_matrices = transition.get_Qt(beta_t, device)\n",
    "\n",
    "# Print the transition matrix for edges at the final timestep\n",
    "print(\"Transition matrix for edges (q_e) at the final timestep:\")\n",
    "t = 997\n",
    "print(q_t_matrices.E[t+1])\n",
    "print(_get_prior_distribution_transition_mat(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import binom\n",
    "\n",
    "# Parameters\n",
    "N = 1000  # number of trials\n",
    "p = 0.012  # probability of success\n",
    "n_values = np.arange(0, 21)  # number of successes from 0 to 20\n",
    "\n",
    "# Calculate the probabilities\n",
    "probabilities = binom.pmf(n_values, N, p)\n",
    "\n",
    "# Display the probabilities\n",
    "for n, prob in zip(n_values, probabilities):\n",
    "    print(f\"P(X = {n}) = {prob:.10f}\")\n",
    "\n",
    "# Plot the probabilities\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.stem(n_values, probabilities, use_line_collection=True)\n",
    "plt.xlabel('Number of successes (n)')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Binomial Distribution PMF (N=1000, p=0.012)')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import h5py\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "def load_new_format(new_file_path):\n",
    "    paths = []\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    with h5py.File(new_file_path, 'r') as new_hf:\n",
    "        node_coordinates = new_hf['graph']['node_coordinates'][:]\n",
    "        edges = new_hf['graph']['edges'][:]\n",
    "        edge_coordinates = node_coordinates[edges]\n",
    "        nodes = [(i, {'pos': tuple(pos)}) for i, pos in enumerate(node_coordinates)]\n",
    "        \n",
    "        \n",
    "        # Convert edges to a list of tuples\n",
    "        edges = [tuple(edge) for edge in edges]\n",
    "\n",
    "        for i in tqdm(new_hf['trajectories'].keys()):\n",
    "            path_group = new_hf['trajectories'][i]\n",
    "            path = {attr: path_group[attr][()] for attr in path_group.keys()}\n",
    "            if 'edge_orientation' in path:\n",
    "                path['edge_orientations'] = path.pop('edge_orientation')\n",
    "            paths.append(path)\n",
    "\n",
    "    return paths, nodes, edges, edge_coordinates\n",
    "\n",
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, file_path, history_len, future_len, edge_features=None):\n",
    "        self.file_path = file_path\n",
    "        self.history_len = history_len\n",
    "        self.future_len = future_len\n",
    "        self.edge_features = edge_features\n",
    "        self.num_edge_features = 1\n",
    "        if 'coordinates' in self.edge_features:\n",
    "            self.num_edge_features = 5\n",
    "        if 'edge_orientations' in self.edge_features:\n",
    "            self.num_edge_features = 6\n",
    "        self.trajectories, self.nodes, self.edges, self.edge_coordinates = load_new_format(file_path)\n",
    "        self.edge_coordinates = torch.tensor(self.edge_coordinates, dtype=torch.float64)\n",
    "        \n",
    "        self.graph = nx.Graph()\n",
    "        self.graph.add_nodes_from(self.nodes)\n",
    "        self.graph.add_edges_from(self.edges)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # trajectory_name = self.keys[idx]\n",
    "        trajectory = self.trajectories[idx]\n",
    "        edge_idxs = torch.tensor(trajectory['edge_idxs'][:], dtype=torch.long)\n",
    "        edge_orientations = torch.tensor(trajectory['edge_orientations'][:], dtype=torch.long)\n",
    "        \n",
    "        # edge_coordinates_data = trajectory.get('coordinates', [])\n",
    "        edge_coordinates_data = self.edge_coordinates[edge_idxs]\n",
    "\n",
    "        if len(edge_coordinates_data) > 0:\n",
    "            edge_coordinates_np = np.array(edge_coordinates_data)\n",
    "            edge_coordinates = torch.tensor(edge_coordinates_np, dtype=torch.float64)\n",
    "        else:\n",
    "            edge_coordinates = torch.tensor([], dtype=torch.float64)\n",
    "\n",
    "        # Reverse coordinates if orientation is -1\n",
    "        edge_coordinates[edge_orientations == -1] = edge_coordinates[edge_orientations == -1][:, [1, 0]]\n",
    "        \n",
    "        # Calculate the required padding length\n",
    "        total_len = self.history_len + self.future_len\n",
    "        padding_length = max(total_len - len(edge_idxs), 0)\n",
    "        \n",
    "        # Pad edge indices and orientations\n",
    "        edge_idxs = torch.nn.functional.pad(edge_idxs, (0, padding_length), value=-1)\n",
    "        edge_orientations = torch.nn.functional.pad(edge_orientations, (0, padding_length), value=0)\n",
    "        \n",
    "        # Pad coordinates\n",
    "        if padding_length > 0 and edge_coordinates.numel() > 0:\n",
    "            zero_padding = torch.zeros((padding_length, 2, 2), dtype=torch.float)\n",
    "            edge_coordinates = torch.cat([edge_coordinates, zero_padding], dim=0)\n",
    "        \n",
    "        # Split into history and future\n",
    "        history_indices = edge_idxs[:self.history_len]\n",
    "        future_indices = edge_idxs[self.history_len:self.history_len + self.future_len]\n",
    "        history_coordinates = edge_coordinates[:self.history_len] if edge_coordinates.numel() > 0 else None\n",
    "        future_coordinates = edge_coordinates[self.history_len:self.history_len + self.future_len] if edge_coordinates.numel() > 0 else None\n",
    "        \n",
    "        history_edge_orientations = torch.zeros(self.get_n_edges())\n",
    "        future_edge_orientations = torch.zeros(self.get_n_edges())\n",
    "\n",
    "        for index, i in enumerate(history_indices):\n",
    "            history_edge_orientations[i] = edge_orientations[index]\n",
    "        \n",
    "        for index, i in enumerate(future_indices):\n",
    "            future_edge_orientations[i] = edge_orientations[index]\n",
    "\n",
    "        # One-hot encoding of edge indices (ensure valid indices first)\n",
    "        valid_history_mask = history_indices >= 0\n",
    "        valid_future_mask = future_indices >= 0\n",
    "        \n",
    "        history_one_hot_edges = torch.nn.functional.one_hot(history_indices[valid_history_mask], num_classes=len(self.edges))\n",
    "        future_one_hot_edges = torch.nn.functional.one_hot(future_indices[valid_future_mask], num_classes=len(self.edges))\n",
    "        \n",
    "        # Sum across the time dimension to count occurrences of each edge\n",
    "        history_one_hot_edges = history_one_hot_edges.sum(dim=0)  # (num_edges,)\n",
    "        future_one_hot_edges = future_one_hot_edges.sum(dim=0)  # (num_edges,)\n",
    "\n",
    "        if 'edge_orientations' in self.edge_features:\n",
    "            history_edge_features = torch.stack((history_one_hot_edges, history_edge_orientations), dim=1)\n",
    "            future_edge_features = torch.stack((future_one_hot_edges, future_edge_orientations), dim=1)\n",
    "        else:\n",
    "            history_edge_features = history_one_hot_edges\n",
    "            future_edge_features = future_one_hot_edges\n",
    "        \n",
    "        # Generate the tensor indicating nodes in history\n",
    "        node_in_history = torch.zeros((len(self.nodes), 1), dtype=torch.float)\n",
    "        history_edges = [self.edges[i] for i in history_indices if i >= 0]\n",
    "        history_nodes = set(node for edge in history_edges for node in edge)\n",
    "        for node in history_nodes:\n",
    "            node_in_history[node] = 1\n",
    "            \n",
    "        # Basic History edge features = coordinates, binary encoding\n",
    "        history_edge_features = history_one_hot_edges.view(-1, 1).float()\n",
    "        future_edge_features = future_one_hot_edges.view(-1, 1).float()\n",
    "        if 'coordinates' in self.edge_features:\n",
    "            history_edge_features = torch.cat((history_edge_features, torch.flatten(self.edge_coordinates, start_dim=1).float()), dim=1)\n",
    "            future_edge_features = torch.cat((future_edge_features, torch.flatten(self.edge_coordinates, start_dim=1).float()), dim=1)\n",
    "            self.num_edge_features = 5\n",
    "        if 'edge_orientations' in self.edge_features:\n",
    "            history_edge_features = torch.cat((history_edge_features, history_edge_orientations.float()), dim=1)\n",
    "            future_edge_features = torch.cat((future_edge_features, future_edge_orientations.float()), dim=1)\n",
    "        return {\n",
    "            \"history_indices\": history_indices,\n",
    "            \"future_indices\": future_indices,\n",
    "            \"history_coordinates\": history_coordinates,\n",
    "            \"future_coordinates\": future_coordinates,\n",
    "            \"history_one_hot_edges\": history_one_hot_edges,\n",
    "            \"future_one_hot_edges\": future_one_hot_edges,\n",
    "            \"history_edge_orientations\": history_edge_orientations,\n",
    "            \"future_edge_orientations\": future_edge_orientations,\n",
    "            \"history_edge_features\": history_edge_features,\n",
    "            \"future_edge_features\": future_edge_features,\n",
    "            \"node_in_history\": node_in_history,\n",
    "        }, self.graph\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.trajectories)\n",
    "\n",
    "    def get_n_edges(self):\n",
    "        return self.graph.number_of_edges()\n",
    "    \n",
    "    def node_coordinates(self):\n",
    "        \"\"\"\n",
    "        Returns a tensor of shape [#nodes, 2] containing the coordinates of each node.\n",
    "        \"\"\"\n",
    "        coords = [attr['pos'] for _, attr in self.nodes]  # List of tuples (x, y)\n",
    "        coords_tensor = torch.tensor(coords, dtype=torch.float)  # Convert list to tensor\n",
    "        return coords_tensor\n",
    "    \n",
    "    def get_all_edges_tensor(self):\n",
    "        \"\"\"\n",
    "        Returns a tensor of shape [2, num_edges] where each column represents an edge\n",
    "        and the two entries in each column represent the nodes connected by that edge.\n",
    "        \"\"\"\n",
    "        edges = list(self.graph.edges())\n",
    "        edge_tensor = torch.tensor(edges, dtype=torch.long).t()\n",
    "        return edge_tensor\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    graph = [item[1] for item in batch]\n",
    "    # Extract elements for each sample and stack them, handling variable lengths\n",
    "    history_indices = torch.stack([item[0]['history_indices'] for item in batch])\n",
    "    future_indices = torch.stack([item[0]['future_indices'] for item in batch])\n",
    "    \n",
    "    history_one_hot_edges = torch.stack([item[0]['history_one_hot_edges'] for item in batch])\n",
    "    future_one_hot_edges = torch.stack([item[0]['future_one_hot_edges'] for item in batch])\n",
    "\n",
    "    # Coordinates\n",
    "    history_coordinates = [item[0]['history_coordinates'] for item in batch if item[0]['history_coordinates'] is not None]\n",
    "    future_coordinates = [item[0]['future_coordinates'] for item in batch if item[0]['future_coordinates'] is not None]\n",
    "    \n",
    "    history_edge_orientations = torch.stack([item[0]['history_edge_orientations'] for item in batch])\n",
    "    future_edge_orientations = torch.stack([item[0]['future_edge_orientations'] for item in batch])\n",
    "    \n",
    "    history_edge_features = torch.stack([item[0]['history_edge_features'] for item in batch])\n",
    "    future_edge_features = torch.stack([item[0]['future_edge_features'] for item in batch])\n",
    "    \n",
    "    history_one_hot_nodes = torch.stack([item[0]['node_in_history'] for item in batch])\n",
    "    \n",
    "    # Stack coordinates if not empty\n",
    "    if history_coordinates:\n",
    "        history_coordinates = torch.stack(history_coordinates)\n",
    "    if future_coordinates:\n",
    "        future_coordinates = torch.stack(future_coordinates)\n",
    "\n",
    "    return {\n",
    "            \"history_indices\": history_indices,\n",
    "            \"future_indices\": future_indices,\n",
    "            \"history_coordinates\": history_coordinates,\n",
    "            \"future_coordinates\": future_coordinates,\n",
    "            \"history_one_hot_edges\": history_one_hot_edges,\n",
    "            \"future_one_hot_edges\": future_one_hot_edges,\n",
    "            \"history_edge_orientations\": history_edge_orientations,\n",
    "            \"future_edge_orientations\": future_edge_orientations,\n",
    "            \"history_edge_features\": history_edge_features,\n",
    "            \"future_edge_features\": future_edge_features,\n",
    "            \"history_one_hot_nodes\": history_one_hot_nodes,\n",
    "            \"graph\": graph,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TrajectoryDataset(\"/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/data/tdrive_1001_1200.h5\", 5, 2, edge_features=['one_hot_edges', 'coordinates'])\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Given tensor\n",
    "original_tensor = torch.tensor([\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
    "     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "])\n",
    "\n",
    "# Current edge tensor\n",
    "current_edge = torch.tensor([39, 17])\n",
    "\n",
    "# Transforming the tensor\n",
    "def transform_tensor(original_tensor, current_edge):\n",
    "    batch_size = original_tensor.size(0)\n",
    "    max_neighbors = (original_tensor == 1).sum(dim=1).max().item()\n",
    "    transformed_tensor = torch.zeros((batch_size, max_neighbors), dtype=torch.long)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # Find indices of neighbors\n",
    "        neighbor_indices = (original_tensor[i] == 1).nonzero(as_tuple=False).squeeze()\n",
    "        # Only keep the index where it matches the current edge\n",
    "        valid_indices = (neighbor_indices == current_edge[i]).nonzero(as_tuple=False).squeeze()    \n",
    "        # Set the values in the transformed tensor\n",
    "        transformed_tensor[i, valid_indices] = 1\n",
    "\n",
    "    return transformed_tensor\n",
    "\n",
    "transformed_tensor = transform_tensor(original_tensor, current_edge)\n",
    "print(transformed_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import F1Score\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.transforms import LineGraph\n",
    "#from dataset.trajctory_dataset import TrajectoryDataset, collate_fn\n",
    "#from .d3pm_diffusion import make_diffusion\n",
    "#from .d3pm_edge_encoder import Edge_Encoder\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import F1Score\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import wandb\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "\n",
    "class Benchmark_Models(nn.Module):\n",
    "    def __init__(self, data_config, model_config, train_config, test_config, wandb_config, model):\n",
    "        super(Benchmark_Models, self).__init__()\n",
    "        # Data\n",
    "        self.data_config = data_config\n",
    "        self.train_data_path = self.data_config['train_data_path']\n",
    "        self.test_data_path = self.data_config['test_data_path']\n",
    "        self.history_len = self.data_config['history_len']\n",
    "        self.future_len = self.data_config['future_len']\n",
    "        self.num_classes = self.data_config['num_classes']\n",
    "        self.edge_features = self.data_config['edge_features']\n",
    "        \n",
    "        # Model\n",
    "        self.model_config = model_config\n",
    "        self.model = model # Edge_Encoder\n",
    "        self.hidden_channels = self.model_config['hidden_channels']\n",
    "        self.condition_dim = self.model_config['condition_dim']\n",
    "        self.num_layers = self.model_config['num_layers']\n",
    "        \n",
    "        # Training\n",
    "        self.train_config = train_config\n",
    "        self.lr = self.train_config['lr']\n",
    "        self.lr_decay_parameter = self.train_config['lr_decay']\n",
    "        self.learning_rate_warmup_steps = self.train_config['learning_rate_warmup_steps']\n",
    "        self.num_epochs = self.train_config['num_epochs']\n",
    "        self.gradient_accumulation = self.train_config['gradient_accumulation']\n",
    "        self.gradient_accumulation_steps = self.train_config['gradient_accumulation_steps']\n",
    "        self.batch_size = self.train_config['batch_size'] if not self.gradient_accumulation else self.train_config['batch_size'] * self.gradient_accumulation_steps\n",
    "        \n",
    "        # Testing\n",
    "        self.test_config = test_config\n",
    "        self.test_batch_size = self.test_config['batch_size']\n",
    "        self.model_path = self.test_config['model_path']\n",
    "        self.eval_every_steps = self.test_config['eval_every_steps']\n",
    "        \n",
    "        # WandB\n",
    "        self.wandb_config = wandb_config\n",
    "        wandb.init(\n",
    "            settings=wandb.Settings(start_method=\"fork\"),\n",
    "            project=self.wandb_config['project'],\n",
    "            entity=self.wandb_config['entity'],\n",
    "            notes=self.wandb_config['notes'],\n",
    "            job_type=self.wandb_config['job_type'],\n",
    "            config={**self.data_config, **self.model_config, **self.train_config}\n",
    "        )\n",
    "        self.exp_name = self.wandb_config['exp_name']\n",
    "        wandb.run.name = self.exp_name\n",
    "\n",
    "        # Logging\n",
    "        self.dataset = self.data_config['dataset']\n",
    "        self.model_dir = os.path.join(\"experiments\", self.exp_name)\n",
    "        os.makedirs(self.model_dir,exist_ok=True)\n",
    "        log_name = '{}.log'.format(time.strftime('%Y-%m-%d-%H-%M'))\n",
    "        log_name = f\"{self.dataset}_{log_name}\"\n",
    "        \n",
    "        self.log = logging.getLogger()\n",
    "        self.log.setLevel(logging.INFO)\n",
    "        log_dir = os.path.join(self.model_dir, log_name)\n",
    "        file_handler = logging.FileHandler(log_dir)\n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        file_handler.setFormatter(formatter)\n",
    "        self.log.addHandler(file_handler)\n",
    "        \n",
    "        self.log_loss_every_steps = self.train_config['log_loss_every_steps']        \n",
    "        \n",
    "        # Build Components\n",
    "        self._build_train_dataloader()\n",
    "        self._build_test_dataloader()\n",
    "        self._build_model()\n",
    "        self._build_optimizer()\n",
    "            \n",
    "    def train(self):\n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "        '''def get_neighbors(line_graph, edge, device):\n",
    "            neighbors = []\n",
    "            for e in edge:\n",
    "                neighbor_set = set()\n",
    "                for i in range(line_graph.edge_index.size(1)):\n",
    "                    if line_graph.edge_index[0, i] == e:\n",
    "                        neighbor_set.add(line_graph.edge_index[1, i].item())\n",
    "                    elif line_graph.edge_index[1, i] == e:\n",
    "                        neighbor_set.add(line_graph.edge_index[0, i].item())\n",
    "                neighbors.append(list(neighbor_set))\n",
    "            # Create a binary tensor for neighbors\n",
    "            neighbors_binary = torch.zeros((len(edge), self.num_edges), dtype=torch.long, device=device)\n",
    "            \n",
    "            for i, n in enumerate(neighbors):\n",
    "                neighbors_binary[i, n] = 1\n",
    "            \n",
    "            return neighbors_binary\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            ground_truth_fut = []\n",
    "            pred_fut = []\n",
    "            self.model.train()\n",
    "            total_loss = 0\n",
    "            for batch in self.train_data_loader:\n",
    "                history_edge_features = batch[\"history_edge_features\"]\n",
    "                last_history_edge = batch[\"history_indices\"][:, -1]\n",
    "                future_edge_indices = batch[\"future_indices\"]\n",
    "                future_edge_features = batch[\"future_edge_features\"]\n",
    "                future_edge_indices_one_hot = future_edge_features[:, :, 0]\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                visited_edges = [set() for _ in range(history_edge_features.size(0))]   # keep track of visited edges, to avoid cycles\n",
    "                prediction = []\n",
    "                for idx in range(self.future_len):\n",
    "                    future = future_edge_indices_one_hot.clone()\n",
    "                    future.zero_()\n",
    "                    future[:, idx] = 1\n",
    "                    \"\"\"for j in range(future_edge_indices.size(0)):\n",
    "                        future[j, future_edge_indices[j, idx]] = 1\"\"\"\"\"\"\n",
    "                    \n",
    "                    neighbors = get_neighbors(self.line_graph, last_history_edge, device=history_edge_features.device)\n",
    "                    logits, preds = self.model(history_edge_features, neighbors)\n",
    "                    \n",
    "                    # Mask logits for visited edges\n",
    "                    #logits = logits.clone()\n",
    "                    \"\"\"for i in range(len(preds)):\n",
    "                        for visited_edge in visited_edges[i]:\n",
    "                            logits[i, neighbors[i] == visited_edge] = float('-inf')\n",
    "                    \n",
    "                    # Update history and visited edges\n",
    "                    for i in range(len(preds)):\n",
    "                        visited_edges[i].add(preds[i].item())  # Add predicted edge to visited set\n",
    "                        history_edge_features[i] = history_edge_features[i].clone()\n",
    "                        history_edge_features[i, preds[i], 0] = 1\"\"\"  # Add it to history edge features\n",
    "                    last_history_edge = preds   # Update last history edge\n",
    "                    loss = F.binary_cross_entropy_with_logits(logits, future)\n",
    "                    prediction.append(preds)\n",
    "                    loss.backward()\n",
    "\n",
    "                pred_fut.append(prediction)\n",
    "                ground_truth_fut.append(future_edge_indices_one_hot)\n",
    "                # Calculate the loss (cross-entropy)\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                \n",
    "            avg_loss = total_loss / len(self.train_data_loader)\n",
    "            f1_score = F1Score(task='binary', average='macro', num_classes=2)\n",
    "            #f1_epoch = f1_score(torch.flatten(torch.cat(pred_fut)).detach(), torch.flatten(torch.cat(ground_truth_fut)).detach())\n",
    "            # Logging\n",
    "            if (epoch + 1) % self.log_loss_every_steps == 0:\n",
    "                print(f\"Epoch {epoch + 1}/{self.num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "                wandb.log({\"epoch\": epoch + 1, \"loss\": avg_loss})\n",
    "                #wandb.log({\"epoch\": epoch + 1, \"average_F1_score\": f1_epoch.item()})\n",
    "                print(pred_fut)\n",
    "                print(future_edge_indices)\n",
    "                self.log.info(f\"Epoch {epoch + 1} Average Loss: {avg_loss}\")\n",
    "                print(\"Epoch:\", epoch + 1)\n",
    "                print(\"Loss:\", avg_loss)\n",
    "                #print(\"F1:\", f1_epoch.item())'''\n",
    "        def transform_tensor(neighbor_tensor, current_edge):\n",
    "            batch_size = neighbor_tensor.size(0)\n",
    "            max_neighbors = (neighbor_tensor == 1).sum(dim=1).max().item()\n",
    "            transformed_tensor = torch.zeros((batch_size, max_neighbors), dtype=torch.long)\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                # Find indices of neighbors\n",
    "                neighbor_indices = (neighbor_tensor[i] == 1).nonzero(as_tuple=False).squeeze()\n",
    "                # Only keep the index where it matches the current edge\n",
    "                valid_indices = (neighbor_indices == current_edge[i]).nonzero(as_tuple=False).squeeze()\n",
    "                # Set the values in the transformed tensor\n",
    "                transformed_tensor[i, valid_indices] = 1\n",
    "\n",
    "            return transformed_tensor\n",
    "        \n",
    "        '''def group_and_pad(tensor, batch_size, pad_value=0):\n",
    "            # Get unique groups\n",
    "            groups = torch.unique(tensor[:, 0])\n",
    "            grouped_sequences = []\n",
    "            \n",
    "            # Find the maximum length of sequences\n",
    "            max_len = 0\n",
    "            for group in groups:\n",
    "                group_elements = tensor[tensor[:, 0] == group][:, 1]\n",
    "                grouped_sequences.append(group_elements)\n",
    "                max_len = max(max_len, len(group_elements))\n",
    "            \n",
    "            # Pad the sequences\n",
    "            padded_sequences = []\n",
    "            for seq in grouped_sequences:\n",
    "                padded_seq = torch.cat([seq, torch.full((max_len - len(seq),), pad_value)])\n",
    "                padded_sequences.append(padded_seq)\n",
    "            \n",
    "            return torch.stack(padded_sequences)'''\n",
    "        \n",
    "        def group_and_pad(tensor, batch_size, pad_value=0, missing_value=-1):\n",
    "            grouped_sequences = []\n",
    "\n",
    "            # Iterate through all possible groups\n",
    "            for group in range(batch_size):\n",
    "                group_elements = tensor[tensor[:, 0] == group][:, 1]\n",
    "                if len(group_elements) == 0:\n",
    "                    # If the group is missing, add the missing value\n",
    "                    group_elements = torch.tensor([missing_value])\n",
    "                grouped_sequences.append(group_elements)\n",
    "\n",
    "            # Find the maximum length of sequences\n",
    "            max_len = max(len(seq) for seq in grouped_sequences)\n",
    "            \n",
    "            # Pad the sequences\n",
    "            padded_sequences = []\n",
    "            for seq in grouped_sequences:\n",
    "                padded_seq = torch.cat([seq, torch.full((max_len - len(seq),), pad_value)])\n",
    "                padded_sequences.append(padded_seq)\n",
    "            \n",
    "            return torch.stack(padded_sequences)\n",
    "        \n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        for epoch in tqdm(range(self.num_epochs)):\n",
    "            self.model.train()\n",
    "            total_loss = 0\n",
    "            pred_fut = []\n",
    "            ground_truth_fut = []\n",
    "            for batch in self.train_data_loader:\n",
    "                hidden = self.model.init_hidden(self.batch_size)\n",
    "                history_edge_features = batch[\"history_edge_features\"]\n",
    "                history_edge_indices = batch[\"history_indices\"]\n",
    "                history_edge_indices_one_hot = history_edge_features[:, :, 0]\n",
    "                initial_edge = batch[\"history_indices\"][:, -1]\n",
    "                future_edge_indices = batch[\"future_indices\"]\n",
    "                future_edge_features = batch[\"future_edge_features\"]\n",
    "                future_edge_indices_one_hot = future_edge_features[:, :, 0]\n",
    "                batch_size_act = history_edge_features.size(0)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = 0\n",
    "                preds = []\n",
    "                preds_binary = torch.zeros_like(future_edge_indices_one_hot)\n",
    "                for t in range(self.future_len):\n",
    "                    if t == 0:\n",
    "                        current_edge = initial_edge\n",
    "                    else:\n",
    "                        current_edge = future_edge_indices[:, t-1]\n",
    "                    \n",
    "                    true_neighbors = self.get_neighbors(self.line_graph, current_edge)\n",
    "                    # TODO: Use history edge features at t == 0, then add true future_edge_features at t-1\n",
    "                    input_features = self.model.get_neighbor_features(history_edge_features, true_neighbors)\n",
    "                    out, hidden = self.model(input_features, hidden)\n",
    "                    logits = out.squeeze(-1)  # Remove the last dimension to match (bs, num_neighbors)\n",
    "                    \n",
    "                    #masked_logits = logits.clone()\n",
    "                    #masked_logits[true_neighbors == 0] = -100    # Mask out true neighbors\n",
    "                    #masked_logits[history_edge_indices_one_hot == 1] = -100   # Mask out history\n",
    "                    \n",
    "                    predicted_edge_indices = torch.argmax(logits, dim=1)\n",
    "                    true_neighbors_padded = group_and_pad(torch.argwhere(true_neighbors == 1), batch_size_act)  # (bs, num_neighbors)\n",
    "                    \n",
    "                    predicted_edges = true_neighbors_padded.gather(1, predicted_edge_indices.unsqueeze(1)).squeeze(1)\n",
    "                    preds.append(predicted_edges)\n",
    "                    ground_truth = transform_tensor(true_neighbors, future_edge_indices[:, t])\n",
    "                    loss += criterion(logits, ground_truth.float())\n",
    "                \n",
    "                for i in range(self.batch_size):\n",
    "                    pred_binary = torch.zeros(self.num_edges, dtype=torch.float)\n",
    "                    pred_binary[torch.stack(preds).t()[i]] = 1\n",
    "                    preds_binary[i] = pred_binary.clone().detach()\n",
    "                \n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                pred_fut.append(preds_binary)\n",
    "                ground_truth_fut.append(future_edge_indices_one_hot)\n",
    "                \n",
    "            preds = [torch.stack(preds).t()]\n",
    "            avg_loss = total_loss / len(self.train_data_loader)\n",
    "            f1_score = F1Score(task='binary', average='macro', num_classes=2)\n",
    "            f1_epoch = f1_score(torch.flatten(torch.cat(pred_fut)).detach(), torch.flatten(torch.cat(ground_truth_fut)).detach())\n",
    "\n",
    "            if (epoch + 1) % self.log_loss_every_steps == 0:\n",
    "                print(f\"Epoch {epoch + 1}/{self.num_epochs}, Loss: {avg_loss:.4f}, F1 Score: {f1_epoch.item()}\")\n",
    "                print(\"History Edges:\", history_edge_indices)\n",
    "                print(\"Predicted Edges:\", preds)\n",
    "                print(\"Future_edge_indices\", future_edge_indices)\n",
    "        \n",
    "        print(\"> Training Complete!\\n\")\n",
    "        \n",
    "    '''def get_neighbors(self, line_graph, edge):\n",
    "        neighbors = []\n",
    "        for e in edge:\n",
    "            # When e == -1, neighbor_tensor = torch.zeros(self.num_edges, dtype=torch.long)\n",
    "            neighbor_set = set()\n",
    "            for i in range(line_graph.edge_index.size(1)):\n",
    "                if line_graph.edge_index[0, i] == e:\n",
    "                    neighbor_set.add(line_graph.edge_index[1, i].item())\n",
    "                elif line_graph.edge_index[1, i] == e:\n",
    "                    neighbor_set.add(line_graph.edge_index[0, i].item())\n",
    "            neighbor_tensor = torch.zeros(self.num_edges, dtype=torch.long)\n",
    "            neighbor_tensor[list(neighbor_set)] = 1\n",
    "            neighbors.append(neighbor_tensor)\n",
    "        \n",
    "        return torch.stack(neighbors)'''\n",
    "        \n",
    "    def get_neighbors(self, line_graph, edge):\n",
    "        edge_tensor = torch.tensor(edge, dtype=torch.long)\n",
    "\n",
    "        # Loop through each edge in batch and update the corresponding row in neighbor_tensor\n",
    "        for i, e in enumerate(edge_tensor):\n",
    "            # Create a 2D boolean mask for matching edges in edge_index\n",
    "            mask0 = line_graph.edge_index[0].unsqueeze(1) == e.unsqueeze(0)\n",
    "            mask1 = line_graph.edge_index[1].unsqueeze(1) == e.unsqueeze(0)\n",
    "\n",
    "            # Find neighbors: if mask0[i, j] is True, the neighbor is edge_index[1, i], and vice versa for mask1\n",
    "            neighbors_index_0 = torch.where(mask0, line_graph.edge_index[1].unsqueeze(1), torch.full_like(line_graph.edge_index[1].unsqueeze(1), -1))\n",
    "            neighbor_indices = neighbors_index_0[:, 0][neighbors_index_0[:, 0] != -1]\n",
    "            \n",
    "            print(\"Edge\", e)\n",
    "            print(\"neighbor_indices\", neighbor_indices)\n",
    "\n",
    "            # We now need to construct the final neighbor tensor\n",
    "            neighbor_tensor = torch.zeros((edge_tensor.size(0), self.num_edges), dtype=torch.long, device=edge_tensor.device)\n",
    "            # Get unique neighbor indices for the current edge e\n",
    "            for j in range(len(neighbor_indices)):\n",
    "                neighbor_tensor[i, neighbor_indices[j]] = 1\n",
    "\n",
    "        print(neighbor_tensor)\n",
    "        return neighbor_tensor\n",
    "        \n",
    "    def save_model(self):\n",
    "        save_path = os.path.join(self.model_dir, \n",
    "                                 self.exp_name + '_' + self.model_config['name'] + '_' +  self.model_config['transition_mat_type'] + '_'  + \n",
    "                                 f'_hidden_dim_{self.hidden_channels}_condition_dim_{self.condition_dim}_layers_{self.num_layers}.pth')\n",
    "        torch.save(self.model.state_dict(), save_path)\n",
    "        self.log.info(f\"Model saved at {save_path}!\")\n",
    "        \n",
    "    def load_model(self, model_path):\n",
    "        self.model.load_state_dict(torch.load(model_path))\n",
    "        self.log.info(\"Model loaded!\\n\")\n",
    "    \n",
    "    def _build_optimizer(self):\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        \n",
    "        def lr_lambda(epoch):\n",
    "            if epoch < self.learning_rate_warmup_steps:\n",
    "                return 1.0\n",
    "            else:\n",
    "                decay_lr = self.lr_decay_parameter ** (epoch - self.learning_rate_warmup_steps)\n",
    "                return max(decay_lr, 2e-5 / self.lr)\n",
    "            \n",
    "        self.scheduler = torch.optim.lr_scheduler.LambdaLR(self.optimizer, lr_lambda)\n",
    "        print(\"> Optimizer and Scheduler built!\\n\")\n",
    "        \n",
    "    def _build_train_dataloader(self):\n",
    "        print(\"Loading Training Dataset...\")\n",
    "        self.train_dataset = TrajectoryDataset(self.train_data_path, self.history_len, self.future_len, self.edge_features)\n",
    "        self.G = self.train_dataset.graph\n",
    "        self.nodes = self.G.nodes\n",
    "        self.edges = self.G.edges(data=True)\n",
    "        self.indexed_edges = self.train_dataset.edges\n",
    "        self.num_edge_features = self.train_dataset.num_edge_features\n",
    "        \n",
    "        # Build the line graph and corresponding edge index\n",
    "        edge_index = self._build_edge_index()\n",
    "        self.line_graph = Data(edge_index=edge_index)\n",
    "        \n",
    "        self.edge_tensor = self.train_dataset.get_all_edges_tensor()\n",
    "        self.num_edges = self.train_dataset.get_n_edges()\n",
    "        \n",
    "        self.train_data_loader = DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "                \n",
    "        print(\"> Training Dataset loaded!\\n\")\n",
    "        \n",
    "    def _build_edge_index(self):\n",
    "        print(\"Building edge index for line graph...\")\n",
    "        edge_index = torch.tensor([[e[0], e[1]] for e in self.edges], dtype=torch.long).t().contiguous()\n",
    "        edge_to_index = {tuple(e[:2]): e[2]['index'] for e in self.edges}\n",
    "        line_graph_edges = []\n",
    "        edge_list = edge_index.t().tolist()\n",
    "        \n",
    "        neighbor_counts = {edge_to_index[(u1, v1)]: 0 for u1, v1 in edge_list}\n",
    "        \n",
    "        for i, (u1, v1) in tqdm(enumerate(edge_list), total=len(edge_list), desc=\"Processing edges\"):\n",
    "            for j, (u2, v2) in enumerate(edge_list):\n",
    "                if i != j and (u1 == u2 or u1 == v2 or v1 == u2 or v1 == v2):\n",
    "                    line_graph_edges.append((edge_to_index[(u1, v1)], edge_to_index[(u2, v2)]))\n",
    "                    neighbor_counts[edge_to_index[(u1, v1)]] += 1\n",
    "\n",
    "        # Create the edge index for the line graph\n",
    "        edge_index = torch.tensor(line_graph_edges, dtype=torch.long).t().contiguous()\n",
    "        print(\"> Edge index built!\\n\")\n",
    "        \n",
    "        # Find the maximum neighbor degree\n",
    "        self.max_degree = max(neighbor_counts.values())\n",
    "        \n",
    "        return edge_index    \n",
    "\n",
    "    def _build_test_dataloader(self):\n",
    "        self.test_dataset = TrajectoryDataset(self.test_data_path, self.history_len, self.future_len, self.edge_features)\n",
    "        self.test_data_loader = DataLoader(self.test_dataset, batch_size=self.test_batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "        print(\"> Test Dataset loaded!\\n\")\n",
    "        \n",
    "    def _build_model(self):\n",
    "        #self.model = self.model(self.model_config, self.history_len, self.future_len, self.num_classes,\n",
    "        #                        nodes=self.nodes, edges=self.edges,\n",
    "        #                        num_edges=self.num_edges, hidden_channels=self.hidden_channels, num_edge_features=self.num_edge_features, max_degree=self.max_degree)\n",
    "        self.model = self.model(self.model_config, self.num_edge_features, self.num_edges)\n",
    "        print(\"> Model built!\\n\")\n",
    "        \n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import h5py\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "def load_new_format(new_file_path):\n",
    "    paths = []\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    with h5py.File(new_file_path, 'r') as new_hf:\n",
    "        node_coordinates = new_hf['graph']['node_coordinates'][:]\n",
    "        edges = new_hf['graph']['edges'][:]\n",
    "        edge_coordinates = node_coordinates[edges]\n",
    "        nodes = [(i, {'pos': tuple(pos)}) for i, pos in enumerate(node_coordinates)]\n",
    "        \n",
    "        if 'edge_indices' in new_hf['graph']:\n",
    "            edge_indices = new_hf['graph']['edge_indices'][:]\n",
    "            # Convert edges to a list of tuples\n",
    "            # Sort edges based on their saved indices\n",
    "            indexed_edges = sorted(zip(edges, edge_indices), key=lambda x: x[1])\n",
    "            edges = [edge for edge, _ in indexed_edges]\n",
    "        else:\n",
    "            edges = [tuple(edge) for edge in edges]\n",
    "\n",
    "        for i in tqdm(new_hf['trajectories'].keys()):\n",
    "            path_group = new_hf['trajectories'][i]\n",
    "            path = {attr: path_group[attr][()] for attr in path_group.keys()}\n",
    "            if 'edge_orientation' in path:\n",
    "                path['edge_orientations'] = path.pop('edge_orientation')\n",
    "            paths.append(path)\n",
    "\n",
    "    return paths, nodes, edges, edge_coordinates\n",
    "\n",
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, file_path, history_len, future_len, edge_features=None):\n",
    "        self.file_path = file_path\n",
    "        self.history_len = history_len\n",
    "        self.future_len = future_len\n",
    "        self.edge_features = edge_features\n",
    "        self.num_edge_features = 1\n",
    "        if 'coordinates' in self.edge_features:\n",
    "            self.num_edge_features = 5\n",
    "        if 'edge_orientations' in self.edge_features:\n",
    "            self.num_edge_features = 6\n",
    "        self.trajectories, self.nodes, self.edges, self.edge_coordinates = load_new_format(file_path)\n",
    "        self.edge_coordinates = torch.tensor(self.edge_coordinates, dtype=torch.float64)\n",
    "        \n",
    "        self.graph = nx.Graph()\n",
    "        indexed_edges = [((start, end), index) for index, (start, end) in enumerate(self.edges)]\n",
    "\n",
    "        # Add edges with index to the graph\n",
    "        for (start, end), index in indexed_edges:\n",
    "            self.graph.add_edge(start, end, index=index, default_orientation=(start, end))\n",
    "        self.graph.add_nodes_from(self.nodes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        trajectory = self.trajectories[idx]\n",
    "        edge_idxs = torch.tensor(trajectory['edge_idxs'][:], dtype=torch.long)\n",
    "        edge_orientations = torch.tensor(trajectory['edge_orientations'][:], dtype=torch.long)\n",
    "        \n",
    "        edge_coordinates_data = self.edge_coordinates[edge_idxs]\n",
    "\n",
    "        if len(edge_coordinates_data) > 0:\n",
    "            edge_coordinates_np = np.array(edge_coordinates_data)\n",
    "            edge_coordinates = torch.tensor(edge_coordinates_np, dtype=torch.float64)\n",
    "        else:\n",
    "            edge_coordinates = torch.tensor([], dtype=torch.float64)\n",
    "\n",
    "        # Reverse coordinates if orientation is -1\n",
    "        edge_coordinates[edge_orientations == -1] = edge_coordinates[edge_orientations == -1][:, [1, 0]]\n",
    "        \n",
    "        # Calculate the required padding length\n",
    "        total_len = self.history_len + self.future_len\n",
    "        padding_length = max(total_len - len(edge_idxs), 0)\n",
    "        \n",
    "        # Pad edge indices and orientations\n",
    "        edge_idxs = torch.nn.functional.pad(edge_idxs, (0, padding_length), value=-1)\n",
    "        edge_orientations = torch.nn.functional.pad(edge_orientations, (0, padding_length), value=0)\n",
    "        \n",
    "        # Pad coordinates\n",
    "        if padding_length > 0 and edge_coordinates.numel() > 0:\n",
    "            zero_padding = torch.zeros((padding_length, 2, 2), dtype=torch.float)\n",
    "            edge_coordinates = torch.cat([edge_coordinates, zero_padding], dim=0)\n",
    "        \n",
    "        # Split into history and future\n",
    "        history_indices = edge_idxs[:self.history_len]\n",
    "        future_indices = edge_idxs[self.history_len:self.history_len + self.future_len]\n",
    "        history_coordinates = edge_coordinates[:self.history_len] if edge_coordinates.numel() > 0 else None\n",
    "        future_coordinates = edge_coordinates[self.history_len:self.history_len + self.future_len] if edge_coordinates.numel() > 0 else None\n",
    "        \n",
    "        history_edge_orientations = torch.zeros(self.get_n_edges())\n",
    "        future_edge_orientations = torch.zeros(self.get_n_edges())\n",
    "\n",
    "        for index, i in enumerate(history_indices):\n",
    "            history_edge_orientations[i] = edge_orientations[index]\n",
    "        \n",
    "        for index, i in enumerate(future_indices):\n",
    "            future_edge_orientations[i] = edge_orientations[index]\n",
    "\n",
    "        # One-hot encoding of edge indices (ensure valid indices first)\n",
    "        valid_history_mask = history_indices >= 0\n",
    "        valid_future_mask = future_indices >= 0\n",
    "        \n",
    "        history_one_hot_edges = torch.nn.functional.one_hot(history_indices[valid_history_mask], num_classes=len(self.edges))\n",
    "        future_one_hot_edges = torch.nn.functional.one_hot(future_indices[valid_future_mask], num_classes=len(self.edges))\n",
    "        \n",
    "        # Sum across the time dimension to count occurrences of each edge\n",
    "        history_one_hot_edges = history_one_hot_edges.sum(dim=0)  # (num_edges,)\n",
    "        future_one_hot_edges = future_one_hot_edges.sum(dim=0)  # (num_edges,)\n",
    "\n",
    "        if 'edge_orientations' in self.edge_features:\n",
    "            history_edge_features = torch.stack((history_one_hot_edges, history_edge_orientations), dim=1)\n",
    "            future_edge_features = torch.stack((future_one_hot_edges, future_edge_orientations), dim=1)\n",
    "        else:\n",
    "            history_edge_features = history_one_hot_edges\n",
    "            future_edge_features = future_one_hot_edges\n",
    "        \n",
    "        # Generate the tensor indicating nodes in history\n",
    "        node_in_history = torch.zeros((len(self.nodes), 1), dtype=torch.float)\n",
    "        history_edges = [self.edges[i] for i in history_indices if i >= 0]\n",
    "        history_nodes = set(node for edge in history_edges for node in edge)\n",
    "        for node in history_nodes:\n",
    "            node_in_history[node] = 1\n",
    "            \n",
    "        # Basic History edge features = coordinates, binary encoding\n",
    "        history_edge_features = history_one_hot_edges.view(-1, 1).float()\n",
    "        future_edge_features = future_one_hot_edges.view(-1, 1).float()\n",
    "        if 'coordinates' in self.edge_features:\n",
    "            history_edge_features = torch.cat((history_edge_features, torch.flatten(self.edge_coordinates, start_dim=1).float()), dim=1)\n",
    "            future_edge_features = torch.cat((future_edge_features, torch.flatten(self.edge_coordinates, start_dim=1).float()), dim=1)\n",
    "            self.num_edge_features = 5\n",
    "        if 'edge_orientations' in self.edge_features:\n",
    "            history_edge_features = torch.cat((history_edge_features, history_edge_orientations.float()), dim=1)\n",
    "            future_edge_features = torch.cat((future_edge_features, future_edge_orientations.float()), dim=1)\n",
    "        return {\n",
    "            \"history_indices\": history_indices,\n",
    "            \"future_indices\": future_indices,\n",
    "            \"history_coordinates\": history_coordinates,\n",
    "            \"future_coordinates\": future_coordinates,\n",
    "            \"history_one_hot_edges\": history_one_hot_edges,\n",
    "            \"future_one_hot_edges\": future_one_hot_edges,\n",
    "            \"history_edge_orientations\": history_edge_orientations,\n",
    "            \"future_edge_orientations\": future_edge_orientations,\n",
    "            \"history_edge_features\": history_edge_features,\n",
    "            \"future_edge_features\": future_edge_features,\n",
    "            \"node_in_history\": node_in_history,\n",
    "        }, self.graph, self.edges\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.trajectories)\n",
    "\n",
    "    def get_n_edges(self):\n",
    "        return self.graph.number_of_edges()\n",
    "    \n",
    "    def node_coordinates(self):\n",
    "        \"\"\"\n",
    "        Returns a tensor of shape [#nodes, 2] containing the coordinates of each node.\n",
    "        \"\"\"\n",
    "        coords = [attr['pos'] for _, attr in self.nodes]  # List of tuples (x, y)\n",
    "        coords_tensor = torch.tensor(coords, dtype=torch.float)  # Convert list to tensor\n",
    "        return coords_tensor\n",
    "    \n",
    "    def get_all_edges_tensor(self):\n",
    "        \"\"\"\n",
    "        Returns a tensor of shape [2, num_edges] where each column represents an edge\n",
    "        and the two entries in each column represent the nodes connected by that edge.\n",
    "        \"\"\"\n",
    "        edges = list(self.graph.edges())\n",
    "        edge_tensor = torch.tensor(edges, dtype=torch.long).t()\n",
    "        return edge_tensor\n",
    "\n",
    "def collate_fn(batch):\n",
    "    graph = [item[1] for item in batch]\n",
    "    edges = [item[2] for item in batch]\n",
    "    # Extract elements for each sample and stack them, handling variable lengths\n",
    "    history_indices = torch.stack([item[0]['history_indices'] for item in batch])\n",
    "    future_indices = torch.stack([item[0]['future_indices'] for item in batch])\n",
    "    \n",
    "    history_one_hot_edges = torch.stack([item[0]['history_one_hot_edges'] for item in batch])\n",
    "    future_one_hot_edges = torch.stack([item[0]['future_one_hot_edges'] for item in batch])\n",
    "\n",
    "    # Coordinates\n",
    "    history_coordinates = [item[0]['history_coordinates'] for item in batch if item[0]['history_coordinates'] is not None]\n",
    "    future_coordinates = [item[0]['future_coordinates'] for item in batch if item[0]['future_coordinates'] is not None]\n",
    "    \n",
    "    history_edge_orientations = torch.stack([item[0]['history_edge_orientations'] for item in batch])\n",
    "    future_edge_orientations = torch.stack([item[0]['future_edge_orientations'] for item in batch])\n",
    "    \n",
    "    history_edge_features = torch.stack([item[0]['history_edge_features'] for item in batch])\n",
    "    future_edge_features = torch.stack([item[0]['future_edge_features'] for item in batch])\n",
    "    \n",
    "    history_one_hot_nodes = torch.stack([item[0]['node_in_history'] for item in batch])\n",
    "    \n",
    "    # Stack coordinates if not empty\n",
    "    if history_coordinates:\n",
    "        history_coordinates = torch.stack(history_coordinates)\n",
    "    if future_coordinates:\n",
    "        future_coordinates = torch.stack(future_coordinates)\n",
    "\n",
    "    return {\n",
    "            \"history_indices\": history_indices,\n",
    "            \"future_indices\": future_indices,\n",
    "            \"history_coordinates\": history_coordinates,\n",
    "            \"future_coordinates\": future_coordinates,\n",
    "            \"history_one_hot_edges\": history_one_hot_edges,\n",
    "            \"future_one_hot_edges\": future_one_hot_edges,\n",
    "            \"history_edge_orientations\": history_edge_orientations,\n",
    "            \"future_edge_orientations\": future_edge_orientations,\n",
    "            \"history_edge_features\": history_edge_features,\n",
    "            \"future_edge_features\": future_edge_features,\n",
    "            \"history_one_hot_nodes\": history_one_hot_nodes,\n",
    "            \"graph\": graph,\n",
    "            \"edges\": edges,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeRNN(nn.Module):\n",
    "    def __init__(self, model_config, num_edge_features, num_edges):\n",
    "        super(EdgeRNN, self).__init__()\n",
    "        self.model_config = model_config\n",
    "        self.input_dim = num_edge_features\n",
    "        self.num_edges = num_edges\n",
    "        self.hidden_dim = self.model_config['hidden_channels']\n",
    "        self.num_layers = self.model_config['num_layers']\n",
    "        self.rnn = nn.RNN(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(self.hidden_dim, 1)  # Output one logit per neighbor\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_dim)\n",
    "    \n",
    "    def recursive_edge_prediction(self, edge_features, initial_edge, line_graph, future_len):\n",
    "        batch_size, num_edges, num_features = edge_features.size()\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(edge_features.device)\n",
    "        current_edge = initial_edge\n",
    "        predicted_edges = []\n",
    "        logits_list = []\n",
    "\n",
    "        for _ in range(future_len):\n",
    "            neighbors = self.get_neighbors(line_graph, current_edge, edge_features.device)  # shape: [batch_size, num_edges]\n",
    "            neighbor_features = self.get_neighbor_features(edge_features, neighbors)  # shape: [batch_size, num_neighbors, num_features]\n",
    "            max_num_neighbors = neighbors.sum(1).max().item()\n",
    "            logits, hidden = self.forward(neighbor_features, hidden)\n",
    "            logits = logits.squeeze(-1)  # Remove the last dimension to match [batch_size, num_neighbors]\n",
    "            \n",
    "            # Mask logits\n",
    "            mask = torch.arange(max_num_neighbors, device=edge_features.device).expand(len(neighbors), max_num_neighbors) < neighbors.sum(1, keepdim=True)\n",
    "            logits[~mask] = float(-10)\n",
    "            \n",
    "            logits_list.append(logits)\n",
    "            \n",
    "            _, predicted_edge_idx = torch.max(logits, dim=1)\n",
    "            #print(\"predicted_edge_idx\", predicted_edge_idx)\n",
    "            neighbor_indices = torch.nonzero(neighbors, as_tuple=True)\n",
    "            neighbor_indices = torch.split(neighbor_indices[1], neighbors.sum(dim=1).tolist())\n",
    "            max_len = max(len(s) for s in neighbor_indices)\n",
    "            neighbor_indices = torch.stack([F.pad(s, (0, max_len - len(s))) for s in neighbor_indices])\n",
    "            #print(\"Neighbor indices\", neighbor_indices)\n",
    "            predicted_edge = neighbor_indices.gather(1, predicted_edge_idx.unsqueeze(1)).squeeze(1)\n",
    "            #print(\"predicted_edge\", predicted_edge)\n",
    "\n",
    "            predicted_edges.append(predicted_edge)\n",
    "            current_edge = predicted_edge.unsqueeze(1)  # Update current edge for the next iteration\n",
    "        return logits_list, predicted_edges\n",
    "    \n",
    "    def get_neighbor_features(self, edge_features, neighbors):\n",
    "        batch_size, num_edges, num_features = edge_features.size()\n",
    "        neighbor_list = []\n",
    "        for i in range(batch_size):\n",
    "            if neighbors[i].sum() == 0:\n",
    "                neighbor_list.append(torch.zeros(1, num_features, dtype=torch.float))\n",
    "                continue\n",
    "            neighbor_indices = neighbors[i].nonzero(as_tuple=False).squeeze(1)\n",
    "            neighbor_list.append(edge_features[i, neighbor_indices])\n",
    "        \n",
    "        neighbor_features = torch.nn.utils.rnn.pad_sequence(neighbor_list, batch_first=True)\n",
    "        '''\n",
    "        # Filter out the row indicating the edge in the history!\n",
    "        filtered_neighbor_features = neighbor_features[~(neighbor_features[:, :, 0] == 1)]\n",
    "        filtered_neighbor_features = filtered_neighbor_features.view(neighbor_features.size(0), -1, neighbor_features.size(2))\n",
    "        return filtered_neighbor_features\n",
    "        '''\n",
    "        return neighbor_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = EdgeRNN\n",
    "\n",
    "    \n",
    "data_config = {\"dataset\": \"synthetic_2_traj\",\n",
    "    \"train_data_path\": '/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/data/synthetic_2_traj.h5',\n",
    "    \"test_data_path\": '/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/data/synthetic_2_traj.h5',\n",
    "    \"history_len\": 5,\n",
    "    \"future_len\": 2,\n",
    "    \"num_classes\": 2,\n",
    "    \"edge_features\": ['one_hot_edges', 'coordinates'],\n",
    "    \"one_hot_nodes\": False}\n",
    "\n",
    "model_config = {\"name\": \"mlp_benchmark\",\n",
    "    \"hidden_channels\": 32,\n",
    "    \"time_embedding_dim\": 16,\n",
    "    \"condition_dim\": 16,\n",
    "    \"out_ch\": 1,\n",
    "    \"num_heads\": 1,\n",
    "    \"num_layers\": 1,\n",
    "    \"theta\": 1.0, # controls strength of conv layers in residual model\n",
    "    \"dropout\": 0.1,\n",
    "    \"model_output\": \"logits\",\n",
    "    \"model_prediction\": \"x_start\",  # Options: 'x_start','xprev'\n",
    "    \"transition_mat_type\": 'gaussian',  # Options: 'gaussian','uniform','absorbing', 'marginal_prior'\n",
    "    \"transition_bands\": 1,\n",
    "    \"loss_type\": \"cross_entropy_x_start\",  # Options: kl, cross_entropy_x_start, hybrid\n",
    "    \"hybrid_coeff\": 0.001,  # Only used for hybrid loss type.\n",
    "    \"class_weights\": [0.05, 0.95] # = future_len/num_edges and (num_edges - future_len)/num_edges\n",
    "    }\n",
    "\n",
    "train_config = {\"batch_size\": 10,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"lr\": 0.01,\n",
    "    \"gradient_accumulation\": False,\n",
    "    \"gradient_accumulation_steps\": 2,\n",
    "    \"num_epochs\": 1000,\n",
    "    \"learning_rate_warmup_steps\": 2000, # previously 10000\n",
    "    \"lr_decay\": 0.9999, # previously 0.9999\n",
    "    \"log_loss_every_steps\": 20,\n",
    "    \"save_model\": False,\n",
    "    \"save_model_every_steps\": 1000}\n",
    "\n",
    "test_config = {\"batch_size\": 1, # currently only 1 works\n",
    "    \"model_path\": '/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/experiments/synthetic_d3pm_residual_fixed/synthetic_d3pm_residual_fixed_hidden_dim_32_time_dim_16_condition_dim_16_layers_2_weights_0.1.pth',\n",
    "    \"number_samples\": 1,\n",
    "    \"eval_every_steps\": 1000\n",
    "  }\n",
    "\n",
    "wandb_config = {\"exp_name\": \"tdrive_benchmark_test\",\n",
    "    \"project\": \"trajectory_prediction_using_denoising_diffusion_models\",\n",
    "    \"entity\": \"joeschmit99\",\n",
    "    \"job_type\": \"test\",\n",
    "    \"notes\": \"Benchmark test\",\n",
    "    \"tags\": [\"synthetic\", \"MLP_Benchmark\"]} \n",
    "\n",
    "model = Benchmark_Models(data_config, model_config, train_config, test_config, wandb_config, encoder_model)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import h5py\n",
    "import networkx as nx\n",
    "\n",
    "def load_new_format(new_file_path):\n",
    "    paths = []\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    with h5py.File(new_file_path, 'r') as new_hf:\n",
    "        node_coordinates = new_hf['graph']['node_coordinates'][:]\n",
    "        edges = new_hf['graph']['edges'][:]\n",
    "        edge_coordinates = node_coordinates[edges]\n",
    "        nodes = [(i, {'pos': tuple(pos)}) for i, pos in enumerate(node_coordinates)]\n",
    "        \n",
    "        if 'edge_indices' in new_hf['graph']:\n",
    "            edge_indices = new_hf['graph']['edge_indices'][:]\n",
    "            # Convert edges to a list of tuples\n",
    "            # Sort edges based on their saved indices\n",
    "            indexed_edges = sorted(zip(edges, edge_indices), key=lambda x: x[1])\n",
    "            edges = [edge for edge, _ in indexed_edges]\n",
    "        else:\n",
    "            edges = [tuple(edge) for edge in edges]\n",
    "\n",
    "        for i in tqdm(new_hf['trajectories'].keys()):\n",
    "            path_group = new_hf['trajectories'][i]\n",
    "            path = {attr: path_group[attr][()] for attr in path_group.keys()}\n",
    "            if 'edge_orientation' in path:\n",
    "                path['edge_orientations'] = path.pop('edge_orientation')\n",
    "            paths.append(path)\n",
    "\n",
    "    return paths, nodes, edges, edge_coordinates\n",
    "\n",
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, file_path, history_len, future_len, edge_features=None):\n",
    "        self.file_path = file_path\n",
    "        self.history_len = history_len\n",
    "        self.future_len = future_len\n",
    "        self.edge_features = edge_features\n",
    "        self.num_edge_features = 1\n",
    "        if 'coordinates' in self.edge_features:\n",
    "            self.num_edge_features = 5\n",
    "        if 'edge_orientations' in self.edge_features:\n",
    "            self.num_edge_features = 6\n",
    "        self.trajectories, self.nodes, self.edges, self.edge_coordinates = load_new_format(file_path)\n",
    "        self.edge_coordinates = torch.tensor(self.edge_coordinates, dtype=torch.float64)\n",
    "        \n",
    "        self.graph = nx.Graph()\n",
    "        indexed_edges = [((start, end), index) for index, (start, end) in enumerate(self.edges)]\n",
    "\n",
    "        # Add edges with index to the graph\n",
    "        for (start, end), index in indexed_edges:\n",
    "            self.graph.add_edge(start, end, index=index, default_orientation=(start, end))\n",
    "        self.graph.add_nodes_from(self.nodes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        trajectory = self.trajectories[idx]\n",
    "        edge_idxs = torch.tensor(trajectory['edge_idxs'][:], dtype=torch.long)\n",
    "        edge_orientations = torch.tensor(trajectory['edge_orientations'][:], dtype=torch.long)\n",
    "        \n",
    "        edge_coordinates_data = self.edge_coordinates[edge_idxs]\n",
    "\n",
    "        if len(edge_coordinates_data) > 0:\n",
    "            edge_coordinates_np = np.array(edge_coordinates_data)\n",
    "            edge_coordinates = torch.tensor(edge_coordinates_np, dtype=torch.float64)\n",
    "        else:\n",
    "            edge_coordinates = torch.tensor([], dtype=torch.float64)\n",
    "\n",
    "        # Reverse coordinates if orientation is -1\n",
    "        edge_coordinates[edge_orientations == -1] = edge_coordinates[edge_orientations == -1][:, [1, 0]]\n",
    "        \n",
    "        # Calculate the required padding length\n",
    "        total_len = self.history_len + self.future_len\n",
    "        padding_length = max(total_len - len(edge_idxs), 0)\n",
    "        \n",
    "        # Pad edge indices and orientations\n",
    "        edge_idxs = torch.nn.functional.pad(edge_idxs, (0, padding_length), value=-1)\n",
    "        edge_orientations = torch.nn.functional.pad(edge_orientations, (0, padding_length), value=0)\n",
    "        \n",
    "        # Pad coordinates\n",
    "        if padding_length > 0 and edge_coordinates.numel() > 0:\n",
    "            zero_padding = torch.zeros((padding_length, 2, 2), dtype=torch.float)\n",
    "            edge_coordinates = torch.cat([edge_coordinates, zero_padding], dim=0)\n",
    "        \n",
    "        # Split into history and future\n",
    "        history_indices = edge_idxs[:self.history_len]\n",
    "        future_indices = edge_idxs[self.history_len:self.history_len + self.future_len]\n",
    "        #history_coordinates = edge_coordinates[:self.history_len] if edge_coordinates.numel() > 0 else None\n",
    "        #future_coordinates = edge_coordinates[self.history_len:self.history_len + self.future_len] if edge_coordinates.numel() > 0 else None\n",
    "        \n",
    "        history_edge_orientations = torch.zeros(self.get_n_edges())\n",
    "        future_edge_orientations = torch.zeros(self.get_n_edges())\n",
    "\n",
    "        for index, i in enumerate(history_indices):\n",
    "            history_edge_orientations[i] = edge_orientations[index]\n",
    "        \n",
    "        for index, i in enumerate(future_indices):\n",
    "            future_edge_orientations[i] = edge_orientations[index]\n",
    "\n",
    "        # One-hot encoding of edge indices (ensure valid indices first)\n",
    "        valid_history_mask = history_indices >= 0\n",
    "        valid_future_mask = future_indices >= 0\n",
    "        \n",
    "        history_one_hot_edges = torch.nn.functional.one_hot(history_indices[valid_history_mask], num_classes=len(self.edges))\n",
    "        future_one_hot_edges = torch.nn.functional.one_hot(future_indices[valid_future_mask], num_classes=len(self.edges))\n",
    "        \n",
    "        # Sum across the time dimension to count occurrences of each edge\n",
    "        history_one_hot_edges = history_one_hot_edges.sum(dim=0)  # (num_edges,)\n",
    "        future_one_hot_edges = future_one_hot_edges.sum(dim=0)  # (num_edges,)\n",
    "        \n",
    "        # Generate the tensor indicating nodes in history\n",
    "        \"\"\"node_in_history = torch.zeros((len(self.nodes), 1), dtype=torch.float)\n",
    "        history_edges = [self.edges[i] for i in history_indices if i >= 0]\n",
    "        history_nodes = set(node for edge in history_edges for node in edge)\n",
    "        for node in history_nodes:\n",
    "            node_in_history[node] = 1\"\"\"\n",
    "            \n",
    "        # Basic History edge features = coordinates, binary encoding\n",
    "        history_edge_features = history_one_hot_edges.view(-1, 1).float()\n",
    "        future_edge_features = future_one_hot_edges.view(-1, 1).float()\n",
    "        if 'coordinates' in self.edge_features:\n",
    "            history_edge_features = torch.cat((history_edge_features, torch.flatten(self.edge_coordinates, start_dim=1).float()), dim=1)\n",
    "            future_edge_features = torch.cat((future_edge_features, torch.flatten(self.edge_coordinates, start_dim=1).float()), dim=1)\n",
    "            self.num_edge_features = 5\n",
    "        if 'edge_orientations' in self.edge_features:\n",
    "            history_edge_features = torch.cat((history_edge_features, history_edge_orientations.float()), dim=1)\n",
    "            future_edge_features = torch.cat((future_edge_features, future_edge_orientations.float()), dim=1)\n",
    "        return {\n",
    "            \"history_indices\": history_indices,\n",
    "            \"future_indices\": future_indices,\n",
    "            \"history_edge_features\": history_edge_features,\n",
    "            \"future_edge_features\": future_edge_features,\n",
    "            #\"history_coordinates\": history_coordinates,\n",
    "            #\"future_coordinates\": future_coordinates,\n",
    "            #\"history_one_hot_edges\": history_one_hot_edges,\n",
    "            #\"future_one_hot_edges\": future_one_hot_edges,\n",
    "            #\"history_edge_orientations\": history_edge_orientations,\n",
    "            #\"future_edge_orientations\": future_edge_orientations,\n",
    "            #\"node_in_history\": node_in_history,\n",
    "        }, self.graph# , self.edges\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.trajectories)\n",
    "\n",
    "    def get_n_edges(self):\n",
    "        return self.graph.number_of_edges()\n",
    "    \n",
    "    \"\"\"def node_coordinates(self):\n",
    "        \"\"\"\n",
    "        Returns a tensor of shape [#nodes, 2] containing the coordinates of each node.\n",
    "        \"\"\"\n",
    "        coords = [attr['pos'] for _, attr in self.nodes]  # List of tuples (x, y)\n",
    "        coords_tensor = torch.tensor(coords, dtype=torch.float)  # Convert list to tensor\n",
    "        return coords_tensor\n",
    "    \n",
    "    def get_all_edges_tensor(self):\n",
    "        \"\"\"\n",
    "        Returns a tensor of shape [2, num_edges] where each column represents an edge\n",
    "        and the two entries in each column represent the nodes connected by that edge.\n",
    "        \"\"\"\n",
    "        edges = list(self.graph.edges())\n",
    "        edge_tensor = torch.tensor(edges, dtype=torch.long).t()\n",
    "        return edge_tensor\"\"\"\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    graph = [item[1] for item in batch]\n",
    "    # edges = [item[2] for item in batch]\n",
    "    # Extract elements for each sample and stack them, handling variable lengths\n",
    "    history_indices = torch.stack([item[0]['history_indices'] for item in batch])\n",
    "    future_indices = torch.stack([item[0]['future_indices'] for item in batch])\n",
    "    \n",
    "    #history_one_hot_edges = torch.stack([item[0]['history_one_hot_edges'] for item in batch])\n",
    "    #future_one_hot_edges = torch.stack([item[0]['future_one_hot_edges'] for item in batch])\n",
    "\n",
    "    # Coordinates\n",
    "    #history_coordinates = [item[0]['history_coordinates'] for item in batch if item[0]['history_coordinates'] is not None]\n",
    "    #future_coordinates = [item[0]['future_coordinates'] for item in batch if item[0]['future_coordinates'] is not None]\n",
    "    \n",
    "    #history_edge_orientations = torch.stack([item[0]['history_edge_orientations'] for item in batch])\n",
    "    #future_edge_orientations = torch.stack([item[0]['future_edge_orientations'] for item in batch])\n",
    "    \n",
    "    history_edge_features = torch.stack([item[0]['history_edge_features'] for item in batch])\n",
    "    future_edge_features = torch.stack([item[0]['future_edge_features'] for item in batch])\n",
    "    \n",
    "    #history_one_hot_nodes = torch.stack([item[0]['node_in_history'] for item in batch])\n",
    "    \n",
    "    # Stack coordinates if not empty\n",
    "    \"\"\"if history_coordinates:\n",
    "        history_coordinates = torch.stack(history_coordinates)\n",
    "    if future_coordinates:\n",
    "        future_coordinates = torch.stack(future_coordinates)\"\"\"\n",
    "\n",
    "    return {\n",
    "            \"history_indices\": history_indices,\n",
    "            \"future_indices\": future_indices,\n",
    "            #\"history_coordinates\": history_coordinates,\n",
    "            #\"future_coordinates\": future_coordinates,\n",
    "            #\"history_one_hot_edges\": history_one_hot_edges,\n",
    "            #\"future_one_hot_edges\": future_one_hot_edges,\n",
    "            #\"history_edge_orientations\": history_edge_orientations,\n",
    "            #\"future_edge_orientations\": future_edge_orientations,\n",
    "            \"history_edge_features\": history_edge_features,\n",
    "            \"future_edge_features\": future_edge_features,\n",
    "            #\"history_one_hot_nodes\": history_one_hot_nodes,\n",
    "            \"graph\": graph,\n",
    "            # \"edges\": edges,\n",
    "        }'''\n",
    "        \n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import h5py\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, file_path, history_len, future_len, edge_features=None, device=None):\n",
    "        self.file_path = file_path\n",
    "        self.history_len = history_len\n",
    "        self.future_len = future_len\n",
    "        self.edge_features = edge_features\n",
    "        self.device = device\n",
    "        self.num_edge_features = 1\n",
    "        if 'coordinates' in self.edge_features:\n",
    "            self.num_edge_features = 5\n",
    "        if 'edge_orientations' in self.edge_features:\n",
    "            self.num_edge_features = 6\n",
    "        self.trajectories, self.nodes, self.edges, self.edge_coordinates = self.load_new_format(file_path, self.device)\n",
    "        \n",
    "        self.edge_coordinates = torch.tensor(self.edge_coordinates, dtype=torch.float64, device=self.device)\n",
    "        \n",
    "    @staticmethod\n",
    "    def load_new_format(file_path, device):\n",
    "        paths = []\n",
    "        with h5py.File(file_path, 'r') as new_hf:\n",
    "            node_coordinates = torch.tensor(new_hf['graph']['node_coordinates'][:], dtype=torch.float, device=device)\n",
    "            #edges = torch.tensor(new_hf['graph']['edges'][:], dtype=torch.long, device=device)\n",
    "            edges = new_hf['graph']['edges'][:]\n",
    "            edge_coordinates = node_coordinates[edges]\n",
    "            nodes = [(i, {'pos': torch.tensor(pos, device=device)}) for i, pos in enumerate(node_coordinates)]\n",
    "            #edges = [(torch.tensor(edge[0], device=device), torch.tensor(edge[1], device=device)) for edge in edges]\n",
    "            edges = [tuple(edge) for edge in edges]\n",
    "\n",
    "            for i in tqdm(new_hf['trajectories'].keys()):\n",
    "                path_group = new_hf['trajectories'][i]\n",
    "                path = {attr: torch.tensor(path_group[attr][()], device=device) for attr in path_group.keys() if attr in ['coordinates', 'edge_idxs', 'edge_orientations']}\n",
    "                paths.append(path)\n",
    "            \n",
    "        return paths, nodes, edges, edge_coordinates\n",
    "    \n",
    "    # @staticmethod\n",
    "    def build_graph(self):\n",
    "        graph = nx.Graph()\n",
    "        graph.add_nodes_from(self.nodes)\n",
    "        indexed_edges = [((start, end), index) for index, (start, end) in enumerate(self.edges)]\n",
    "        for (start, end), index in indexed_edges:\n",
    "            graph.add_edge(start, end, index=index, default_orientation=(start, end))\n",
    "        return graph\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        trajectory = self.trajectories[idx]\n",
    "    \n",
    "        edge_idxs = trajectory['edge_idxs']\n",
    "        if 'edge_orientations' in self.edge_features:\n",
    "            edge_orientations = trajectory['edge_orientations']\n",
    "        \n",
    "        # Calculate the required padding length\n",
    "        total_len = self.history_len + self.future_len\n",
    "        padding_length = max(total_len - len(edge_idxs), 0)\n",
    "        \n",
    "        # Pad edge indices, orientations, and coordinates\n",
    "        edge_idxs = torch.nn.functional.pad(edge_idxs, (0, padding_length), value=-1)\n",
    "        if 'edge_orientations' in self.edge_features:\n",
    "            edge_orientations = torch.nn.functional.pad(edge_orientations, (0, padding_length), value=0)\n",
    "        \n",
    "        # Split into history and future\n",
    "        history_indices = edge_idxs[:self.history_len]\n",
    "        future_indices = edge_idxs[self.history_len:self.history_len + self.future_len]\n",
    "\n",
    "        # Extract and generate features\n",
    "        history_edge_features, future_edge_features = self.generate_edge_features(history_indices, future_indices, self.edge_coordinates)\n",
    "\n",
    "        return {\n",
    "            \"history_indices\": history_indices,\n",
    "            \"future_indices\": future_indices,\n",
    "            \"history_edge_features\": history_edge_features,\n",
    "            \"future_edge_features\": future_edge_features,\n",
    "        }\n",
    "\n",
    "    def generate_edge_features(self, history_indices, future_indices, history_edge_orientations=None, future_edge_orientations=None):\n",
    "        # Binary on/off edges\n",
    "        valid_history_mask = history_indices >= 0\n",
    "        valid_future_mask = future_indices >= 0\n",
    "        \n",
    "        history_one_hot_edges = torch.nn.functional.one_hot(history_indices[valid_history_mask], num_classes=len(self.edges))\n",
    "        future_one_hot_edges = torch.nn.functional.one_hot(future_indices[valid_future_mask], num_classes=len(self.edges))\n",
    "        \n",
    "        # Sum across the time dimension to count occurrences of each edge\n",
    "        history_one_hot_edges = history_one_hot_edges.sum(dim=0)  # (num_edges,)\n",
    "        future_one_hot_edges = future_one_hot_edges.sum(dim=0)  # (num_edges,)\n",
    "        \n",
    "        # Basic History edge features = coordinates, binary encoding\n",
    "        history_edge_features = history_one_hot_edges.view(-1, 1).float()\n",
    "        future_edge_features = future_one_hot_edges.view(-1, 1).float()\n",
    "        if 'coordinates' in self.edge_features:\n",
    "            history_edge_features = torch.cat((history_edge_features, torch.flatten(self.edge_coordinates, start_dim=1).float()), dim=1)\n",
    "            future_edge_features = torch.cat((future_edge_features, torch.flatten(self.edge_coordinates, start_dim=1).float()), dim=1)\n",
    "            pass\n",
    "        if 'edge_orientations' in self.edge_features:\n",
    "            history_edge_features = torch.cat((history_edge_features, history_edge_orientations.float()), dim=1)\n",
    "            future_edge_features = torch.cat((future_edge_features, future_edge_orientations.float()), dim=1)\n",
    "        return history_edge_features, future_edge_features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.trajectories)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    history_indices = torch.stack([item['history_indices'] for item in batch])\n",
    "    future_indices = torch.stack([item['future_indices'] for item in batch])\n",
    "    history_edge_features = torch.stack([item['history_edge_features'] for item in batch])\n",
    "    future_edge_features = torch.stack([item['future_edge_features'] for item in batch])\n",
    "\n",
    "    return {\n",
    "        \"history_indices\": history_indices,\n",
    "        \"future_indices\": future_indices,\n",
    "        \"history_edge_features\": history_edge_features,\n",
    "        \"future_edge_features\": future_edge_features,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2024 The Google Research Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"Diffusion for discrete state spaces.\"\"\"\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def make_diffusion(diffusion_config, model_config, num_edges, future_len, device):\n",
    "    \"\"\"HParams -> diffusion object.\"\"\"\n",
    "    return CategoricalDiffusion(\n",
    "        betas=get_diffusion_betas(diffusion_config, device),\n",
    "        model_prediction=model_config['model_prediction'],\n",
    "        model_output=model_config['model_output'],\n",
    "        transition_mat_type=model_config['transition_mat_type'],\n",
    "        transition_bands=model_config['transition_bands'],\n",
    "        loss_type=model_config['loss_type'],\n",
    "        hybrid_coeff=model_config['hybrid_coeff'],\n",
    "        num_edges=num_edges,\n",
    "        model_name=model_config['name'],\n",
    "        future_len=future_len,\n",
    "        device=device\n",
    ")\n",
    "\n",
    "\n",
    "def get_diffusion_betas(spec, device):\n",
    "    \"\"\"Get betas from the hyperparameters.\"\"\"\n",
    "    \n",
    "    if spec['type'] == 'linear':\n",
    "        # Used by Ho et al. for DDPM, https://arxiv.org/abs/2006.11239.\n",
    "        # To be used with Gaussian diffusion models in continuous and discrete\n",
    "        # state spaces.\n",
    "        # To be used with transition_mat_type = 'gaussian'\n",
    "        return torch.linspace(spec['start'], spec['stop'], spec['num_timesteps']).to(device)\n",
    "    elif spec['type'] == 'cosine':\n",
    "        # Schedule proposed by Hoogeboom et al. https://arxiv.org/abs/2102.05379\n",
    "        # To be used with transition_mat_type = 'uniform'.\n",
    "        steps = torch.linspace(0, 1, spec['num_timesteps'] + 1, dtype=torch.float64)\n",
    "        alpha_bar = torch.cos((steps + 0.008) / 1.008 * torch.pi / 2)\n",
    "        betas = torch.minimum(1 - alpha_bar[1:] / alpha_bar[:-1], torch.tensor(0.999))\n",
    "        return betas.to(device)\n",
    "    elif spec['type'] == 'jsd':  # 1/T, 1/(T-1), 1/(T-2), ..., 1\n",
    "        # Proposed by Sohl-Dickstein et al., https://arxiv.org/abs/1503.03585\n",
    "        # To be used with absorbing state models.\n",
    "        # ensures that the probability of decaying to the absorbing state\n",
    "        # increases linearly over time, and is 1 for t = T-1 (the final time).\n",
    "        # To be used with transition_mat_type = 'absorbing'\n",
    "        return 1. / torch.linspace(spec['num_timesteps'], 1, spec['num_timesteps']).to(device)\n",
    "    else:\n",
    "        raise NotImplementedError(spec['type'])\n",
    "\n",
    "\n",
    "class CategoricalDiffusion:\n",
    "    \"\"\"Discrete state space diffusion process.\n",
    "\n",
    "    Time convention: noisy data is labeled x_0, ..., x_{T-1}, and original data\n",
    "    is labeled x_start (or x_{-1}). This convention differs from the papers,\n",
    "    which use x_1, ..., x_T for noisy data and x_0 for original data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *, betas, model_prediction, model_output,\n",
    "               transition_mat_type, transition_bands, loss_type, hybrid_coeff,\n",
    "               num_edges, torch_dtype=torch.float32, model_name=None, future_len=None, device=None):\n",
    "\n",
    "        self.model_prediction = model_prediction  # *x_start*, xprev\n",
    "        self.model_output = model_output  # logits or *logistic_pars*\n",
    "        self.loss_type = loss_type  # kl, *hybrid*, cross_entropy_x_start\n",
    "        self.hybrid_coeff = hybrid_coeff\n",
    "        self.torch_dtype = torch_dtype\n",
    "        self.model_name = model_name\n",
    "        self.device = device\n",
    "\n",
    "        # Data \\in {0, ..., num_edges-1}\n",
    "        self.num_classes = 2 # 0 or 1\n",
    "        self.num_edges = num_edges\n",
    "        self.future_len = future_len\n",
    "        self.class_weights = torch.tensor([self.future_len / self.num_edges, 1 - self.future_len / self.num_edges], dtype=torch.float64)\n",
    "        self.class_probs = torch.tensor([1 - self.future_len / self.num_edges, self.future_len / self.num_edges], dtype=torch.float64)\n",
    "        self.transition_bands = transition_bands\n",
    "        self.transition_mat_type = transition_mat_type\n",
    "        self.eps = 1.e-6\n",
    "\n",
    "        if not isinstance(betas, torch.Tensor):\n",
    "            raise ValueError('expected betas to be a torch tensor')\n",
    "        if not ((betas > 0).all() and (betas <= 1).all()):\n",
    "            raise ValueError('betas must be in (0, 1]')\n",
    "\n",
    "        # Computations here in float64 for accuracy\n",
    "        self.betas = betas.to(dtype=torch.float64).to(self.device, non_blocking=True)\n",
    "        self.num_timesteps, = betas.shape\n",
    "\n",
    "        # Construct transition matrices for q(x_t|x_{t-1})\n",
    "        # NOTE: t goes from {0, ..., T-1}\n",
    "        if self.transition_mat_type == 'uniform':\n",
    "            q_one_step_mats = [self._get_transition_mat(t) \n",
    "                            for t in range(0, self.num_timesteps)]\n",
    "        elif self.transition_mat_type == 'gaussian':\n",
    "            q_one_step_mats = [self._get_gaussian_transition_mat(t)\n",
    "                            for t in range(0, self.num_timesteps)]\n",
    "        elif self.transition_mat_type == 'absorbing':\n",
    "            q_one_step_mats = [self._get_absorbing_transition_mat(t)\n",
    "                            for t in range(0, self.num_timesteps)]\n",
    "        elif self.transition_mat_type == 'marginal_prior':\n",
    "            q_one_step_mats = [self._get_prior_distribution_transition_mat(t)\n",
    "                               for t in range(0, self.num_timesteps)]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"transition_mat_type must be 'gaussian', 'uniform', 'absorbing' \"\n",
    "                f\", but is {self.transition_mat_type}\"\n",
    "                )\n",
    "\n",
    "        self.q_onestep_mats = torch.stack(q_one_step_mats, axis=0).to(self.device, non_blocking=True)\n",
    "        assert self.q_onestep_mats.shape == (self.num_timesteps,\n",
    "                                            self.num_classes,\n",
    "                                            self.num_classes)\n",
    "\n",
    "        # Construct transition matrices for q(x_t|x_start)\n",
    "        q_mat_t = self.q_onestep_mats[0]\n",
    "        q_mats = [q_mat_t]\n",
    "        for t in range(1, self.num_timesteps):\n",
    "            # Q_{1...t} = Q_{1 ... t-1} Q_t = Q_1 Q_2 ... Q_t\n",
    "            q_mat_t = torch.tensordot(q_mat_t, self.q_onestep_mats[t],\n",
    "                                    dims=[[1], [0]])\n",
    "            q_mats.append(q_mat_t)\n",
    "        self.q_mats = torch.stack(q_mats, axis=0)\n",
    "        assert self.q_mats.shape == (self.num_timesteps, self.num_classes,\n",
    "                                    self.num_classes), self.q_mats.shape\n",
    "\n",
    "        # Don't precompute transition matrices for q(x_{t-1} | x_t, x_start)\n",
    "        # Can be computed from self.q_mats and self.q_one_step_mats.\n",
    "        # Only need transpose of q_onestep_mats for posterior computation.\n",
    "        self.transpose_q_onestep_mats = torch.transpose(self.q_onestep_mats, dim0=1, dim1=2)\n",
    "        del self.q_onestep_mats\n",
    "\n",
    "    def _get_full_transition_mat(self, t):\n",
    "        \"\"\"Computes transition matrix for q(x_t|x_{t-1}).\n",
    "\n",
    "        Contrary to the band diagonal version, this method constructs a transition\n",
    "        matrix with uniform probability to all other states.\n",
    "\n",
    "        Args:\n",
    "            t: timestep. integer scalar.\n",
    "\n",
    "        Returns:\n",
    "            Q_t: transition matrix. shape = (num_classes, num_classes).\n",
    "        \"\"\"\n",
    "        beta_t = self.betas[t]\n",
    "        # Create a matrix filled with beta_t/num_classes\n",
    "        mat = torch.full((self.num_classes, self.num_classes), \n",
    "                            fill_value=beta_t / float(self.num_classes),\n",
    "                            dtype=torch.float64)\n",
    "\n",
    "        # Create a diagonal matrix with values to be set on the diagonal of mat\n",
    "        diag_val = 1. - beta_t * (self.num_classes - 1.) / self.num_classes\n",
    "        diag_matrix = torch.diag(torch.full((self.num_classes,), diag_val, dtype=torch.float64))\n",
    "\n",
    "        # Set the diagonal values\n",
    "        mat.fill_diagonal_(diag_val)\n",
    "\n",
    "        return mat\n",
    "\n",
    "    def _get_transition_mat(self, t):\n",
    "        r\"\"\"Computes transition matrix for q(x_t|x_{t-1}).\n",
    "\n",
    "        This method constructs a transition\n",
    "        matrix Q with\n",
    "        Q_{ij} = beta_t / num_classes       if |i-j| <= self.transition_bands\n",
    "                1 - \\sum_{l \\neq i} Q_{il} if i==j.\n",
    "                0                          else.\n",
    "\n",
    "        Args:\n",
    "        t: timestep. integer scalar (or numpy array?)\n",
    "\n",
    "        Returns:\n",
    "        Q_t: transition matrix. shape = (num_classes, num_classes).\n",
    "        \"\"\"\n",
    "        if self.transition_bands is None:\n",
    "            return self._get_full_transition_mat(t)\n",
    "        # Assumes num_off_diags < num_classes\n",
    "        beta_t = self.betas[t]\n",
    "        \n",
    "        mat = torch.zeros((self.num_classes, self.num_classes),\n",
    "                        dtype=torch.float64)\n",
    "        off_diag = torch.full((self.num_classes - 1,), fill_value=beta_t / float(self.num_classes), dtype=torch.float64)\n",
    "\n",
    "        for k in range(1, self.transition_bands + 1):\n",
    "            mat += torch.diag(off_diag, k)\n",
    "            mat += torch.diag(off_diag, -k)\n",
    "            off_diag = off_diag[:-1]\n",
    "\n",
    "        # Add diagonal values such that rows sum to one\n",
    "        diag = 1. - mat.sum(dim=1)\n",
    "        mat += torch.diag(diag)\n",
    "        \n",
    "        return mat\n",
    "\n",
    "    def _get_gaussian_transition_mat(self, t):\n",
    "        r\"\"\"Computes transition matrix for q(x_t|x_{t-1}).\n",
    "\n",
    "        This method constructs a transition matrix Q with\n",
    "        decaying entries as a function of how far off diagonal the entry is.\n",
    "        Normalization option 1:\n",
    "        Q_{ij} =  ~ softmax(-val^2/beta_t)   if |i-j| <= self.transition_bands\n",
    "                    1 - \\sum_{l \\neq i} Q_{il}  if i==j.\n",
    "                    0                          else.\n",
    "\n",
    "        Normalization option 2:\n",
    "        tilde{Q}_{ij} =  softmax(-val^2/beta_t)   if |i-j| <= self.transition_bands\n",
    "                            0                        else.\n",
    "\n",
    "        Q_{ij} =  tilde{Q}_{ij} / sum_l{tilde{Q}_{lj}}\n",
    "\n",
    "        Args:\n",
    "            t: timestep. integer scalar (or numpy array?)\n",
    "\n",
    "        Returns:\n",
    "            Q_t: transition matrix. shape = (num_classes, num_classes).\n",
    "        \"\"\"\n",
    "        transition_bands = self.transition_bands if self.transition_bands else self.num_classes - 1\n",
    "\n",
    "        beta_t = self.betas[t]\n",
    "\n",
    "        mat = torch.zeros((self.num_classes, self.num_classes),\n",
    "                        dtype=torch.float64).to(self.device, non_blocking=True)\n",
    "\n",
    "        # Make the values correspond to a similar type of gaussian as in the\n",
    "        # gaussian diffusion case for continuous state spaces.\n",
    "        values = torch.linspace(torch.tensor(0.), torch.tensor(self.num_classes-1), self.num_classes, dtype=torch.float64).to(self.device, non_blocking=True)\n",
    "        values = values * 2./ (self.num_classes - 1.)\n",
    "        values = values[:transition_bands+1]\n",
    "        values = -values * values / beta_t\n",
    "        \n",
    "        # To reverse the tensor 'values' starting from the second element\n",
    "        reversed_values = values[1:].flip(dims=[0])\n",
    "        # Concatenating the reversed values with the original values\n",
    "        values = torch.cat([reversed_values, values], dim=0)\n",
    "        values = F.softmax(values, dim=0)\n",
    "        values = values[transition_bands:]\n",
    "        \n",
    "        for k in range(1, transition_bands + 1):\n",
    "            off_diag = torch.full((self.num_classes - k,), values[k], dtype=torch.float64).to(self.device, non_blocking=True)\n",
    "\n",
    "            mat += torch.diag(off_diag, k)\n",
    "            mat += torch.diag(off_diag, -k)\n",
    "\n",
    "        # Add diagonal values such that rows and columns sum to one.\n",
    "        # Technically only the ROWS need to sum to one\n",
    "        # NOTE: this normalization leads to a doubly stochastic matrix,\n",
    "        # which is necessary if we want to have a uniform stationary distribution.\n",
    "        diag = 1. - mat.sum(dim=1)\n",
    "        mat += torch.diag_embed(diag)\n",
    "\n",
    "        return mat.to(self.device, non_blocking=True)\n",
    "\n",
    "    def _get_absorbing_transition_mat(self, t):\n",
    "        \"\"\"Computes transition matrix for q(x_t|x_{t-1}).\n",
    "\n",
    "        Has an absorbing state for pixelvalues self.num_classes//2.\n",
    "\n",
    "        Args:\n",
    "        t: timestep. integer scalar.\n",
    "\n",
    "        Returns:\n",
    "        Q_t: transition matrix. shape = (num_classes, num_classes).\n",
    "        \"\"\"\n",
    "        beta_t = self.betas[t]\n",
    "\n",
    "        diag = torch.full((self.num_classes,), 1. - beta_t, dtype=torch.float64).to(self.device, non_blocking=True)\n",
    "        mat = torch.diag(diag)\n",
    "\n",
    "        # Add beta_t to the num_classes/2-th column for the absorbing state\n",
    "        mat[:, self.num_classes // 2] += beta_t\n",
    "\n",
    "        return mat\n",
    "    \n",
    "    def _get_prior_distribution_transition_mat(self, t):\n",
    "        \"\"\"Computes transition matrix for q(x_t|x_{t-1}).\n",
    "        Use cosine schedule for these transition matrices.\n",
    "\n",
    "        Args:\n",
    "        t: timestep. integer scalar.\n",
    "\n",
    "        Returns:\n",
    "        Q_t: transition matrix. shape = (num_classes, num_classes).\n",
    "        \"\"\"\n",
    "        beta_t = self.betas[t]\n",
    "        mat = torch.zeros((self.num_classes, self.num_classes), dtype=torch.float64).to(self.device, non_blocking=True)\n",
    "\n",
    "        for i in range(self.num_classes):\n",
    "            for j in range(self.num_classes):\n",
    "                if i != j:\n",
    "                    mat[i, j] = beta_t * self.class_probs[j]\n",
    "                else:\n",
    "                    mat[i, j] = 1 - beta_t + beta_t * self.class_probs[j]\n",
    "        \n",
    "        return mat\n",
    "\n",
    "    def _at(self, a, t, x):\n",
    "        \"\"\"\n",
    "        Extract coefficients at specified timesteps t and conditioning data x in PyTorch.\n",
    "\n",
    "        Args:\n",
    "        a: torch.Tensor: PyTorch tensor of constants indexed by time, dtype should be pre-set.\n",
    "        t: torch.Tensor: PyTorch tensor of time indices, shape = (batch_size,).\n",
    "        x: torch.Tensor: PyTorch tensor of shape (bs, ...) of int32 or int64 type.\n",
    "            (Noisy) data. Should not be of one-hot representation, but have integer\n",
    "            values representing the class values. --> NOT A LOT NEEDS TO CHANGE, MY CLASS VALUES ARE SIMPLY 0 AND 1\n",
    "\n",
    "        Returns:\n",
    "        a[t, x]: torch.Tensor: PyTorch tensor.\n",
    "        \"\"\"\n",
    "        ### Original ###\n",
    "        # x.shape = (bs, height, width, channels)\n",
    "        # t_broadcast_shape = (bs, 1, 1, 1)\n",
    "        # a.shape = (num_timesteps, num_pixel_vals, num_pixel_vals)\n",
    "        # out.shape = (bs, height, width, channels, num_pixel_vals)\n",
    "        # out[i, j, k, l, m] = a[t[i, j, k, l], x[i, j, k, l], m]\n",
    "        \n",
    "        ### New ###\n",
    "        # x.shape = (bs, num_edges, channels=1) \n",
    "        # t_broadcast_shape = (bs, 1, 1)\n",
    "        # a.shape = (num_timesteps, num_classes, num_classes) \n",
    "        # out.shape = (bs, num_edges, channels, num_classes) \n",
    "        \n",
    "        # Convert `a` to the desired dtype if not already\n",
    "        a = a.type(self.torch_dtype)\n",
    "\n",
    "        # Prepare t for broadcasting by adding necessary singleton dimensions\n",
    "        t_broadcast = t.view(-1, *((1,) * (x.ndim - 1))).to(self.device, non_blocking=True)\n",
    "\n",
    "        # Advanced indexing in PyTorch to select elements\n",
    "        return a[t_broadcast, x.long()].to(self.device, non_blocking=True)\n",
    "\n",
    "    def _at_onehot(self, a, t, x):\n",
    "        \"\"\"Extract coefficients at specified timesteps t and conditioning data x.\n",
    "\n",
    "        Args:\n",
    "        a: torch.Tensor: PyTorch tensor of constants indexed by time, dtype should be pre-set.\n",
    "        t: torch.Tensor: PyTorch tensor of time indices, shape = (batch_size,).\n",
    "        x: torch.Tensor: PyTorch tensor of shape (bs, ...) of float32 type.\n",
    "            (Noisy) data. Should be of one-hot-type representation.\n",
    "\n",
    "        Returns:\n",
    "        out: torch.tensor: output of dot(x, a[t], axis=[[-1], [1]]).\n",
    "            shape = (bs, num_edges, channels=1, num_classes)\n",
    "        \"\"\"\n",
    "        a = a.type(self.torch_dtype)\n",
    "        \n",
    "        ### Final ###\n",
    "        # t.shape = (bs)\n",
    "        # x.shape = (bs, num_edges, num_classes)\n",
    "        # a[t].shape = (bs, num_classes, num_classes)\n",
    "        # out.shape = (bs, num_edges, num_classes)\n",
    "\n",
    "        a_t = a[t]\n",
    "        out = torch.einsum('bik,bkj->bij', x, a_t).to(self.device, non_blocking=True)\n",
    "        \n",
    "        return out.to(self.device, non_blocking=True)\n",
    "\n",
    "    def q_probs(self, x_start, t):\n",
    "        \"\"\"Compute probabilities of q(x_t | x_start).\n",
    "\n",
    "        Args:\n",
    "        x_start: torch.tensor: tensor of shape (bs, ...) of int32 or int64 type.\n",
    "            Should not be of one hot representation, but have integer values\n",
    "            representing the class values.\n",
    "        t: torch.tensor: torch tensor of shape (bs,).\n",
    "\n",
    "        Returns:\n",
    "        probs: torch.tensor: shape (bs, x_start.shape[1:],\n",
    "                                                num_classes).\n",
    "        \"\"\"\n",
    "        return self._at(self.q_mats, t, x_start)\n",
    "\n",
    "    def q_sample(self, x_start, t, noise):\n",
    "        \"\"\"\n",
    "        Sample from q(x_t | x_start) (i.e. add noise to the data) using Gumbel softmax trick.\n",
    "\n",
    "        Args:\n",
    "        x_start: torch.tensor: original clean data, in integer form (not onehot).\n",
    "            shape = (bs, num_edges).\n",
    "        t: torch.tensor: timestep of the diffusion process, shape (bs,).\n",
    "        noise: torch.tensor: uniform noise on [0, 1) used to sample noisy data.\n",
    "            shape should match (*x_start.shape, num_classes).\n",
    "\n",
    "        Returns:\n",
    "        sample: torch.tensor: same shape as x_start. noisy data.\n",
    "        \"\"\"\n",
    "        assert noise.shape == x_start.shape + (self.num_classes,)\n",
    "        logits = torch.log(self.q_probs(x_start, t) + self.eps)\n",
    "\n",
    "        # To avoid numerical issues, clip the noise to a minimum value\n",
    "        noise = torch.clamp(noise, min=torch.finfo(noise.dtype).tiny, max=1.)\n",
    "        gumbel_noise = -torch.log(-torch.log(noise)).to(self.device, non_blocking=True)\n",
    "        return torch.argmax(logits + gumbel_noise, dim=-1)\n",
    "    \n",
    "    def _get_logits_from_logistic_pars(self, loc, log_scale):\n",
    "        \"\"\"\n",
    "        Computes logits for an underlying logistic distribution.\n",
    "\n",
    "        Args:\n",
    "        loc: torch.tensor: location parameter of logistic distribution.\n",
    "        log_scale: torch.tensor: log scale parameter of logistic distribution.\n",
    "\n",
    "        Returns:\n",
    "        logits: torch.tensor: logits corresponding to logistic distribution\n",
    "        \"\"\"\n",
    "        loc = loc.unsqueeze(-1)\n",
    "        log_scale = log_scale.unsqueeze(-1)\n",
    "\n",
    "        # Adjust the scale such that if it's zero, the probabilities have a scale\n",
    "        # that is neither too wide nor too narrow.\n",
    "        inv_scale = torch.exp(- (log_scale - 2.))\n",
    "\n",
    "        bin_width = 2. / (self.num_classes - 1.)\n",
    "        bin_centers = torch.linspace(-1., 1., self.num_classes)\n",
    "\n",
    "        bin_centers = bin_centers.unsqueeze(0)  # Add batch dimension\n",
    "        bin_centers = bin_centers - loc\n",
    "\n",
    "        log_cdf_min = -F.softplus(-inv_scale * (bin_centers - 0.5 * bin_width))\n",
    "        log_cdf_plus = -F.softplus(-inv_scale * (bin_centers + 0.5 * bin_width))\n",
    "\n",
    "        logits = torch.log(torch.exp(log_cdf_plus) - torch.exp(log_cdf_min) + self.eps)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def q_posterior_logits(self, x_start, x_t, t, x_start_logits):\n",
    "        \"\"\"Compute logits of q(x_{t-1} | x_t, x_start) in PyTorch.\"\"\"\n",
    "        \n",
    "        if x_start_logits:\n",
    "            assert x_start.shape == x_t.shape + (self.num_classes,), (x_start.shape, x_t.shape)\n",
    "        else:\n",
    "            assert x_start.shape == x_t.shape, (x_start.shape, x_t.shape)\n",
    "            \n",
    "        fact1 = self._at(self.transpose_q_onestep_mats, t, x_t)\n",
    "        if x_start_logits:\n",
    "            fact2 = self._at_onehot(self.q_mats, t-1, F.softmax(x_start, dim=-1))\n",
    "            tzero_logits = x_start\n",
    "        else:\n",
    "            fact2 = self._at(self.q_mats, t-1, x_start)\n",
    "            tzero_logits = torch.log(F.one_hot(x_start.to(torch.int64), num_classes=self.num_classes) + self.eps)\n",
    "\n",
    "        out = torch.log(fact1 + self.eps) + torch.log(fact2 + self.eps)\n",
    "\n",
    "        t_broadcast = t.unsqueeze(1).unsqueeze(2)  # Adds new dimensions: [batch_size, 1, 1]\n",
    "        t_broadcast = t_broadcast.expand(-1, tzero_logits.size(1), tzero_logits.size(-1)).to(self.device, non_blocking=True)   # tzero_logits.size(1) = num_edges, tzero_logits.size(-1) = num_classes\n",
    "\n",
    "        return torch.where(t_broadcast == 0, tzero_logits, out) # (bs, num_edges, num_classes)\n",
    "\n",
    "    def p_logits(self, model_fn, x, t, edge_features=None, edge_index=None, condition=None):\n",
    "        \"\"\"Compute logits of p(x_{t-1} | x_t) in PyTorch.\n",
    "\n",
    "        Args:\n",
    "            model_fn (function): The model function that takes input `x` and `t` and returns the model output.\n",
    "            x (torch.Tensor): The input tensor of shape (batch_size, input_size) representing the noised input at time t.\n",
    "            t (torch.Tensor): The time tensor of shape (batch_size,) representing the time step.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing two tensors:\n",
    "                - model_logits (torch.Tensor): The logits of p(x_{t-1} | x_t) of shape (batch_size, input_size, num_classes).\n",
    "                - pred_x_start_logits (torch.Tensor): The logits of p(x_{t-1} | x_start) of shape (batch_size, input_size, num_classes).\n",
    "        \"\"\"\n",
    "        assert t.shape == (x.shape[0],)\n",
    "        model_output = model_fn(edge_features, edge_index, t, condition=condition)\n",
    "\n",
    "        if self.model_output == 'logits':\n",
    "            model_logits = model_output\n",
    "        elif self.model_output == 'logistic_pars':\n",
    "            loc, log_scale = model_output\n",
    "            model_logits = self._get_logits_from_logistic_pars(loc, log_scale)\n",
    "        else:\n",
    "            raise NotImplementedError(self.model_output)\n",
    "\n",
    "        if self.model_prediction == 'x_start':\n",
    "            pred_x_start_logits = model_logits\n",
    "            t_broadcast = t.unsqueeze(1).unsqueeze(2)  # Adds new dimensions: [batch_size, 1, 1]\n",
    "            t_broadcast = t_broadcast.expand(-1, pred_x_start_logits.size(1), pred_x_start_logits.size(-1)).to(self.device, non_blocking=True)   # pred_x_start_logits.size(1) = num_edges, pred_x_start_logits.size(-1) = num_classes\n",
    "            model_logits = torch.where(t_broadcast == 0, pred_x_start_logits,\n",
    "                                       self.q_posterior_logits(x_start=pred_x_start_logits, x_t=x, t=t, x_start_logits=True))\n",
    "            \n",
    "        elif self.model_prediction == 'xprev':\n",
    "            pred_x_start_logits = model_logits\n",
    "            raise NotImplementedError(self.model_prediction)\n",
    "        \n",
    "        assert (model_logits.shape == pred_x_start_logits.shape == x.shape + (self.num_classes,))\n",
    "        return model_logits, pred_x_start_logits    # (bs, num_eedges, 2)\n",
    "    \n",
    "    # === Sampling ===\n",
    "\n",
    "    def p_sample(self, model_fn, x, t, noise, edge_features=None, edge_index=None, condition=None):\n",
    "        \"\"\"Sample one timestep from the model p(x_{t-1} | x_t).\"\"\"\n",
    "        # Get model logits\n",
    "        model_logits, pred_x_start_logits = self.p_logits(model_fn=model_fn, x=x, t=t, edge_features=edge_features, edge_index=edge_index, condition=condition)\n",
    "        assert noise.shape == model_logits.shape, noise.shape\n",
    "\n",
    "        # No noise when t == 0\n",
    "        nonzero_mask = (t != 0).float().reshape(x.shape[0], *([1] * (len(x.shape) - 1)))\n",
    "        # For numerical precision clip the noise to a minimum value\n",
    "        noise = torch.clamp(noise, min=torch.finfo(noise.dtype).eps, max=1.)\n",
    "        gumbel_noise = -torch.log(-torch.log(noise))\n",
    "\n",
    "        sample = torch.argmax(model_logits + nonzero_mask * gumbel_noise, dim=-1)\n",
    "\n",
    "        assert sample.shape == x.shape\n",
    "        assert pred_x_start_logits.shape == model_logits.shape\n",
    "        return sample, F.softmax(pred_x_start_logits, dim=-1)\n",
    "\n",
    "    def p_sample_loop(self, model_fn, shape, num_timesteps=None, return_x_init=False, edge_features=None, edge_index=None, line_graph=None, condition=None):\n",
    "        \"\"\"Ancestral sampling.\"\"\"\n",
    "        if num_timesteps is None:\n",
    "            num_timesteps = self.num_timesteps\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        if self.transition_mat_type in ['gaussian', 'uniform', 'marginal_prior']:\n",
    "            x_init = torch.randint(0, self.num_classes, size=shape, device=device)\n",
    "        elif self.transition_mat_type == 'absorbing':\n",
    "            x_init = torch.full(shape, fill_value=self.num_classes // 2, dtype=torch.int32, device=device)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid transition_mat_type {self.transition_mat_type}\")\n",
    "\n",
    "        x = x_init.clone()  # (bs, num_edges)\n",
    "        edge_attr = x_init.float()\n",
    "        #new_line_graph_x = line_graph.x.clone()\n",
    "        #new_line_graph_x[:, :, 0] = edge_attr\n",
    "        new_edge_features = edge_features.clone()\n",
    "        new_edge_features[:, :, 0] = edge_attr\n",
    "        \n",
    "        for i in range(num_timesteps):\n",
    "            t = torch.full([shape[0]], self.num_timesteps - 1 - i, dtype=torch.long, device=device)\n",
    "            noise = torch.rand(x.shape + (self.num_classes,), device=device, dtype=torch.float32)\n",
    "            x, _ = self.p_sample(model_fn=model_fn, x=x, t=t, noise=noise, edge_features=new_edge_features, edge_index=edge_index, condition=condition)\n",
    "            new_edge_features[:, :, 0] = x.float()\n",
    "\n",
    "        if return_x_init:\n",
    "            return x_init, x\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "  # === Log likelihood / loss calculation ===\n",
    "        \n",
    "    def cross_entropy_x_start(self, x_start, pred_x_start_logits, class_weights):\n",
    "        \"\"\"Calculate binary weighted cross entropy between x_start and predicted x_start logits.\n",
    "\n",
    "        Args:\n",
    "            x_start (torch.Tensor): original clean data, expected binary labels (0 or 1), shape (bs, num_edges)\n",
    "            pred_x_start_logits (torch.Tensor): logits as predicted by the model\n",
    "            class_weights (torch.Tensor): tensor with weights for class 0 and class 1\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: scalar tensor representing the mean binary weighted cross entropy loss.\n",
    "        \"\"\"\n",
    "        # Calculate binary cross-entropy with logits\n",
    "        x_start = x_start.long().to(self.device, non_blocking=True)\n",
    "        pred_x_start_logits = pred_x_start_logits.permute(0, 2, 1).float() # (bs, num_edges, num_classes) -> (bs, num_classes, num_edges)\n",
    "        ce = F.cross_entropy(pred_x_start_logits, x_start, weight=class_weights.float().to(self.device, non_blocking=True), reduction='mean')\n",
    "\n",
    "        return ce\n",
    "\n",
    "    def training_losses(self, model_fn, condition=None, *, x_start, edge_features, edge_index, line_graph=None):\n",
    "        \"\"\"Training loss calculation.\"\"\"\n",
    "        # Add noise to data\n",
    "        noise = torch.rand(x_start.shape + (self.num_classes,), dtype=torch.float32)\n",
    "        t = torch.randint(0, self.num_timesteps, (x_start.shape[0],))\n",
    "\n",
    "        # t starts at zero. so x_0 is the first noisy datapoint, not the datapoint itself.\n",
    "        x_t = self.q_sample(x_start=x_start, t=t, noise=noise)  # (bs, num_edges)\n",
    "        \n",
    "        edge_attr_t = x_t.float()\n",
    "        # new_line_graph_x = line_graph.x.clone()\n",
    "        new_edge_features = edge_features.clone()\n",
    "        for i in range(edge_attr_t.shape[0]):\n",
    "            # new_line_graph_x[i, :, 0] = edge_attr_t[i]  # Update the edge attributes in the line graph with the noised trajectory x_t\n",
    "            new_edge_features[i, :, 0] = edge_attr_t[i]\n",
    "\n",
    "\n",
    "        # Calculate the loss\n",
    "        if self.loss_type == 'kl':\n",
    "            losses, pred_x_start_logits = self.vb_terms_bpd(model_fn=model_fn, x_start=x_start, x_t=x_t, t=t,\n",
    "                                                               edge_features=new_edge_features, edge_index=edge_index, condition=condition)\n",
    "            \n",
    "            pred_x_start_logits = pred_x_start_logits.squeeze(2)    # (bs, num_edges, channels, classes) -> (bs, num_edges, classes)\n",
    "            # NOTE: Currently only works for batch size of 1\n",
    "            pred_x_start_logits = pred_x_start_logits.squeeze(0)    # (bs, num_edges, classes) -> (num_edges, classes)\n",
    "            pred = pred_x_start_logits.argmax(dim=1)                # (num_edges, classes) -> (num_edges,)\n",
    "            \n",
    "            return losses, pred\n",
    "            \n",
    "        elif self.loss_type == 'cross_entropy_x_start':\n",
    "            \n",
    "            _, pred_x_start_logits = self.p_logits(model_fn, x=x_t, t=t, edge_features=new_edge_features, edge_index=edge_index, condition=condition)\n",
    "            losses = self.cross_entropy_x_start(x_start=x_start, pred_x_start_logits=pred_x_start_logits, class_weights=self.class_weights)\n",
    "            \n",
    "            pred_x_start_logits = pred_x_start_logits.squeeze(2)    # (bs, num_edges, channels, classes) -> (bs, num_edges, classes)\n",
    "            \n",
    "            if (self.model_name == 'edge_encoder') | (self.model_name == 'edge_encoder_residual'):\n",
    "                # NOTE: Currently only works for batch size of 1\n",
    "                pred_x_start_logits = pred_x_start_logits.squeeze(0)    # (bs, num_edges, classes) -> (num_edges, classes)\n",
    "                pred = pred_x_start_logits.argmax(dim=1)    # (num_edges, classes) -> (num_edges,)\n",
    "            elif self.model_name == 'edge_encoder_mlp':\n",
    "                pred = pred_x_start_logits.argmax(dim=2)\n",
    "            \n",
    "            return losses, pred\n",
    "            \n",
    "        else:\n",
    "            raise NotImplementedError(self.loss_type)\n",
    "\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import F1Score\n",
    "from torch_geometric.utils import from_networkx\n",
    "#from dataset.trajctory_dataset import TrajectoryDataset, collate_fn\n",
    "#from .d3pm_diffusion import make_diffusion\n",
    "#from .d3pm_edge_encoder import Edge_Encoder\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import wandb\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "\n",
    "class Graph_Diffusion_Model(nn.Module):\n",
    "    def __init__(self, data_config, diffusion_config, model_config, train_config, test_config, wandb_config, model):\n",
    "        super(Graph_Diffusion_Model, self).__init__()\n",
    "        \n",
    "        # Data\n",
    "        self.data_config = data_config\n",
    "        self.train_data_path = self.data_config['train_data_path']\n",
    "        self.val_data_path = self.data_config['val_data_path']\n",
    "        self.history_len = self.data_config['history_len']\n",
    "        self.future_len = self.data_config['future_len']\n",
    "        self.num_classes = self.data_config['num_classes']\n",
    "        self.edge_features = self.data_config['edge_features']\n",
    "        \n",
    "        # Diffusion\n",
    "        self.diffusion_config = diffusion_config\n",
    "        self.num_timesteps = self.diffusion_config['num_timesteps']\n",
    "        \n",
    "        # Model\n",
    "        self.model_config = model_config\n",
    "        self.model = model # Edge_Encoder\n",
    "        self.hidden_channels = self.model_config['hidden_channels']\n",
    "        self.time_embedding_dim = self.model_config['time_embedding_dim']\n",
    "        self.condition_dim = self.model_config['condition_dim']\n",
    "        self.num_layers = self.model_config['num_layers']\n",
    "        \n",
    "        # Training\n",
    "        self.train_config = train_config\n",
    "        self.lr = self.train_config['lr']\n",
    "        self.lr_decay_parameter = self.train_config['lr_decay']\n",
    "        self.learning_rate_warmup_steps = self.train_config['learning_rate_warmup_steps']\n",
    "        self.num_epochs = self.train_config['num_epochs']\n",
    "        self.gradient_accumulation = self.train_config['gradient_accumulation']\n",
    "        self.gradient_accumulation_steps = self.train_config['gradient_accumulation_steps']\n",
    "        self.batch_size = self.train_config['batch_size'] if not self.gradient_accumulation else self.train_config['batch_size'] * self.gradient_accumulation_steps\n",
    "        \n",
    "        # Testing\n",
    "        self.test_config = test_config\n",
    "        self.test_batch_size = self.test_config['batch_size']\n",
    "        self.model_path = self.test_config['model_path']\n",
    "        self.eval_every_steps = self.test_config['eval_every_steps']\n",
    "        \n",
    "        # WandB\n",
    "        self.wandb_config = wandb_config\n",
    "        wandb.init(\n",
    "            settings=wandb.Settings(start_method=\"fork\"),\n",
    "            project=self.wandb_config['project'],\n",
    "            entity=self.wandb_config['entity'],\n",
    "            notes=self.wandb_config['notes'],\n",
    "            job_type=self.wandb_config['job_type'],\n",
    "            config={**self.data_config, **self.diffusion_config, **self.model_config, **self.train_config}\n",
    "        )\n",
    "        self.exp_name = self.wandb_config['exp_name']\n",
    "        wandb.run.name = self.exp_name\n",
    "\n",
    "        # Logging\n",
    "        self.dataset = self.data_config['dataset']\n",
    "        self.model_dir = os.path.join(\"experiments\", self.exp_name)\n",
    "        os.makedirs(self.model_dir,exist_ok=True)\n",
    "        log_name = '{}.log'.format(time.strftime('%Y-%m-%d-%H-%M'))\n",
    "        log_name = f\"{self.dataset}_{log_name}\"\n",
    "        \n",
    "        self.log = logging.getLogger()\n",
    "        self.log.setLevel(logging.INFO)\n",
    "        log_dir = os.path.join(self.model_dir, log_name)\n",
    "        file_handler = logging.FileHandler(log_dir)\n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        file_handler.setFormatter(formatter)\n",
    "        self.log.addHandler(file_handler)\n",
    "        \n",
    "        self.log_loss_every_steps = self.train_config['log_loss_every_steps']        \n",
    "        \n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Build Components\n",
    "        self._build_train_dataloader()\n",
    "        self._build_test_dataloader()\n",
    "        self._build_model()\n",
    "        self._build_optimizer()\n",
    "        \n",
    "        # Move model to GPU\n",
    "        \n",
    "        self.model.to(self.device, non_blocking=True)\n",
    "        print(\"device\", self.device)\n",
    "        \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Trains the diffusion-based trajectory prediction model.\n",
    "\n",
    "        This function performs the training of the diffusion-based trajectory prediction model. It iterates over the specified number of epochs and updates the model's parameters based on the training data. The training process includes forward propagation, loss calculation, gradient computation, and parameter updates.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "        dif = make_diffusion(self.diffusion_config, self.model_config, num_edges=self.num_edges, future_len=self.future_len, device=self.device)\n",
    "        def model_fn(x, edge_index, t, condition=None):\n",
    "            if self.model_config['name'] == 'edge_encoder':\n",
    "                return self.model.forward(x, edge_index, t, condition, mode='future')\n",
    "            elif self.model_config['name'] == 'edge_encoder_residual':\n",
    "                return self.model.forward(x, edge_index, t, condition, mode='future')\n",
    "            elif self.model_config['name'] == 'edge_encoder_mlp':\n",
    "                return self.model.forward(x, t=t, condition=condition, mode='future')\n",
    "                \n",
    "        for epoch in tqdm(range(self.num_epochs)):\n",
    "            current_lr = self.scheduler.get_last_lr()[0]\n",
    "            wandb.log({\"epoch\": epoch, \"learning_rate\": current_lr})\n",
    "            \n",
    "            total_loss = 0\n",
    "            ground_truth_fut = []\n",
    "            pred_fut = []\n",
    "            #with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "                #with record_function(\"model_training\"):\n",
    "            if self.gradient_accumulation:\n",
    "                for data in self.train_data_loader:\n",
    "                    history_edge_features = data[\"history_edge_features\"]\n",
    "                    future_edge_indices_one_hot = data[\"future_edge_features\"][:, :, 0]\n",
    "                    \n",
    "                    self.optimizer.zero_grad()\n",
    "                    for i in range(min(self.gradient_accumulation_steps, history_edge_features.size(0))):\n",
    "                        # Calculate history condition c\n",
    "                        \n",
    "                        if self.model_config['name'] == 'edge_encoder':\n",
    "                            c = self.model.forward(x=history_edge_features[i].unsqueeze(0), edge_index=self.edge_index, mode='history')\n",
    "                        elif self.model_config['name'] == 'edge_encoder_residual':\n",
    "                            c = self.model.forward(x=history_edge_features[i].unsqueeze(0), edge_index=self.edge_index, mode='history')\n",
    "                        elif self.model_config['name'] == 'edge_encoder_mlp':\n",
    "                            c = self.model.forward(x=history_edge_features[i].unsqueeze(0), mode='history')\n",
    "                        else:\n",
    "                            raise NotImplementedError(self.model_config['name'])\n",
    "                        \n",
    "                        x_start = future_edge_indices_one_hot[i].unsqueeze(0)   # (1, num_edges)\n",
    "                        # Get loss and predictions\n",
    "                        loss, preds = dif.training_losses(model_fn, c, x_start=x_start, edge_features=history_edge_features[i].unsqueeze(0), edge_index=self.edge_index, line_graph=None)   # preds are of shape (num_edges,)\n",
    "                        \n",
    "                        total_loss += loss / self.gradient_accumulation_steps\n",
    "                        (loss / self.gradient_accumulation_steps).backward() # Gradient accumulation\n",
    "                        \n",
    "                        ground_truth_fut.append(x_start.detach())\n",
    "                        pred_fut.append(preds.detach())\n",
    "                        \n",
    "                    \n",
    "                    self.optimizer.step()\n",
    "                    \n",
    "            else:\n",
    "                for data in self.train_data_loader:\n",
    "                    history_edge_features = data[\"history_edge_features\"]\n",
    "                    future_edge_indices_one_hot = data[\"future_edge_features\"][:, :, 0]\n",
    "                    \n",
    "                    batch_size = future_edge_indices_one_hot.size(0)\n",
    "                    if self.model_config['name'] == 'edge_encoder_mlp':\n",
    "                        if batch_size == self.batch_size:\n",
    "                            future_edge_indices_one_hot = future_edge_indices_one_hot.view(self.batch_size, self.num_edges)\n",
    "                        else:\n",
    "                            future_edge_indices_one_hot = future_edge_indices_one_hot.view(batch_size, self.num_edges)\n",
    "                    \n",
    "                    self.optimizer.zero_grad()\n",
    "                    # Calculate history condition c\n",
    "                    if self.model_config['name'] == 'edge_encoder':\n",
    "                        c = self.model.forward(x=history_edge_features, edge_index=self.edge_index, mode='history')\n",
    "                    elif self.model_config['name'] == 'edge_encoder_residual':\n",
    "                        c = self.model.forward(x=history_edge_features, edge_index=self.edge_index, mode='history')\n",
    "                    elif self.model_config['name'] == 'edge_encoder_mlp':\n",
    "                        c = self.model.forward(x=history_edge_features, mode='history')\n",
    "                    else:\n",
    "                        raise NotImplementedError(self.model_config['name'])\n",
    "                    \n",
    "                    x_start = future_edge_indices_one_hot\n",
    "                    # Get loss and predictions\n",
    "                    loss, preds = dif.training_losses(model_fn, c, x_start=x_start, edge_features=history_edge_features, edge_index=self.edge_index, line_graph=None)\n",
    "                                        \n",
    "                    total_loss += loss\n",
    "                    loss.backward()\n",
    "                    \n",
    "                    self.optimizer.step()\n",
    "                    \n",
    "                    ground_truth_fut.append(x_start.detach())\n",
    "                    pred_fut.append(preds.detach())\n",
    "            \n",
    "            self.scheduler.step()\n",
    "                    \n",
    "            avg_loss = total_loss / len(self.train_data_loader)\n",
    "            f1_score = F1Score(task='binary', average='macro', num_classes=2)\n",
    "            f1_epoch = f1_score(torch.flatten(torch.cat(pred_fut)).detach().to('cpu'), torch.flatten(torch.cat(ground_truth_fut)).detach().to('cpu'))\n",
    "            if epoch % self.log_loss_every_steps == 0:\n",
    "                wandb.log({\"epoch\": epoch, \"average_loss\": avg_loss.item()})\n",
    "                wandb.log({\"epoch\": epoch, \"average_F1_score\": f1_epoch.item()})\n",
    "                self.log.info(f\"Epoch {epoch} Average Loss: {avg_loss.item()}\")\n",
    "                print(\"Epoch:\", epoch+1)\n",
    "                print(\"Loss:\", avg_loss.item())\n",
    "                print(\"F1:\", f1_epoch.item())\n",
    "                \n",
    "            if (epoch + 1) % self.eval_every_steps == 0:\n",
    "                print(\"Evaluating on test set...\")\n",
    "                sample_list, ground_truth_hist, ground_truth_fut = self.get_samples(task='predict')\n",
    "                fut_ratio, f1, avg_sample_length = self.eval(sample_list, ground_truth_hist, ground_truth_fut)\n",
    "                print(\"Samples\", sample_list)\n",
    "                print(\"Ground truth\", ground_truth_fut)\n",
    "                print(\"Test F1 Score\", f1.item())\n",
    "                wandb.log({\"Test F1 Score\": f1.item()})\n",
    "                wandb.log({\"Test Future ratio\": fut_ratio})\n",
    "                wandb.log({\"Average test sample length\": avg_sample_length})\n",
    "                        \n",
    "            if self.train_config['save_model'] and (epoch + 1) % self.train_config['save_model_every_steps'] == 0:\n",
    "                self.save_model()\n",
    "            \n",
    "    def get_samples(self, load_model=False, model_path=None, task='predict', number_samples=1, save=False):\n",
    "        \"\"\"\n",
    "        Retrieves samples from the model.\n",
    "\n",
    "        Args:\n",
    "            load_model (bool, optional): Whether to load a pre-trained model. Defaults to False.\n",
    "            model_path (str, optional): The path to the pre-trained model. Required if `load_model` is True.\n",
    "            task (str, optional): The task to perform. Defaults to 'predict'. Other possible value: 'generate' to generate realistic trajectories\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing three lists:\n",
    "                - sample_list (list): A list of samples generated by the model.\n",
    "                - ground_truth_hist (list): A list of ground truth history edge indices.\n",
    "                - ground_truth_fut (list): A list of ground truth future trajectory indices.\n",
    "        \"\"\"\n",
    "        \n",
    "        if load_model:\n",
    "            if model_path is None:\n",
    "                raise ValueError(\"Model path must be provided to load model.\")\n",
    "            self.load_model(model_path)\n",
    "        \n",
    "        if self.test_config['number_samples'] is not None:\n",
    "            number_samples = self.test_config['number_samples']\n",
    "        \n",
    "        def model_fn(x, edge_index, t, condition=None):\n",
    "            if self.model_config['name'] == 'edge_encoder':\n",
    "                return self.model.forward(x, edge_index, t, condition, mode='future')\n",
    "            elif self.model_config['name'] == 'edge_encoder_residual':\n",
    "                return self.model.forward(x, edge_index, t, condition, mode='future')\n",
    "            elif self.model_config['name'] == 'edge_encoder_mlp':\n",
    "                return self.model.forward(x=x, t=t, condition=condition, mode='future')\n",
    "        \n",
    "        sample_list = []\n",
    "        ground_truth_hist = []\n",
    "        ground_truth_fut = []\n",
    "        \n",
    "        if task == 'predict':\n",
    "            for data in tqdm(self.test_dataloader):\n",
    "                history_edge_features = data[\"history_edge_features\"]\n",
    "\n",
    "                history_edge_indices = data[\"history_indices\"]\n",
    "\n",
    "                future_trajectory_indices = data[\"future_indices\"]\n",
    "                # with torch.no_grad():\n",
    "                if self.model_config['name'] == 'edge_encoder':\n",
    "                    c = self.model.forward(x=self.line_graph.x, edge_index=self.line_graph.edge_index, mode='history')\n",
    "                elif self.model_config['name'] == 'edge_encoder_residual':\n",
    "                    c = self.model.forward(x=self.line_graph.x, edge_index=self.line_graph.edge_index, mode='history')\n",
    "                elif self.model_config['name'] == 'edge_encoder_mlp':\n",
    "                    c = self.model.forward(x=history_edge_features, mode='history')\n",
    "            \n",
    "                if number_samples > 1:\n",
    "                    new_seed = torch.seed() + torch.randint(0, 100000, (1,)).item()\n",
    "                    torch.manual_seed(new_seed)\n",
    "                    sample_sublist = []\n",
    "                    for _ in range(number_samples):\n",
    "                        samples = make_diffusion(self.diffusion_config, self.model_config, \n",
    "                                                num_edges=self.num_edges, future_len=self.future_len).p_sample_loop(model_fn=model_fn,\n",
    "                                                                                        shape=(self.test_batch_size, self.num_edges),\n",
    "                                                                                        edge_features=history_edge_features,\n",
    "                                                                                        edge_index=self.edge_index,\n",
    "                                                                                        line_graph=None,\n",
    "                                                                                        condition=c)\n",
    "                        samples = torch.where(samples == 1)[1]\n",
    "                        sample_sublist.append(samples.detach())\n",
    "                    sample_list.append(sample_sublist)\n",
    "                elif number_samples == 1:\n",
    "                    samples = make_diffusion(self.diffusion_config, self.model_config, \n",
    "                                            num_edges=self.num_edges, future_len=self.future_len, device=self.device).p_sample_loop(model_fn=model_fn,\n",
    "                                                                                    shape=(self.test_batch_size, self.num_edges), \n",
    "                                                                                    edge_features=history_edge_features,\n",
    "                                                                                    edge_index=self.edge_index,\n",
    "                                                                                    line_graph=None,\n",
    "                                                                                    condition=c)\n",
    "                    samples = torch.where(samples == 1)[1]\n",
    "                    sample_list.append(samples.detach())\n",
    "                else:\n",
    "                    raise ValueError(\"Number of samples must be greater than 0.\")\n",
    "                ground_truth_hist.append(history_edge_indices.detach())\n",
    "                ground_truth_fut.append(future_trajectory_indices.detach())\n",
    "            \n",
    "            if number_samples == 1:\n",
    "                fut_ratio, f1, avg_sample_length = self.eval(sample_list, ground_truth_hist, ground_truth_fut)\n",
    "                wandb.log({\"F1 Score\": f1.item()})\n",
    "                wandb.log({\"Future ratio\": fut_ratio})\n",
    "                wandb.log({\"Average sample length\": avg_sample_length})\n",
    "            \n",
    "            if save:\n",
    "                torch.save(sample_list, os.path.join(self.model_dir, f'{self.exp_name}_samples.pth'))\n",
    "                torch.save(ground_truth_hist, os.path.join(self.model_dir, f'{self.exp_name}_ground_truth_hist.pth'))\n",
    "                torch.save(ground_truth_fut, os.path.join(self.model_dir, f'{self.exp_name}_ground_truth_fut.pth'))\n",
    "                print(f\"Samples saved at {os.path.join(self.model_dir, f'{self.exp_name}_samples.pth')}!\")\n",
    "            else:\n",
    "                return sample_list, ground_truth_hist, ground_truth_fut\n",
    "        \n",
    "        elif task == 'generate':\n",
    "            # Generate realistic trajectories without condition\n",
    "            # Edge encoder model needs to be able to funciton with no edge_attr and no condition\n",
    "            # Add generate mode to p_logits, p_sample, and p_sample_loop\n",
    "            return\n",
    "        \n",
    "        else:\n",
    "            raise NotImplementedError(task)\n",
    "    \n",
    "    def visualize_sample_density(self, samples, ground_truth_hist, ground_truth_fut, number_plots=5, number_samples=10):\n",
    "        \"\"\"\n",
    "        Visualize the density of the samples generated by the model.\n",
    "\n",
    "        :param samples: A list of predicted edge indices.\n",
    "        :param ground_truth_hist: A list of actual history edge indices.\n",
    "        :param ground_truth_fut: A list of actual future edge indices.\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        samples, ground_truth_hist, ground_truth_fut = self.get_samples(load_model=True, model_path=self.test_config['model_path'], number_samples=number_samples)\n",
    "        save_dir = f'{os.path.join(self.model_dir, f'{self.exp_name}', 'plots')}'\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(self.nodes)\n",
    "        all_edges = {tuple(self.edges[idx]) for idx in range(len(self.edges))}\n",
    "        G.add_edges_from(all_edges)\n",
    "\n",
    "        pos = nx.get_node_attributes(G, 'pos')\n",
    "\n",
    "        for i in range(min(number_plots, len(samples))):\n",
    "            plt.figure(figsize=(18, 8))            \n",
    "\n",
    "            for plot_num, (title, edge_indices) in enumerate([\n",
    "                ('Ground Truth History', ground_truth_hist[i][0]),\n",
    "                ('Ground Truth Future', ground_truth_fut[i][0]),\n",
    "                ('Predicted Future', samples[i])\n",
    "            ]):\n",
    "                plt.subplot(1, 3, plot_num + 1)\n",
    "                plt.title(title)\n",
    "\n",
    "                # Draw all edges as muted gray\n",
    "                nx.draw_networkx_edges(G, pos, edgelist=all_edges, width=0.5, alpha=0.3, edge_color='gray')\n",
    "\n",
    "                # Draw subgraph edges with specified color\n",
    "                edge_color = 'gray' if plot_num == 0 else 'green' if plot_num == 1 else 'red'\n",
    "                node_color = 'skyblue'\n",
    "                if plot_num == 2:\n",
    "                    edge_counts = np.zeros(len(all_edges))\n",
    "                    for sample in samples[i]:\n",
    "                        for edge in sample:\n",
    "                            edge_counts[edge] += 1\n",
    "                    max_count = np.max(edge_counts)\n",
    "                    edge_widths = edge_counts / max_count\n",
    "                    \n",
    "                    nx.draw_networkx_nodes(G, pos, node_color=node_color, node_size=500)\n",
    "                    nx.draw_networkx_edges(G, pos, edgelist=all_edges, edge_color='red', width=edge_widths*5, alpha=edge_widths/np.max(edge_widths))\n",
    "                    nx.draw_networkx_labels(G, pos, font_size=15)\n",
    "                else:\n",
    "                    subgraph_edges = {tuple(self.edges[idx]) for idx in edge_indices if idx < len(self.edges)}\n",
    "                    nx.draw_networkx_nodes(G, pos, node_color=node_color, node_size=500)\n",
    "                    nx.draw_networkx_edges(G, pos, edgelist=subgraph_edges, width=3, alpha=1.0, edge_color=edge_color)\n",
    "                    nx.draw_networkx_labels(G, pos, font_size=15)\n",
    "            # Save plot\n",
    "            plt.savefig(os.path.join(save_dir, f'sample_{i+1}.png'))\n",
    "            plt.close()  # Close the figure to free memory\n",
    "    \n",
    "    def visualize_predictions(self, samples, ground_truth_hist, ground_truth_fut, number_plots=5):\n",
    "        \"\"\"\n",
    "        Visualize the predictions of the model along with ground truth data.\n",
    "\n",
    "        :param samples: A list of predicted edge indices.\n",
    "        :param ground_truth_hist: A list of actual history edge indices.\n",
    "        :param ground_truth_fut: A list of actual future edge indices.\n",
    "        :param number_plots: Number of samples to visualize.\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        save_dir = f'{os.path.join(self.model_dir, f'{self.exp_name}', 'plots')}'\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(self.nodes)\n",
    "        all_edges = {tuple(self.edges[idx]) for idx in range(len(self.edges))}\n",
    "        G.add_edges_from(all_edges)\n",
    "        \n",
    "        pos = nx.get_node_attributes(G, 'pos')  # Retrieve node positions stored in node attributes\n",
    "\n",
    "        for i in range(min(number_plots, len(samples))):\n",
    "            plt.figure(figsize=(18, 8))            \n",
    "\n",
    "            for plot_num, (title, edge_indices) in enumerate([\n",
    "                ('Ground Truth History', ground_truth_hist[i][0]),\n",
    "                ('Ground Truth Future', ground_truth_fut[i][0]),\n",
    "                ('Predicted Future', samples[i])\n",
    "            ]):\n",
    "                plt.subplot(1, 3, plot_num + 1)\n",
    "                plt.title(title)\n",
    "                subgraph_edges = {tuple(self.edges[idx]) for idx in edge_indices if idx < len(self.edges)}\n",
    "\n",
    "                # Draw all edges as muted gray\n",
    "                nx.draw_networkx_edges(G, pos, edgelist=all_edges, width=0.5, alpha=0.3, edge_color='gray')\n",
    "\n",
    "                # Draw subgraph edges with specified color\n",
    "                edge_color = 'gray' if plot_num == 0 else 'green' if plot_num == 1 else 'red'\n",
    "                node_color = 'skyblue'# if plot_num == 0 else 'lightgreen' if plot_num == 1 else 'orange'\n",
    "                nx.draw_networkx_nodes(G, pos, node_color=node_color, node_size=500)\n",
    "                nx.draw_networkx_edges(G, pos, edgelist=subgraph_edges, width=3, alpha=1.0, edge_color=edge_color)\n",
    "                nx.draw_networkx_labels(G, pos, font_size=15)\n",
    "            # Save plot\n",
    "            plt.savefig(os.path.join(save_dir, f'sample_{i+1}.png'))\n",
    "            plt.close()  # Close the figure to free memory\n",
    "    \n",
    "    def eval(self, sample_list, ground_truth_hist, ground_truth_fut):\n",
    "        \"\"\"\n",
    "        Evaluate the model's performance.\n",
    "\n",
    "        :param sample_list: A list of predicted edge indices.\n",
    "        :param ground_truth_hist: A list of actual history edge indices.\n",
    "        :param ground_truth_fut: A list of actual future edge indices.\n",
    "        \"\"\"\n",
    "        def calculate_fut_ratio(sample_list, ground_truth_fut):\n",
    "            \"\"\"\n",
    "            Calculates the ratio of samples in `sample_list` that have at least one or two edges in common with the ground truth future trajectory.\n",
    "\n",
    "            Args:\n",
    "                sample_list (list): A list of samples.\n",
    "                ground_truth_fut (list): A list of ground truth future trajectories.\n",
    "\n",
    "            Returns:\n",
    "                tuple: A tuple containing the ratios of samples that have at least one or two edges in common with the ground truth future trajectory.\n",
    "            \"\"\"\n",
    "            count_1 = 0\n",
    "            count_2 = 0\n",
    "            total = len(sample_list)\n",
    "\n",
    "            for i, sample in enumerate(sample_list):\n",
    "                edges_count = sum(1 for edge in ground_truth_fut[i][0] if edge in sample)\n",
    "                if edges_count >= 1:\n",
    "                    count_1 += 1\n",
    "                if edges_count >= 2:\n",
    "                    count_2 += 1\n",
    "\n",
    "            ratio_1 = count_1 / total\n",
    "            ratio_2 = count_2 / total\n",
    "            return ratio_1, ratio_2\n",
    "        \n",
    "        def calculate_sample_f1(sample_list, ground_truth_fut):\n",
    "            \"\"\"\n",
    "            Calculates the F1 score for a given list of samples and ground truth futures.\n",
    "\n",
    "            Args:\n",
    "                sample_list (list): A list of samples.\n",
    "                ground_truth_fut (list): A list of ground truth futures.\n",
    "\n",
    "            Returns:\n",
    "                float: The F1 score.\n",
    "\n",
    "            \"\"\"\n",
    "            one_hot_samples = [torch.zeros(self.num_edges) for _ in range(len(sample_list))]\n",
    "            one_hot_futures = [torch.zeros(self.num_edges) for _ in range(len(ground_truth_fut))]\n",
    "            for i, one_hot_sample in enumerate(one_hot_samples):\n",
    "                for edge_index, edge in enumerate(self.edges):\n",
    "                    if edge_index in sample_list[i]:\n",
    "                        one_hot_sample[edge_index] = 1\n",
    "            for i, one_hot_fut in enumerate(one_hot_futures):\n",
    "                for edge_index, edge in enumerate(self.edges):\n",
    "                    if edge_index in ground_truth_fut[i]:\n",
    "                        one_hot_fut[edge_index] = 1\n",
    "            metric = F1Score(task='binary', average='macro', num_classes=2)\n",
    "            f1 = metric(torch.cat(one_hot_samples), torch.cat(one_hot_futures))\n",
    "\n",
    "            return f1\n",
    "        \n",
    "        def calculate_avg_sample_length(sample_list):\n",
    "            \"\"\"\n",
    "            Calculate the average sample length.\n",
    "\n",
    "            Args:\n",
    "                sample_list (list): A list of samples.\n",
    "\n",
    "            Returns:\n",
    "                float: The average sample length.\n",
    "            \"\"\"\n",
    "            return sum(len(sample) for sample in sample_list) / len(sample_list)\n",
    "        \n",
    "        fut_ratio = calculate_fut_ratio(sample_list, ground_truth_fut)\n",
    "        f1 = calculate_sample_f1(sample_list, ground_truth_fut)\n",
    "        avg_sample_length = calculate_avg_sample_length(sample_list)\n",
    "        \n",
    "        return fut_ratio, f1, avg_sample_length\n",
    "    \n",
    "    def save_model(self):\n",
    "        save_path = os.path.join(self.model_dir, \n",
    "                                 self.exp_name + '_' + self.model_config['name'] + '_' +  self.model_config['transition_mat_type'] + '_' +  self.diffusion_config['type'] + \n",
    "                                 f'_hidden_dim_{self.hidden_channels}_time_dim_{str(self.time_embedding_dim)}_condition_dim_{self.condition_dim}_layers_{self.num_layers}.pth')\n",
    "        torch.save(self.model.state_dict(), save_path)\n",
    "        self.log.info(f\"Model saved at {save_path}!\")\n",
    "        print(f\"Model saved at {save_path}\")\n",
    "        \n",
    "    def load_model(self, model_path):\n",
    "        self.model.load_state_dict(torch.load(model_path))\n",
    "        self.log.info(\"Model loaded!\")\n",
    "    \n",
    "    def _build_optimizer(self):\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        \n",
    "        def lr_lambda(epoch):\n",
    "            if epoch < self.learning_rate_warmup_steps:\n",
    "                return 1.0\n",
    "            else:\n",
    "                decay_lr = self.lr_decay_parameter ** (epoch - self.learning_rate_warmup_steps)\n",
    "                return max(decay_lr, 2e-5 / self.lr)\n",
    "            \n",
    "        self.scheduler = torch.optim.lr_scheduler.LambdaLR(self.optimizer, lr_lambda)\n",
    "        print(\"> Optimizer and Scheduler built!\")\n",
    "        \n",
    "        \"\"\"print(\"Parameters to optimize:\")\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(name)\"\"\"\n",
    "        \n",
    "    def _build_train_dataloader(self):\n",
    "        print(\"Loading Training Dataset...\")\n",
    "        self.train_dataset = TrajectoryDataset(self.train_data_path, self.history_len, self.future_len, self.edge_features, device=self.device)\n",
    "        self.G = self.train_dataset.build_graph()\n",
    "        self.nodes = self.G.nodes\n",
    "        self.edges = self.G.edges(data=True)\n",
    "        self.num_edges = self.G.number_of_edges()\n",
    "        self.indexed_edges = self.train_dataset.edges\n",
    "        self.num_edge_features = self.train_dataset.num_edge_features\n",
    "        \n",
    "        # Build the line graph and corresponding edge index\n",
    "        self.edge_index = self._build_edge_index()\n",
    "                \n",
    "        self.train_data_loader = DataLoader(self.train_dataset, \n",
    "                                            batch_size=self.batch_size, \n",
    "                                            shuffle=True, \n",
    "                                            collate_fn=collate_fn, \n",
    "                                            num_workers=0,\n",
    "                                            pin_memory=False)\n",
    "                        \n",
    "        print(\"> Training Dataset loaded!\\n\")\n",
    "        \n",
    "    def _build_edge_index(self):\n",
    "        print(\"Building edge index for line graph...\")\n",
    "        edge_index = torch.tensor([[e[0], e[1]] for e in self.edges], dtype=torch.long).t().contiguous()\n",
    "        edge_to_index = {tuple(e[:2]): e[2]['index'] for e in self.edges}\n",
    "        line_graph_edges = []\n",
    "        edge_list = edge_index.t().tolist()\n",
    "        for i, (u1, v1) in tqdm(enumerate(edge_list), total=len(edge_list), desc=\"Processing edges\"):\n",
    "            for j, (u2, v2) in enumerate(edge_list):\n",
    "                if i != j and (u1 == u2 or u1 == v2 or v1 == u2 or v1 == v2):\n",
    "                    line_graph_edges.append((edge_to_index[(u1, v1)], edge_to_index[(u2, v2)]))\n",
    "\n",
    "        # Create the edge index for the line graph\n",
    "        edge_index = torch.tensor(line_graph_edges, dtype=torch.long).t().contiguous()\n",
    "        print(\"> Edge index built!\\n\")\n",
    "        \n",
    "        return edge_index.to(self.device, non_blocking=True)\n",
    "    \n",
    "    def _build_test_dataloader(self):\n",
    "        self.test_dataset = TrajectoryDataset(self.val_data_path, self.history_len, self.future_len, self.edge_features, device=self.device)\n",
    "        self.test_dataloader = DataLoader(self.test_dataset, batch_size=self.test_batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "        print(\"> Test Dataset loaded!\")\n",
    "        \n",
    "    def _build_model(self):\n",
    "        self.model = self.model(self.model_config, self.history_len, self.future_len, self.num_classes,\n",
    "                                num_edges=self.num_edges, hidden_channels=self.hidden_channels, num_edge_features=self.num_edge_features, num_timesteps=self.num_timesteps)\n",
    "        print(\"> Model built!\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def get_timestep_embedding(timesteps, embedding_dim, max_time=1000., device=None):\n",
    "    \"\"\"\n",
    "    Build sinusoidal embeddings (from Fairseq).\n",
    "\n",
    "    This matches the implementation in tensor2tensor, but differs slightly\n",
    "    from the description in Section 3.5 of \"Attention Is All You Need\".\n",
    "\n",
    "    Args:\n",
    "        timesteps: torch.Tensor: generate embedding vectors at these timesteps\n",
    "        embedding_dim: int: dimension of the embeddings to generate\n",
    "        max_time: float: largest time input\n",
    "\n",
    "    Returns:\n",
    "        embedding vectors with shape `(len(timesteps), embedding_dim)`\n",
    "    \"\"\"\n",
    "    timesteps = timesteps.to(device)\n",
    "    assert timesteps.dim() == 1  # Ensure timesteps is a 1D tensor\n",
    "\n",
    "    # Scale timesteps by the maximum time\n",
    "    timesteps = timesteps.float() * (1000. / max_time)\n",
    "\n",
    "    half_dim = embedding_dim // 2\n",
    "    emb = torch.log(torch.tensor(10000.0, device=device)) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32, device=device) * -emb)\n",
    "    emb = timesteps[:, None] * emb[None, :]\n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "\n",
    "    if embedding_dim % 2 == 1:  # Add zero-padding if embedding dimension is odd\n",
    "        zero_pad = torch.zeros((timesteps.shape[0], 1), dtype=torch.float32)\n",
    "        emb = torch.cat([emb, zero_pad], dim=1)\n",
    "\n",
    "    assert emb.shape == (timesteps.shape[0], embedding_dim)\n",
    "    return emb.to(device)\n",
    "\n",
    "class Edge_Encoder_MLP(nn.Module):\n",
    "    def __init__(self, model_config, history_len, future_len, num_classes, num_edges, hidden_channels, num_edge_features, num_timesteps):\n",
    "        super(Edge_Encoder_MLP, self).__init__()\n",
    "        # Config\n",
    "        self.config = model_config\n",
    "        \n",
    "        # Data\n",
    "        self.num_edges = num_edges\n",
    "        self.num_edge_features = num_edge_features\n",
    "        self.history_len = history_len\n",
    "        self.future_len = future_len\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Time embedding\n",
    "        self.max_time = num_timesteps\n",
    "        self.time_embedding_dim = self.config['time_embedding_dim']\n",
    "        self.time_linear0 = nn.Linear(self.time_embedding_dim, self.time_embedding_dim)\n",
    "        self.time_linear1 = nn.Linear(self.time_embedding_dim, self.time_embedding_dim)\n",
    "    \n",
    "        # Model\n",
    "        # GNN layers\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_layers = self.config['num_layers']\n",
    "        self.lin_layers = nn.ModuleList()\n",
    "        self.lin_layers.append(nn.Linear(self.num_edge_features, self.hidden_channels))\n",
    "        for _ in range(1, self.num_layers):\n",
    "            self.lin_layers.append(nn.Linear(self.hidden_channels, self.hidden_channels))\n",
    "        \n",
    "        # Output layers for each task\n",
    "        self.condition_dim = self.config['condition_dim']\n",
    "        self.history_encoder = nn.Linear(self.hidden_channels, self.condition_dim)  # To encode history to c\n",
    "        self.future_decoder = nn.Linear(self.hidden_channels + self.condition_dim + self.time_embedding_dim,\n",
    "                                        self.hidden_channels)  # To predict future edges\n",
    "        self.adjust_to_class_shape = nn.Linear(self.hidden_channels, self.num_classes)\n",
    "\n",
    "    def forward(self, x, t=None, condition=None, mode=None):\n",
    "        \"\"\"\n",
    "        Forward pass through the model\n",
    "        Args:\n",
    "            x: torch.Tensor: input tensor: noised future trajectory indices / history trajectory indices\n",
    "            t: torch.Tensor: timestep tensor\n",
    "        \"\"\"    \n",
    "        \n",
    "        # GNN forward pass\n",
    "        \n",
    "        # Edge Embedding        \n",
    "        for layer in self.lin_layers:\n",
    "            x = F.relu(layer(x))\n",
    "\n",
    "        if mode == 'history':\n",
    "            c = self.history_encoder(x) # (bs, num_edges, condition_dim)\n",
    "            return c\n",
    "        \n",
    "        elif mode == 'future':\n",
    "            # Time embedding\n",
    "            t_emb = get_timestep_embedding(t, embedding_dim=self.time_embedding_dim, max_time=self.max_time, device=x.device)\n",
    "            t_emb = self.time_linear0(t_emb)\n",
    "            t_emb = F.silu(t_emb)  # SiLU activation, equivalent to Swish\n",
    "            t_emb = self.time_linear1(t_emb)\n",
    "            t_emb = F.silu(t_emb)   # (bs, time_embedding_dim)\n",
    "            t_emb = t_emb.unsqueeze(1).repeat(1, x.size(1), 1) # (bs, num_edges, time_embedding_dim)\n",
    "            \n",
    "            #Concatenation\n",
    "            x = torch.cat((x, t_emb), dim=2) # Concatenate with time embedding\n",
    "            x = torch.cat((x, condition), dim=2) # Concatenate with condition c, (bs, num_edges, hidden_channels + condition_dim + time_embedding_dim)\n",
    "            \n",
    "            logits = self.future_decoder(x) # (bs, num_edges, hidden_channels)\n",
    "            logits = self.adjust_to_class_shape(logits) # (bs, num_edges, num_classes=2)\n",
    "\n",
    "            return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = torch.load(\"/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/experiments/tdrive/tdrive_samples.pth\", map_location=torch.device('cpu'))\n",
    "hist = torch.load(\"/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/experiments/tdrive/tdrive_ground_truth_hist.pth\", map_location=torch.device('cpu'))\n",
    "fut = torch.load(\"/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/experiments/tdrive/tdrive_ground_truth_fut.pth\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder_model = Edge_Encoder\n",
    "encoder_model = Edge_Encoder_MLP\n",
    "#encoder_model = Edge_Encoder_Residual\n",
    "\n",
    "\n",
    "    \n",
    "data_config = {\"dataset\": \"synthetic_20_traj\",\n",
    "    \"train_data_path\": '/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/data/tdrive_train.h5',\n",
    "    \"val_data_path\": '/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/data/tdrive_val.h5',\n",
    "    \"history_len\": 5,\n",
    "    \"future_len\": 2,\n",
    "    \"num_classes\": 2,\n",
    "    \"edge_features\": ['one_hot_edges', 'coordinates']\n",
    "    }\n",
    "\n",
    "diffusion_config = {\"type\": 'linear', # Options: 'linear', 'cosine', 'jsd'\n",
    "    \"start\": 0.9,  # 1e-4 gauss, 0.02 uniform\n",
    "    \"stop\": 1.0,  # 0.02 gauss, 1. uniform\n",
    "    \"num_timesteps\": 200}\n",
    "\n",
    "model_config = {\"name\": \"edge_encoder_mlp\",\n",
    "    \"hidden_channels\": 32,\n",
    "    \"time_embedding_dim\": 16,\n",
    "    \"condition_dim\": 16,\n",
    "    \"out_ch\": 1,\n",
    "    \"num_heads\": 1,\n",
    "    \"num_layers\": 2,\n",
    "    \"theta\": 1.0, # controls strength of conv layers in residual model\n",
    "    \"dropout\": 0.1,\n",
    "    \"model_output\": \"logits\",\n",
    "    \"model_prediction\": \"x_start\",  # Options: 'x_start','xprev'\n",
    "    \"transition_mat_type\": 'marginal_prior',  # Options: 'gaussian','uniform','absorbing', 'marginal_prior'\n",
    "    \"transition_bands\": 1,\n",
    "    \"loss_type\": \"cross_entropy_x_start\",  # Options: kl, cross_entropy_x_start, hybrid\n",
    "    \"hybrid_coeff\": 0.001,  # Only used for hybrid loss type.\n",
    "    \"class_weights\": [0.05, 0.95] # = future_len/num_edges and (num_edges - future_len)/num_edges\n",
    "    }\n",
    "\n",
    "train_config = {\"batch_size\": 32,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"lr\": 0.01,\n",
    "    \"gradient_accumulation\": False,\n",
    "    \"gradient_accumulation_steps\": 128,\n",
    "    \"num_epochs\": 500,\n",
    "    \"learning_rate_warmup_steps\": 2000, # previously 10000\n",
    "    \"lr_decay\": 0.9999, # previously 0.9999\n",
    "    \"log_loss_every_steps\": 1,\n",
    "    \"save_model\": True,\n",
    "    \"save_model_every_steps\": 50}\n",
    "\n",
    "test_config = {\"batch_size\": 1, # currently only 1 works\n",
    "    \"model_path\": '/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/experiments/synthetic_d3pm_residual_fixed/synthetic_d3pm_residual_fixed_hidden_dim_32_time_dim_16_condition_dim_16_layers_2_weights_0.1.pth',\n",
    "    \"number_samples\": 1,\n",
    "    \"eval_every_steps\": 1000\n",
    "  }\n",
    "\n",
    "wandb_config = {\"exp_name\": \"tdrive_d3pm_test\",\n",
    "    \"project\": \"trajectory_prediction_using_denoising_diffusion_models\",\n",
    "    \"entity\": \"joeschmit99\",\n",
    "    \"job_type\": \"eval\",\n",
    "    \"notes\": \"\",\n",
    "    \"tags\": [\"tdrive\", \"edge_encoder\"]} \n",
    "\n",
    "model = Graph_Diffusion_Model(data_config, diffusion_config, model_config, train_config, test_config, wandb_config, model=encoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fut_ratio, f1, avg_sample_length\n",
    "model.eval(sample_list=samples, ground_truth_hist=hist, ground_truth_fut=fut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Dataset, Data\n",
    "import h5py\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "class MyData(Data):\n",
    "    def __cat_dim__(self, key, value, *args, **kwargs):\n",
    "        # Specify that 'future_edge_features' should not be concatenated across the zeroth dimension\n",
    "        if (key == 'y') or (key == 'history_indices') or (key == 'future_indices'):\n",
    "            return None  # This will add a new batch dimension during batching\n",
    "        else:\n",
    "            return super().__cat_dim__(key, value, *args, **kwargs)  # Default behaviour\n",
    "\n",
    "class TrajectoryGeoDataset(Dataset):\n",
    "    def __init__(self, file_path, history_len, future_len, edge_features=None, device=None, embedding_dim=None):\n",
    "        super().__init__()\n",
    "        self.file_path = file_path\n",
    "        self.history_len = history_len\n",
    "        self.future_len = future_len\n",
    "        self.edge_features = edge_features\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.device = device\n",
    "        '''self.num_edge_features = 1\n",
    "        if 'coordinates' in self.edge_features:\n",
    "            self.num_edge_features += 4\n",
    "        if 'edge_orientations' in self.edge_features:\n",
    "            self.num_edge_features += 1'''\n",
    "        '''if 'pos_encoding' in self.edge_features:\n",
    "            self.num_edge_features += self.embedding_dim'''\n",
    "        self.trajectories, self.nodes, self.edges, self.edge_coordinates = self.load_new_format(self.file_path, self.device)\n",
    "        \n",
    "        self.edge_coordinates = torch.tensor(self.edge_coordinates, dtype=torch.float64, device=self.device)\n",
    "        '''self.positional_encoding = self.generate_positional_encodings().float()'''\n",
    "        self.edge_index = self._build_edge_index()\n",
    "        # self.num_edges = self.edge_index.size(1)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_new_format(file_path, device):\n",
    "        paths = []\n",
    "        with h5py.File(file_path, 'r') as new_hf:\n",
    "            node_coordinates = torch.tensor(new_hf['graph']['node_coordinates'][:], dtype=torch.float, device=device)\n",
    "            # Normalize the coordinates to (0, 1) if any of the coordinates is larger than 1\n",
    "            if node_coordinates.max() > 1:\n",
    "                max_values = node_coordinates.max(0)[0]\n",
    "                min_values = node_coordinates.min(0)[0]\n",
    "                node_coordinates[:, 0] = (node_coordinates[:, 0] - min_values[0]) / (max_values[0] - min_values[0])\n",
    "                node_coordinates[:, 1] = (node_coordinates[:, 1] - min_values[1]) / (max_values[1] - min_values[1])\n",
    "            #edges = torch.tensor(new_hf['graph']['edges'][:], dtype=torch.long, device=device)\n",
    "            edges = new_hf['graph']['edges'][:]\n",
    "            edge_coordinates = node_coordinates[edges]\n",
    "            nodes = [(i, {'pos': torch.tensor(pos, device=device)}) for i, pos in enumerate(node_coordinates)]\n",
    "            #edges = [(torch.tensor(edge[0], device=device), torch.tensor(edge[1], device=device)) for edge in edges]\n",
    "            edges = [tuple(edge) for edge in edges]\n",
    "\n",
    "            for i in tqdm(new_hf['trajectories'].keys()):\n",
    "                path_group = new_hf['trajectories'][i]\n",
    "                path = {attr: torch.tensor(path_group[attr][()], device=device) for attr in path_group.keys() if attr in ['coordinates', 'edge_idxs', 'edge_orientations']}\n",
    "                paths.append(path)\n",
    "            \n",
    "        return paths, nodes, edges, edge_coordinates\n",
    "    \n",
    "    def _build_edge_index(self):\n",
    "        print(\"Building edge index for line graph...\")\n",
    "        self.G = self.build_graph()\n",
    "        self.num_edges = self.G.number_of_edges()\n",
    "        edge_index = torch.tensor([[e[0], e[1]] for e in self.G.edges(data=True)], dtype=torch.long).t().contiguous()\n",
    "        edge_to_index = {tuple(e[:2]): e[2]['index'] for e in self.G.edges(data=True)}\n",
    "        line_graph_edges = []\n",
    "        edge_list = edge_index.t().tolist()\n",
    "        for i, (u1, v1) in tqdm(enumerate(edge_list), total=len(edge_list), desc=\"Processing edges\"):\n",
    "            for j, (u2, v2) in enumerate(edge_list):\n",
    "                if i != j and (u1 == u2 or u1 == v2 or v1 == u2 or v1 == v2):\n",
    "                    line_graph_edges.append((edge_to_index[(u1, v1)], edge_to_index[(u2, v2)]))\n",
    "\n",
    "        # Create the edge index for the line graph\n",
    "        edge_index = torch.tensor(line_graph_edges, dtype=torch.long).t().contiguous()\n",
    "        print(\"> Edge index built!\\n\")\n",
    "        \n",
    "        return edge_index.to(self.device, non_blocking=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.trajectories)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        trajectory = self.trajectories[idx]\n",
    "        edge_idxs = trajectory['edge_idxs']\n",
    "        if 'edge_orientations' in self.edge_features:\n",
    "            edge_orientations = trajectory['edge_orientations']\n",
    "        \n",
    "        padding_length = max(self.history_len + self.future_len - len(edge_idxs), 0)\n",
    "        edge_idxs = torch.nn.functional.pad(edge_idxs, (0, padding_length), value=-1)\n",
    "\n",
    "        # Split into history and future\n",
    "        history_indices = edge_idxs[:self.history_len]\n",
    "        future_indices = edge_idxs[self.history_len:self.history_len + self.future_len]\n",
    "\n",
    "        # Extract and generate features\n",
    "        history_edge_features, future_edge_features = self.generate_edge_features(history_indices, future_indices, self.edge_coordinates)\n",
    "        data = MyData(x=history_edge_features,          # (batch_size * num_edges, num_edge_features)\n",
    "                    edge_index=self.edge_index,         # (2, num_edges)\n",
    "                    y=future_edge_features,             # (batch_size, num_edges, 1)\n",
    "                    history_indices=history_indices,    # (batch_size, history_len)\n",
    "                    future_indices=future_indices,      # (batch_size, future_len)\n",
    "                    num_nodes=self.num_edges)      \n",
    "        \n",
    "        return data\n",
    "\n",
    "    def generate_edge_features(self, history_indices, future_indices, history_edge_orientations=None, future_edge_orientations=None):\n",
    "        # Binary on/off edges\n",
    "        valid_history_mask = history_indices >= 0\n",
    "        valid_future_mask = future_indices >= 0\n",
    "        \n",
    "        history_one_hot_edges = torch.nn.functional.one_hot(history_indices[valid_history_mask], num_classes=len(self.edges))\n",
    "        future_one_hot_edges = torch.nn.functional.one_hot(future_indices[valid_future_mask], num_classes=len(self.edges))\n",
    "        \n",
    "        # Sum across the time dimension to count occurrences of each edge\n",
    "        history_one_hot_edges = history_one_hot_edges.sum(dim=0)  # (num_edges,)\n",
    "        future_one_hot_edges = future_one_hot_edges.sum(dim=0)  # (num_edges,)\n",
    "        \n",
    "        # Basic History edge features = coordinates, binary encoding\n",
    "        history_edge_features = history_one_hot_edges.view(-1, 1).float()\n",
    "        future_edge_features = future_one_hot_edges.view(-1, 1).float()\n",
    "        if 'coordinates' in self.edge_features:\n",
    "            history_edge_features = torch.cat((history_edge_features, torch.flatten(self.edge_coordinates, start_dim=1).float()), dim=1)\n",
    "        if 'edge_orientations' in self.edge_features:\n",
    "            history_edge_features = torch.cat((history_edge_features, history_edge_orientations.float()), dim=1)\n",
    "        \n",
    "        return history_edge_features, future_edge_features\n",
    "    \n",
    "    def build_graph(self):\n",
    "        import networkx as nx\n",
    "        graph = nx.Graph()\n",
    "        graph.add_nodes_from(self.nodes)\n",
    "        indexed_edges = [((start, end), index) for index, (start, end) in enumerate(self.edges)]\n",
    "        for (start, end), index in indexed_edges:\n",
    "            graph.add_edge(start, end, index=index, default_orientation=(start, end))\n",
    "        return graph\n",
    "    \n",
    "def custom_collate_fn(batch):\n",
    "    batch_size = len(batch)\n",
    "    num_edges = batch[0].num_nodes\n",
    "\n",
    "    x = torch.cat([data.x for data in batch], dim=0)\n",
    "    y = torch.cat([data.y for data in batch], dim=0)\n",
    "    history_indices = torch.cat([data.history_indices for data in batch], dim=0)\n",
    "    future_indices = torch.cat([data.future_indices for data in batch], dim=0)\n",
    "\n",
    "    edge_indices = [data.edge_index for data in batch]\n",
    "    for i, edge_index in enumerate(edge_indices):\n",
    "        edge_indices[i] = edge_index + i * num_edges\n",
    "\n",
    "    edge_index = torch.cat(edge_indices, dim=1)\n",
    "    num_nodes = batch_size * num_edges\n",
    "\n",
    "    return MyData(x=x, edge_index=edge_index, y=y, history_indices=history_indices, future_indices=future_indices, num_nodes=num_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn.conv import GATv2Conv\n",
    "\n",
    "def get_timestep_embedding(timesteps, embedding_dim, max_time=1000., device=None):\n",
    "    \"\"\"\n",
    "    Build sinusoidal embeddings (from Fairseq).\n",
    "\n",
    "    This matches the implementation in tensor2tensor, but differs slightly\n",
    "    from the description in Section 3.5 of \"Attention Is All You Need\".\n",
    "\n",
    "    Args:\n",
    "        timesteps: torch.Tensor: generate embedding vectors at these timesteps\n",
    "        embedding_dim: int: dimension of the embeddings to generate\n",
    "        max_time: float: largest time input\n",
    "\n",
    "    Returns:\n",
    "        embedding vectors with shape `(len(timesteps), embedding_dim)`\n",
    "    \"\"\"\n",
    "    timesteps = timesteps.to(device)\n",
    "    assert timesteps.dim() == 1  # Ensure timesteps is a 1D tensor\n",
    "\n",
    "    # Scale timesteps by the maximum time\n",
    "    timesteps = timesteps.float() * (1000. / max_time)\n",
    "\n",
    "    half_dim = embedding_dim // 2\n",
    "    emb = torch.log(torch.tensor(10000.0, device=device)) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32, device=device) * -emb)\n",
    "    emb = timesteps[:, None] * emb[None, :]\n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "\n",
    "    if embedding_dim % 2 == 1:  # Add zero-padding if embedding dimension is odd\n",
    "        zero_pad = torch.zeros((timesteps.shape[0], 1), dtype=torch.float32)\n",
    "        emb = torch.cat([emb, zero_pad], dim=1)\n",
    "\n",
    "    assert emb.shape == (timesteps.shape[0], embedding_dim)\n",
    "    return emb.to(device)\n",
    "\n",
    "\n",
    "def generate_positional_encodings(history_len, embedding_dim, device, n=1000):\n",
    "    PE = torch.zeros((history_len, embedding_dim), device=device)\n",
    "    for k in range(history_len):\n",
    "        for i in torch.arange(int(embedding_dim/2)):\n",
    "            denominator = torch.pow(n, 2*i/embedding_dim)\n",
    "            PE[k, 2*i] = torch.sin(k/denominator)\n",
    "            PE[k, 2*i+1] = torch.cos(k/denominator)\n",
    "    return PE\n",
    "\n",
    "class Edge_Encoder_Residual(nn.Module):\n",
    "    def __init__(self, model_config, history_len, future_len, num_classes, num_edges, hidden_channels, edge_features, num_edge_features, num_timesteps, pos_encoding_dim):\n",
    "        super(Edge_Encoder_Residual, self).__init__()\n",
    "        # Config\n",
    "        self.config = model_config\n",
    "        \n",
    "        # Data\n",
    "        self.num_edges = num_edges\n",
    "        self.num_edge_features = num_edge_features\n",
    "        self.history_len = history_len\n",
    "        self.future_len = future_len\n",
    "        self.edge_features = edge_features\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.model_output = self.config['model_output']\n",
    "        \n",
    "        # Time embedding\n",
    "        self.max_time = num_timesteps\n",
    "        self.time_embedding_dim = self.config['time_embedding_dim']\n",
    "        self.time_linear0 = nn.Linear(self.time_embedding_dim, self.time_embedding_dim)\n",
    "        self.time_linear1 = nn.Linear(self.time_embedding_dim, self.time_embedding_dim)\n",
    "        \n",
    "        # Positional Encoding\n",
    "        self.pos_encoding_dim = pos_encoding_dim\n",
    "        if 'pos_encoding' in self.edge_features:\n",
    "            self.pos_linear0 = nn.Linear(self.pos_encoding_dim, self.pos_encoding_dim)\n",
    "            self.pos_linear1 = nn.Linear(self.pos_encoding_dim, self.pos_encoding_dim)\n",
    "    \n",
    "        # Model\n",
    "        # GNN layers\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_heads = self.config['num_heads']\n",
    "        self.num_layers = self.config['num_layers']\n",
    "        self.theta = self.config['theta']\n",
    "        \n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(GATv2Conv(self.num_edge_features, self.hidden_channels, heads=self.num_heads, bias=False))\n",
    "        self.res_layers = nn.ModuleList()\n",
    "        self.res_layers.append(nn.Linear(self.num_edge_features, self.hidden_channels * self.num_heads, bias=False))\n",
    "        for _ in range(1, self.num_layers):\n",
    "            self.convs.append(GATv2Conv(self.hidden_channels * self.num_heads, self.hidden_channels, heads=self.num_heads, bias=False))\n",
    "            self.res_layers.append(nn.Linear(self.hidden_channels * self.num_heads, self.hidden_channels * self.num_heads, bias=False))\n",
    "\n",
    "        # Output layers for each task\n",
    "        self.condition_dim = self.config['condition_dim']\n",
    "        self.history_encoder = nn.Linear(self.hidden_channels * self.num_heads, self.condition_dim)  # To encode history to c\n",
    "        if 'pos_encoding' in self.edge_features:\n",
    "            self.future_decoder = nn.Linear(self.hidden_channels * self.num_heads + self.condition_dim + self.time_embedding_dim + self.pos_encoding_dim,\n",
    "                                        self.hidden_channels)  # To predict future edges\n",
    "        else:\n",
    "            self.future_decoder = nn.Linear(self.hidden_channels * self.num_heads + self.condition_dim + self.time_embedding_dim,\n",
    "                                            self.hidden_channels)  # To predict future edges\n",
    "        self.adjust_to_class_shape = nn.Linear(self.hidden_channels, self.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, indices=None, t=None, condition=None, mode=None, batch=None):\n",
    "        \"\"\"\n",
    "        Forward pass through the model\n",
    "        Args:\n",
    "            x: torch.Tensor: input tensor: edge attributes, including binary encoding fo edges present/absent in trajectory\n",
    "            t: torch.Tensor: timestep tensor\n",
    "        \"\"\"    \n",
    "        print(\"Edge Index\", edge_index.size())\n",
    "        print(edge_index)\n",
    "        \n",
    "        # GNN forward pass\n",
    "        # Edge Embedding\n",
    "        if indices is not None:\n",
    "            print(\"Indices\", indices)\n",
    "        batch_size = x.size(0) // self.num_edges\n",
    "        enc = 1\n",
    "        if x.dim() == 3:\n",
    "            enc = 0\n",
    "            x = x.squeeze(0)    # (bs, num_edges, num_edge_features) -> (num_edges, num_edge_features)\n",
    "        #print(\"Input\", x.size())\n",
    "        #print(x)\n",
    "        for conv, res_layer in zip(self.convs, self.res_layers):\n",
    "            res = F.relu(res_layer(x))\n",
    "            x = F.relu(conv(x, edge_index))\n",
    "            x = self.theta * x# + res        # (batch_size * num_edges, hidden_channels * num_heads)\n",
    "            #x = F.relu(res_layer(x))\n",
    "            \n",
    "        print(\"x\", x.size())\n",
    "        print(x)\n",
    "        if mode == 'history':\n",
    "            c = self.history_encoder(x)     # (batch_size * num_edges, condition_dim)\n",
    "            print(\"Condition before\", c.size())\n",
    "            print(c)\n",
    "            if 'pos_encoding' in self.edge_features:\n",
    "                pos_encoding = generate_positional_encodings(self.history_len, self.pos_encoding_dim, device=x.device)\n",
    "                encodings = F.silu(self.pos_linear0(pos_encoding))\n",
    "                encodings = F.silu(self.pos_linear1(encodings))\n",
    "                print(\"Encodings\", encodings.size())\n",
    "                print(encodings)\n",
    "                if enc == 0:\n",
    "                    c = self.integrate_encodings_old(c, indices, encodings)     # (batch_size * num_edges, condition_dim + pos_encoding_dim\n",
    "                else:\n",
    "                    c = self.integrate_encodings(c, indices, encodings)     # (batch_size * num_edges, condition_dim + pos_encoding_dim)\n",
    "            print(\"Condition after\", c.size())\n",
    "            print(c)\n",
    "            return c\n",
    "        \n",
    "        elif mode == 'future':\n",
    "            # Time embedding\n",
    "            # TODO: Check if time embedding and condition generation are the same for each datapoint in a batch and hence the problems while sampling\n",
    "            #print(\"Time\", t)\n",
    "            t_emb = get_timestep_embedding(t, embedding_dim=self.time_embedding_dim, max_time=self.max_time, device=x.device)\n",
    "            t_emb = self.time_linear0(t_emb)\n",
    "            t_emb = F.silu(t_emb)  # SiLU activation, equivalent to Swish\n",
    "            t_emb = self.time_linear1(t_emb)\n",
    "            t_emb = F.silu(t_emb)   # (batch_size, time_embedding_dim)\n",
    "            #print(\"T_emb\", t_emb)\n",
    "            if enc == 0:\n",
    "                t_emb = t_emb.repeat(self.num_edges, 1)\n",
    "            else:\n",
    "                t_emb = torch.repeat_interleave(t_emb, self.num_edges, dim=0) # (batch_size * num_edges, time_embedding_dim)\n",
    "            #print(\"T_emb after\", t_emb)\n",
    "            #print(\"T_emb\", t_emb.size())\n",
    "            \n",
    "            #Concatenation\n",
    "            x = torch.cat((x, t_emb), dim=1) # Concatenate with time embedding, (batch_size * num_edges, hidden_dim')\n",
    "            #print(\"x\", x.size())\n",
    "            x = torch.cat((x, condition), dim=1) # Concatenate with condition c, (batch_size * num_edges, hidden_dim')\n",
    "            #print(\"x\", x.size())\n",
    "            logits = self.future_decoder(x) # (batch_size * num_edges, hidden_channels)\n",
    "            #print(\"logits\", logits.size())\n",
    "            logits = self.adjust_to_class_shape(logits) # (batch_size * num_edges, num_classes=2)\n",
    "            #print(\"Logits size\", logits.size())\n",
    "            if enc == 0:\n",
    "                return logits.unsqueeze(0)\n",
    "            else:\n",
    "                return logits.view(batch_size, self.num_edges, -1)  # (1, num_edges, num_classes=2)\n",
    "\n",
    "    def integrate_encodings(self, features, indices, encodings):\n",
    "        \"\"\"\n",
    "        Integrates positional encodings into the feature matrix.\n",
    "\n",
    "        Args:\n",
    "            features (torch.Tensor): Original feature matrix [num_edges, num_features].\n",
    "            indices (torch.Tensor): Indices of edges where the encodings should be added.\n",
    "            encodings (torch.Tensor): Positional encodings [len(indices), encoding_dim].\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Updated feature matrix with positional encodings integrated.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Ensure that features are on the same device as encodings\n",
    "        batch_size = indices.shape[0]# // self.history_len\n",
    "        encodings = encodings.repeat(batch_size, 1)\n",
    "        #print(encodings)\n",
    "        # Ensure that features and encodings are on the same device\n",
    "        features = features.to(encodings.device)\n",
    "        \n",
    "        # Expand the features tensor to accommodate the positional encodings\n",
    "        new_features = torch.cat([features, torch.zeros(features.size(0), encodings.size(1), device=features.device)], dim=1)\n",
    "        \n",
    "        # Calculate batch offsets\n",
    "        batch_offsets = torch.arange(batch_size, device=features.device) * self.num_edges\n",
    "        \n",
    "        # Reshape indices to batched format to adjust with batch offsets\n",
    "        # indices_batched = indices.view(batch_size, self.history_len)\n",
    "        \n",
    "        # Flatten indices for direct access, adjust with batch offsets\n",
    "        flat_indices = (indices + batch_offsets.unsqueeze(1)).flatten()\n",
    "        \n",
    "        # Place the positional encodings in the correct rows across all batches\n",
    "        new_features[flat_indices, -encodings.size(1):] = encodings\n",
    "\n",
    "        return new_features\n",
    "    \n",
    "    def integrate_encodings_old(self, features, indices, encodings):\n",
    "        \"\"\"\n",
    "        Integrates positional encodings into the feature matrix.\n",
    "\n",
    "        Args:\n",
    "            features (torch.Tensor): Original feature matrix [num_edges, num_features].\n",
    "            indices (torch.Tensor): Indices of edges where the encodings should be added.\n",
    "            encodings (torch.Tensor): Positional encodings [len(indices), encoding_dim].\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Updated feature matrix with positional encodings integrated.\n",
    "        \"\"\"\n",
    "        # Ensure that features are on the same device as encodings\n",
    "        features = features.to(encodings.device)\n",
    "        \n",
    "        # Expand the features tensor to accommodate the positional encodings\n",
    "        new_features = torch.cat([features, torch.zeros(features.size(0), encodings.size(1), device=features.device)], dim=1)\n",
    "        \n",
    "        # Place the positional encodings in the rows specified by indices\n",
    "        new_features[indices, -encodings.size(1):] = encodings\n",
    "\n",
    "        return new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3207662/1086019238.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nodes = [(i, {'pos': torch.tensor(pos, device=device)}) for i, pos in enumerate(node_coordinates)]\n",
      "100%|| 4/4 [00:00<00:00, 891.69it/s]\n",
      "/tmp/ipykernel_3207662/1086019238.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.edge_coordinates = torch.tensor(self.edge_coordinates, dtype=torch.float64, device=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building edge index for line graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing edges: 100%|| 46/46 [00:00<00:00, 47780.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Edge index built!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/ceph/hdd/students/schmitj/miniconda3/envs/diffusion/lib/python3.12/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "train_data_path = '/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/data/synthetic_4_traj.h5'\n",
    "history_len = 5\n",
    "future_len = 5\n",
    "edge_features = ['one_hot_edges', 'coordinates', 'pos_encoding']\n",
    "train_dataset = TrajectoryGeoDataset(train_data_path, history_len, future_len, edge_features, device='cpu')\n",
    "from torch_geometric.data import DataLoader\n",
    "train_data_loader = DataLoader(train_dataset, \n",
    "                                    batch_size=2, \n",
    "                                    shuffle=False, \n",
    "                                    collate_fn=custom_collate_fn, \n",
    "                                    num_workers=0,\n",
    "                                    pin_memory=False,\n",
    "                                    follow_batch=['x', 'y', 'history_indices', 'future_indices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import networkx as nx\n",
    "\n",
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, file_path, history_len, future_len, edge_features=None, device=None, embedding_dim=None):\n",
    "        self.file_path = file_path\n",
    "        self.history_len = history_len\n",
    "        self.future_len = future_len\n",
    "        self.edge_features = edge_features\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.device = device\n",
    "        self.num_edge_features = 1\n",
    "        if 'coordinates' in self.edge_features:\n",
    "            self.num_edge_features += 4\n",
    "        if 'edge_orientations' in self.edge_features:\n",
    "            self.num_edge_features += 1\n",
    "        '''if 'pos_encoding' in self.edge_features:\n",
    "            self.num_edge_features += self.embedding_dim'''\n",
    "        self.trajectories, self.nodes, self.edges, self.edge_coordinates = self.load_new_format(file_path, self.device)\n",
    "        \n",
    "        self.edge_coordinates = torch.tensor(self.edge_coordinates, dtype=torch.float64, device=self.device)\n",
    "        self.edge_index = self._build_edge_index()\n",
    "        # self.positional_encoding = self.generate_positional_encodings().float()\n",
    "        \n",
    "    @staticmethod\n",
    "    def load_new_format(file_path, device):\n",
    "        paths = []\n",
    "        with h5py.File(file_path, 'r') as new_hf:\n",
    "            node_coordinates = torch.tensor(new_hf['graph']['node_coordinates'][:], dtype=torch.float, device=device)\n",
    "            # Normalize the coordinates to (0, 1) if any of the coordinates is larger than 1\n",
    "            if node_coordinates.max() > 1:\n",
    "                max_values = node_coordinates.max(0)[0]\n",
    "                min_values = node_coordinates.min(0)[0]\n",
    "                node_coordinates[:, 0] = (node_coordinates[:, 0] - min_values[0]) / (max_values[0] - min_values[0])\n",
    "                node_coordinates[:, 1] = (node_coordinates[:, 1] - min_values[1]) / (max_values[1] - min_values[1])\n",
    "            #edges = torch.tensor(new_hf['graph']['edges'][:], dtype=torch.long, device=device)\n",
    "            edges = new_hf['graph']['edges'][:]\n",
    "            edge_coordinates = node_coordinates[edges]\n",
    "            nodes = [(i, {'pos': torch.tensor(pos, device=device)}) for i, pos in enumerate(node_coordinates)]\n",
    "            #edges = [(torch.tensor(edge[0], device=device), torch.tensor(edge[1], device=device)) for edge in edges]\n",
    "            edges = [tuple(edge) for edge in edges]\n",
    "\n",
    "            for i in tqdm(new_hf['trajectories'].keys()):\n",
    "                path_group = new_hf['trajectories'][i]\n",
    "                path = {attr: torch.tensor(path_group[attr][()], device=device) for attr in path_group.keys() if attr in ['coordinates', 'edge_idxs', 'edge_orientations']}\n",
    "                paths.append(path)\n",
    "            \n",
    "        return paths, nodes, edges, edge_coordinates\n",
    "    \n",
    "    # @staticmethod\n",
    "    def build_graph(self):\n",
    "        graph = nx.Graph()\n",
    "        graph.add_nodes_from(self.nodes)\n",
    "        indexed_edges = [((start, end), index) for index, (start, end) in enumerate(self.edges)]\n",
    "        for (start, end), index in indexed_edges:\n",
    "            graph.add_edge(start, end, index=index, default_orientation=(start, end))\n",
    "        return graph\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        trajectory = self.trajectories[idx]\n",
    "    \n",
    "        edge_idxs = trajectory['edge_idxs']\n",
    "        if 'edge_orientations' in self.edge_features:\n",
    "            edge_orientations = trajectory['edge_orientations']\n",
    "        \n",
    "        # Calculate the required padding length\n",
    "        total_len = self.history_len + self.future_len\n",
    "        padding_length = max(total_len - len(edge_idxs), 0)\n",
    "        \n",
    "        # Pad edge indices, orientations, and coordinates\n",
    "        edge_idxs = torch.nn.functional.pad(edge_idxs, (0, padding_length), value=-1)\n",
    "        if 'edge_orientations' in self.edge_features:\n",
    "            edge_orientations = torch.nn.functional.pad(edge_orientations, (0, padding_length), value=0)\n",
    "        \n",
    "        # Split into history and future\n",
    "        history_indices = edge_idxs[:self.history_len]\n",
    "        future_indices = edge_idxs[self.history_len:self.history_len + self.future_len]\n",
    "\n",
    "        # Extract and generate features\n",
    "        history_edge_features, future_edge_features = self.generate_edge_features(history_indices, future_indices, self.edge_coordinates)\n",
    "\n",
    "        return {\n",
    "            \"history_indices\": history_indices,\n",
    "            \"future_indices\": future_indices,\n",
    "            \"history_edge_features\": history_edge_features,\n",
    "            \"future_edge_features\": future_edge_features,\n",
    "        }\n",
    "\n",
    "    def generate_edge_features(self, history_indices, future_indices, history_edge_orientations=None, future_edge_orientations=None):\n",
    "        # Binary on/off edges\n",
    "        valid_history_mask = history_indices >= 0\n",
    "        valid_future_mask = future_indices >= 0\n",
    "        \n",
    "        history_one_hot_edges = torch.nn.functional.one_hot(history_indices[valid_history_mask], num_classes=len(self.edges))\n",
    "        future_one_hot_edges = torch.nn.functional.one_hot(future_indices[valid_future_mask], num_classes=len(self.edges))\n",
    "        \n",
    "        # Sum across the time dimension to count occurrences of each edge\n",
    "        history_one_hot_edges = history_one_hot_edges.sum(dim=0)  # (num_edges,)\n",
    "        future_one_hot_edges = future_one_hot_edges.sum(dim=0)  # (num_edges,)\n",
    "        \n",
    "        # Basic History edge features = coordinates, binary encoding\n",
    "        history_edge_features = history_one_hot_edges.view(-1, 1).float()\n",
    "        future_edge_features = future_one_hot_edges.view(-1, 1).float()\n",
    "        if 'coordinates' in self.edge_features:\n",
    "            history_edge_features = torch.cat((history_edge_features, torch.flatten(self.edge_coordinates, start_dim=1).float()), dim=1)\n",
    "            future_edge_features = torch.cat((future_edge_features, torch.flatten(self.edge_coordinates, start_dim=1).float()), dim=1)\n",
    "        if 'edge_orientations' in self.edge_features:\n",
    "            history_edge_features = torch.cat((history_edge_features, history_edge_orientations.float()), dim=1)\n",
    "            future_edge_features = torch.cat((future_edge_features, future_edge_orientations.float()), dim=1)\n",
    "        '''if 'pos_encoding' in self.edge_features:\n",
    "            encoding_tensor = torch.zeros((len(self.edges), self.embedding_dim), dtype=torch.float64, device=self.device)\n",
    "            for i, index in enumerate(history_indices):\n",
    "                encoding_tensor[index] = self.positional_encoding[i]\n",
    "            history_edge_features = torch.cat((history_edge_features, encoding_tensor.float()), dim=1)    '''\n",
    "        \n",
    "        return history_edge_features, future_edge_features\n",
    "    \n",
    "    def generate_positional_encodings(self):\n",
    "        position = torch.arange(self.history_len)\n",
    "        angle_rates = 1 / torch.pow(10000, (2 * (torch.arange(self.embedding_dim) // 2)) / self.embedding_dim)\n",
    "        angle_rads = position.float().unsqueeze(1) * angle_rates.unsqueeze(0)\n",
    "        sines = torch.sin(angle_rads[:, 0::2])\n",
    "        cosines = torch.cos(angle_rads[:, 1::2])\n",
    "        \n",
    "        return torch.cat((sines.float(), cosines.float()), dim=-1).to(self.device, non_blocking=True)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.trajectories)\n",
    "    \n",
    "    def _build_edge_index(self):\n",
    "        print(\"Building edge index for line graph...\")\n",
    "        self.G = self.build_graph()\n",
    "        edge_index = torch.tensor([[e[0], e[1]] for e in self.G.edges(data=True)], dtype=torch.long).t().contiguous()\n",
    "        edge_to_index = {tuple(e[:2]): e[2]['index'] for e in self.G.edges(data=True)}\n",
    "        line_graph_edges = []\n",
    "        edge_list = edge_index.t().tolist()\n",
    "        for i, (u1, v1) in tqdm(enumerate(edge_list), total=len(edge_list), desc=\"Processing edges\"):\n",
    "            for j, (u2, v2) in enumerate(edge_list):\n",
    "                if i != j and (u1 == u2 or u1 == v2 or v1 == u2 or v1 == v2):\n",
    "                    line_graph_edges.append((edge_to_index[(u1, v1)], edge_to_index[(u2, v2)]))\n",
    "\n",
    "        # Create the edge index for the line graph\n",
    "        edge_index = torch.tensor(line_graph_edges, dtype=torch.long).t().contiguous()\n",
    "        print(\"> Edge index built!\\n\")\n",
    "        \n",
    "        return edge_index.to(self.device, non_blocking=True)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    history_indices = torch.stack([item['history_indices'] for item in batch])\n",
    "    future_indices = torch.stack([item['future_indices'] for item in batch])\n",
    "    history_edge_features = torch.stack([item['history_edge_features'] for item in batch])\n",
    "    future_edge_features = torch.stack([item['future_edge_features'] for item in batch])\n",
    "\n",
    "    return {\n",
    "        \"history_indices\": history_indices,\n",
    "        \"future_indices\": future_indices,\n",
    "        \"history_edge_features\": history_edge_features,\n",
    "        \"future_edge_features\": future_edge_features,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3207662/2380671171.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nodes = [(i, {'pos': torch.tensor(pos, device=device)}) for i, pos in enumerate(node_coordinates)]\n",
      "100%|| 4/4 [00:00<00:00, 1018.34it/s]\n",
      "/tmp/ipykernel_3207662/2380671171.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.edge_coordinates = torch.tensor(self.edge_coordinates, dtype=torch.float64, device=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building edge index for line graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing edges: 100%|| 46/46 [00:00<00:00, 64269.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Edge index built!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data_path = '/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/data/synthetic_4_traj.h5'\n",
    "history_len = 5\n",
    "future_len = 5\n",
    "edge_features = ['one_hot_edges', 'coordinates', 'pos_encoding']\n",
    "old_train_dataset = TrajectoryDataset(train_data_path, history_len, future_len, edge_features, device='cpu')\n",
    "from torch.utils.data import DataLoader\n",
    "old_train_data_loader = DataLoader(old_train_dataset, \n",
    "                                    batch_size=2, \n",
    "                                    shuffle=False, \n",
    "                                    collate_fn=collate_fn, \n",
    "                                    num_workers=0,\n",
    "                                    pin_memory=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = {\"dataset\": \"synthetic_20_traj\",\n",
    "    \"train_data_path\": '/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/data/synthetic_4_traj.h5',\n",
    "    \"val_data_path\": '/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/data/synthetic_4_traj.h5',\n",
    "    \"history_len\": 5,\n",
    "    \"future_len\": 5,\n",
    "    \"num_classes\": 2,\n",
    "    \"pos_encoding_dim\": 2,\n",
    "    \"edge_features\": ['one_hot_edges', 'coordinates', 'pos_encoding']#, 'pos_encoding'\n",
    "    }\n",
    "\n",
    "diffusion_config = {\"type\": 'cosine', # Options: 'linear', 'cosine', 'jsd'\n",
    "    \"start\": 0.0001,  # 1e-4 gauss, 0.02 uniform\n",
    "    \"stop\": 0.01,  # 0.02 gauss, 1. uniform\n",
    "    \"num_timesteps\": 50}\n",
    "\n",
    "model_config = {\"name\": \"edge_encoder_residual\",\n",
    "    \"hidden_channels\": 4,\n",
    "    \"time_embedding_dim\": 2,\n",
    "    \"condition_dim\": 2,\n",
    "    \"num_heads\": 1,\n",
    "    \"num_layers\": 1,\n",
    "    \"theta\": 1.0, # controls strength of conv layers in residual model\n",
    "    \"dropout\": 0.1,\n",
    "    \"model_output\": \"logits\",\n",
    "    \"model_prediction\": \"x_start\",  # Options: 'x_start','xprev'\n",
    "    \"transition_mat_type\": 'custom',  # Options: 'gaussian', 'uniform', 'absorbing', 'marginal_prior', 'custom'\n",
    "    \"transition_bands\": 0,\n",
    "    \"loss_type\": \"cross_entropy_x_start\",  # Options: kl, cross_entropy_x_start, hybrid\n",
    "    \"hybrid_coeff\": 0.001,  # Only used for hybrid loss type.\n",
    "    }\n",
    "\n",
    "train_config = {\"batch_size\": 2,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"lr\": 0.01,\n",
    "    \"gradient_accumulation\": False,\n",
    "    \"gradient_accumulation_steps\": 16,\n",
    "    \"num_epochs\": 800,\n",
    "    \"learning_rate_warmup_steps\": 300, # previously 10000\n",
    "    \"lr_decay\": 0.9995, # previously 0.9999\n",
    "    \"log_loss_every_steps\": 2,\n",
    "    \"log_metrics_every_steps\": 2,\n",
    "    \"save_model\": False,\n",
    "    \"save_model_every_steps\": 1}\n",
    "\n",
    "test_config = {\"batch_size\": 1, # currently only 1 works\n",
    "    \"model_path\": '/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/experiments/geolife_residual/geolife_residual_edge_encoder_residual_marginal_prior_cosine_hidden_dim_32_time_dim_16_condition_dim_16_layers_2.pth',\n",
    "    \"number_samples\": 1,\n",
    "    \"eval_every_steps\": 100\n",
    "  }\n",
    "\n",
    "wandb_config = {\"exp_name\": \"synthetic_d3pm_test\",\n",
    "    \"project\": \"trajectory_prediction_using_denoising_diffusion_models\",\n",
    "    \"entity\": \"joeschmit99\",\n",
    "    \"job_type\": \"test\",\n",
    "    \"notes\": \"\",\n",
    "    \"tags\": [\"synthetic\", \"edge_encoder\"]} \n",
    "G = train_dataset.build_graph()\n",
    "\n",
    "model = Edge_Encoder_Residual(model_config, history_len, future_len, num_classes=2, num_edges=G.number_of_edges(), hidden_channels=4, edge_features=edge_features, num_edge_features=5, num_timesteps=50, pos_encoding_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge Index torch.Size([2, 488])\n",
      "tensor([[ 0,  0,  0,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,\n",
      "          3,  3,  3,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  6,  6,  6,  7,  7,\n",
      "          7,  8,  8,  8,  8,  9,  9,  9,  9,  9, 10, 10, 10, 10, 11, 11, 11, 11,\n",
      "         11, 12, 12, 12, 12, 12, 12, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15, 15,\n",
      "         15, 15, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18,\n",
      "         18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 21, 21,\n",
      "         21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23,\n",
      "         23, 23, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 26, 26, 26, 26,\n",
      "         27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29,\n",
      "         29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 32,\n",
      "         32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 35,\n",
      "         35, 35, 35, 36, 36, 36, 36, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 39,\n",
      "         39, 39, 39, 40, 40, 40, 40, 40, 41, 41, 42, 42, 42, 42, 42, 43, 43, 43,\n",
      "         44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 46, 46, 46, 47, 47, 47, 47, 47,\n",
      "         48, 48, 48, 48, 48, 48, 49, 49, 49, 49, 49, 49, 49, 50, 50, 50, 50, 50,\n",
      "         50, 51, 51, 51, 51, 52, 52, 52, 53, 53, 53, 54, 54, 54, 54, 55, 55, 55,\n",
      "         55, 55, 56, 56, 56, 56, 57, 57, 57, 57, 57, 58, 58, 58, 58, 58, 58, 59,\n",
      "         59, 59, 60, 60, 60, 60, 60, 60, 61, 61, 61, 61, 62, 62, 62, 62, 62, 62,\n",
      "         63, 63, 63, 63, 63, 63, 64, 64, 64, 64, 64, 64, 64, 65, 65, 65, 65, 65,\n",
      "         65, 65, 66, 66, 66, 66, 66, 66, 67, 67, 67, 67, 67, 67, 67, 67, 68, 68,\n",
      "         68, 68, 68, 68, 68, 69, 69, 69, 69, 69, 69, 69, 70, 70, 70, 70, 70, 70,\n",
      "         70, 71, 71, 71, 71, 71, 72, 72, 72, 72, 73, 73, 73, 73, 73, 73, 74, 74,\n",
      "         74, 74, 74, 74, 75, 75, 75, 75, 75, 75, 75, 76, 76, 76, 76, 76, 76, 76,\n",
      "         76, 76, 77, 77, 77, 77, 77, 77, 77, 78, 78, 78, 78, 78, 78, 78, 79, 79,\n",
      "         79, 79, 79, 79, 80, 80, 80, 80, 80, 81, 81, 81, 81, 82, 82, 82, 82, 83,\n",
      "         83, 83, 83, 83, 84, 84, 84, 84, 84, 85, 85, 85, 85, 86, 86, 86, 86, 86,\n",
      "         87, 87, 88, 88, 88, 88, 88, 89, 89, 89, 90, 90, 90, 90, 90, 90, 91, 91,\n",
      "         91, 91],\n",
      "        [ 1,  2, 41,  0,  2,  3,  4,  5,  0,  1,  3, 19, 30, 33,  1,  2,  4,  5,\n",
      "         19, 30, 33,  1,  3,  5, 16, 19, 20,  1,  3,  4,  6,  5,  7,  8,  6,  8,\n",
      "         15,  6,  7,  9, 10,  8, 10, 11, 12, 13,  8,  9, 11, 14,  9, 10, 12, 13,\n",
      "         14,  9, 11, 13, 24, 27, 44,  9, 11, 12, 10, 11, 18, 22, 23, 24,  7, 16,\n",
      "         17, 18,  4, 15, 17, 18, 19, 20, 15, 16, 18, 20, 21, 22, 14, 15, 16, 17,\n",
      "         22, 23, 24,  2,  3,  4, 16, 20, 30, 33,  4, 16, 17, 19, 21, 22, 17, 20,\n",
      "         22, 28, 29, 30, 31, 32, 14, 17, 18, 20, 21, 23, 24, 14, 18, 22, 24, 25,\n",
      "         26, 27, 12, 14, 18, 22, 23, 27, 44, 23, 26, 27, 36, 37, 23, 25, 27, 28,\n",
      "         12, 23, 24, 25, 26, 44, 21, 26, 29, 30, 31, 32, 21, 28, 30, 31, 32, 35,\n",
      "         38,  2,  3, 19, 21, 28, 29, 31, 32, 33, 21, 28, 29, 30, 32, 35, 36, 21,\n",
      "         28, 29, 30, 31, 33, 34,  2,  3, 19, 30, 32, 34, 32, 33, 38, 39, 40, 29,\n",
      "         31, 36, 38, 25, 31, 35, 37, 25, 36, 42, 44, 45, 29, 34, 35, 39, 40, 34,\n",
      "         38, 40, 41, 34, 38, 39, 42, 43,  0, 39, 37, 40, 43, 44, 45, 40, 42, 45,\n",
      "         12, 24, 27, 37, 42, 45, 37, 42, 43, 44, 47, 48, 87, 46, 48, 49, 50, 51,\n",
      "         46, 47, 49, 65, 76, 79, 47, 48, 50, 51, 65, 76, 79, 47, 49, 51, 62, 65,\n",
      "         66, 47, 49, 50, 52, 51, 53, 54, 52, 54, 61, 52, 53, 55, 56, 54, 56, 57,\n",
      "         58, 59, 54, 55, 57, 60, 55, 56, 58, 59, 60, 55, 57, 59, 70, 73, 90, 55,\n",
      "         57, 58, 56, 57, 64, 68, 69, 70, 53, 62, 63, 64, 50, 61, 63, 64, 65, 66,\n",
      "         61, 62, 64, 66, 67, 68, 60, 61, 62, 63, 68, 69, 70, 48, 49, 50, 62, 66,\n",
      "         76, 79, 50, 62, 63, 65, 67, 68, 63, 66, 68, 74, 75, 76, 77, 78, 60, 63,\n",
      "         64, 66, 67, 69, 70, 60, 64, 68, 70, 71, 72, 73, 58, 60, 64, 68, 69, 73,\n",
      "         90, 69, 72, 73, 82, 83, 69, 71, 73, 74, 58, 69, 70, 71, 72, 90, 67, 72,\n",
      "         75, 76, 77, 78, 67, 74, 76, 77, 78, 81, 84, 48, 49, 65, 67, 74, 75, 77,\n",
      "         78, 79, 67, 74, 75, 76, 78, 81, 82, 67, 74, 75, 76, 77, 79, 80, 48, 49,\n",
      "         65, 76, 78, 80, 78, 79, 84, 85, 86, 75, 77, 82, 84, 71, 77, 81, 83, 71,\n",
      "         82, 88, 90, 91, 75, 80, 81, 85, 86, 80, 84, 86, 87, 80, 84, 85, 88, 89,\n",
      "         46, 85, 83, 86, 89, 90, 91, 86, 88, 91, 58, 70, 73, 83, 88, 91, 83, 88,\n",
      "         89, 90]])\n",
      "Indices tensor([[ 8,  7, 15, 16, 19],\n",
      "        [44, 24, 18, 16, 19]])\n",
      "x torch.Size([92, 4])\n",
      "tensor([[0.0000, 0.0721, 0.3291, 0.0000],\n",
      "        [0.0000, 0.0505, 0.0783, 0.0000],\n",
      "        [0.0000, 0.2023, 0.0434, 0.0000],\n",
      "        [0.0000, 0.1419, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2012, 0.0000, 0.0145],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1241, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2324, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2840, 0.0000, 0.0045],\n",
      "        [0.0000, 0.2317, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1208, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0686, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2231, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1627, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0376, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0895, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1096, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1615, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0712, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0994, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2316, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1345, 0.0756, 0.0000],\n",
      "        [0.0000, 0.0541, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1433, 0.0138, 0.0000],\n",
      "        [0.0000, 0.1570, 0.1535, 0.0000],\n",
      "        [0.0000, 0.0368, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2097, 0.2984, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0721, 0.3291, 0.0000],\n",
      "        [0.0000, 0.0505, 0.0783, 0.0000],\n",
      "        [0.0000, 0.2023, 0.0434, 0.0000],\n",
      "        [0.0000, 0.1419, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2012, 0.0000, 0.0145],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0438, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0004, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1890, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2356, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1178, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0933, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2231, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1627, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0376, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0451, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0163, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0243, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0895, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1096, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1615, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0712, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0994, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2316, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1345, 0.0756, 0.0000],\n",
      "        [0.0000, 0.0541, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0013, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1433, 0.0138, 0.0000],\n",
      "        [0.0000, 0.1570, 0.1535, 0.0000],\n",
      "        [0.0000, 0.0368, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2097, 0.2984, 0.0000],\n",
      "        [0.0000, 0.0140, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0106, 0.0000, 0.0000]], grad_fn=<MulBackward0>)\n",
      "Condition before torch.Size([92, 2])\n",
      "tensor([[-0.0957, -0.3014],\n",
      "        [-0.0843, -0.3045],\n",
      "        [-0.1551, -0.3586],\n",
      "        [-0.1267, -0.3395],\n",
      "        [-0.1552, -0.3591],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.1183, -0.3333],\n",
      "        [-0.1689, -0.3709],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.1933, -0.3884],\n",
      "        [-0.1686, -0.3706],\n",
      "        [-0.1168, -0.3322],\n",
      "        [-0.0924, -0.3141],\n",
      "        [-0.1646, -0.3676],\n",
      "        [-0.1364, -0.3467],\n",
      "        [-0.0779, -0.3033],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.1022, -0.3213],\n",
      "        [-0.1115, -0.3283],\n",
      "        [-0.1358, -0.3463],\n",
      "        [-0.0936, -0.3150],\n",
      "        [-0.1068, -0.3248],\n",
      "        [-0.1686, -0.3706],\n",
      "        [-0.1236, -0.3337],\n",
      "        [-0.0856, -0.3091],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.1274, -0.3394],\n",
      "        [-0.1345, -0.3382],\n",
      "        [-0.0775, -0.3030],\n",
      "        [-0.1598, -0.3504],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0957, -0.3014],\n",
      "        [-0.0843, -0.3045],\n",
      "        [-0.1551, -0.3586],\n",
      "        [-0.1267, -0.3395],\n",
      "        [-0.1552, -0.3591],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0402, -0.2892],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0601, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.1487, -0.3558],\n",
      "        [-0.1704, -0.3720],\n",
      "        [-0.1154, -0.3311],\n",
      "        [-0.1039, -0.3226],\n",
      "        [-0.1646, -0.3676],\n",
      "        [-0.1364, -0.3467],\n",
      "        [-0.0779, -0.3033],\n",
      "        [-0.0814, -0.3059],\n",
      "        [-0.0680, -0.2960],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0717, -0.2987],\n",
      "        [-0.1022, -0.3213],\n",
      "        [-0.1115, -0.3283],\n",
      "        [-0.1358, -0.3463],\n",
      "        [-0.0936, -0.3150],\n",
      "        [-0.1068, -0.3248],\n",
      "        [-0.1686, -0.3706],\n",
      "        [-0.1236, -0.3337],\n",
      "        [-0.0856, -0.3091],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0610, -0.2908],\n",
      "        [-0.1274, -0.3394],\n",
      "        [-0.1345, -0.3382],\n",
      "        [-0.0775, -0.3030],\n",
      "        [-0.1598, -0.3504],\n",
      "        [-0.0669, -0.2952],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0653, -0.2940]], grad_fn=<AddmmBackward0>)\n",
      "Encodings torch.Size([5, 2])\n",
      "tensor([[0.1198, 0.1403],\n",
      "        [0.1196, 0.1054],\n",
      "        [0.1080, 0.1321],\n",
      "        [0.1023, 0.1904],\n",
      "        [0.1013, 0.2107]], grad_fn=<SiluBackward0>)\n",
      "Condition after torch.Size([92, 4])\n",
      "tensor([[-0.0957, -0.3014,  0.0000,  0.0000],\n",
      "        [-0.0843, -0.3045,  0.0000,  0.0000],\n",
      "        [-0.1551, -0.3586,  0.0000,  0.0000],\n",
      "        [-0.1267, -0.3395,  0.0000,  0.0000],\n",
      "        [-0.1552, -0.3591,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.1183, -0.3333,  0.0000,  0.0000],\n",
      "        [-0.1689, -0.3709,  0.1196,  0.1054],\n",
      "        [-0.0603, -0.2903,  0.1198,  0.1403],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.1933, -0.3884,  0.1080,  0.1321],\n",
      "        [-0.1686, -0.3706,  0.1023,  0.1904],\n",
      "        [-0.1168, -0.3322,  0.0000,  0.0000],\n",
      "        [-0.0924, -0.3141,  0.0000,  0.0000],\n",
      "        [-0.1646, -0.3676,  0.1013,  0.2107],\n",
      "        [-0.1364, -0.3467,  0.0000,  0.0000],\n",
      "        [-0.0779, -0.3033,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.1022, -0.3213,  0.0000,  0.0000],\n",
      "        [-0.1115, -0.3283,  0.0000,  0.0000],\n",
      "        [-0.1358, -0.3463,  0.0000,  0.0000],\n",
      "        [-0.0936, -0.3150,  0.0000,  0.0000],\n",
      "        [-0.1068, -0.3248,  0.0000,  0.0000],\n",
      "        [-0.1686, -0.3706,  0.0000,  0.0000],\n",
      "        [-0.1236, -0.3337,  0.0000,  0.0000],\n",
      "        [-0.0856, -0.3091,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.1274, -0.3394,  0.0000,  0.0000],\n",
      "        [-0.1345, -0.3382,  0.0000,  0.0000],\n",
      "        [-0.0775, -0.3030,  0.0000,  0.0000],\n",
      "        [-0.1598, -0.3504,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0957, -0.3014,  0.0000,  0.0000],\n",
      "        [-0.0843, -0.3045,  0.0000,  0.0000],\n",
      "        [-0.1551, -0.3586,  0.0000,  0.0000],\n",
      "        [-0.1267, -0.3395,  0.0000,  0.0000],\n",
      "        [-0.1552, -0.3591,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0402, -0.2892,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0601, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.1487, -0.3558,  0.0000,  0.0000],\n",
      "        [-0.1704, -0.3720,  0.1023,  0.1904],\n",
      "        [-0.1154, -0.3311,  0.0000,  0.0000],\n",
      "        [-0.1039, -0.3226,  0.1080,  0.1321],\n",
      "        [-0.1646, -0.3676,  0.1013,  0.2107],\n",
      "        [-0.1364, -0.3467,  0.0000,  0.0000],\n",
      "        [-0.0779, -0.3033,  0.0000,  0.0000],\n",
      "        [-0.0814, -0.3059,  0.0000,  0.0000],\n",
      "        [-0.0680, -0.2960,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.1196,  0.1054],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0717, -0.2987,  0.0000,  0.0000],\n",
      "        [-0.1022, -0.3213,  0.0000,  0.0000],\n",
      "        [-0.1115, -0.3283,  0.0000,  0.0000],\n",
      "        [-0.1358, -0.3463,  0.0000,  0.0000],\n",
      "        [-0.0936, -0.3150,  0.0000,  0.0000],\n",
      "        [-0.1068, -0.3248,  0.0000,  0.0000],\n",
      "        [-0.1686, -0.3706,  0.0000,  0.0000],\n",
      "        [-0.1236, -0.3337,  0.0000,  0.0000],\n",
      "        [-0.0856, -0.3091,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0610, -0.2908,  0.0000,  0.0000],\n",
      "        [-0.1274, -0.3394,  0.0000,  0.0000],\n",
      "        [-0.1345, -0.3382,  0.0000,  0.0000],\n",
      "        [-0.0775, -0.3030,  0.0000,  0.0000],\n",
      "        [-0.1598, -0.3504,  0.0000,  0.0000],\n",
      "        [-0.0669, -0.2952,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.1198,  0.1403],\n",
      "        [-0.0653, -0.2940,  0.0000,  0.0000]], grad_fn=<CopySlices>)\n",
      "Edge Index torch.Size([2, 488])\n",
      "tensor([[ 0,  0,  0,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,\n",
      "          3,  3,  3,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  6,  6,  6,  7,  7,\n",
      "          7,  8,  8,  8,  8,  9,  9,  9,  9,  9, 10, 10, 10, 10, 11, 11, 11, 11,\n",
      "         11, 12, 12, 12, 12, 12, 12, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15, 15,\n",
      "         15, 15, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18,\n",
      "         18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 21, 21,\n",
      "         21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23,\n",
      "         23, 23, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 26, 26, 26, 26,\n",
      "         27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29,\n",
      "         29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 32,\n",
      "         32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 35,\n",
      "         35, 35, 35, 36, 36, 36, 36, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 39,\n",
      "         39, 39, 39, 40, 40, 40, 40, 40, 41, 41, 42, 42, 42, 42, 42, 43, 43, 43,\n",
      "         44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 46, 46, 46, 47, 47, 47, 47, 47,\n",
      "         48, 48, 48, 48, 48, 48, 49, 49, 49, 49, 49, 49, 49, 50, 50, 50, 50, 50,\n",
      "         50, 51, 51, 51, 51, 52, 52, 52, 53, 53, 53, 54, 54, 54, 54, 55, 55, 55,\n",
      "         55, 55, 56, 56, 56, 56, 57, 57, 57, 57, 57, 58, 58, 58, 58, 58, 58, 59,\n",
      "         59, 59, 60, 60, 60, 60, 60, 60, 61, 61, 61, 61, 62, 62, 62, 62, 62, 62,\n",
      "         63, 63, 63, 63, 63, 63, 64, 64, 64, 64, 64, 64, 64, 65, 65, 65, 65, 65,\n",
      "         65, 65, 66, 66, 66, 66, 66, 66, 67, 67, 67, 67, 67, 67, 67, 67, 68, 68,\n",
      "         68, 68, 68, 68, 68, 69, 69, 69, 69, 69, 69, 69, 70, 70, 70, 70, 70, 70,\n",
      "         70, 71, 71, 71, 71, 71, 72, 72, 72, 72, 73, 73, 73, 73, 73, 73, 74, 74,\n",
      "         74, 74, 74, 74, 75, 75, 75, 75, 75, 75, 75, 76, 76, 76, 76, 76, 76, 76,\n",
      "         76, 76, 77, 77, 77, 77, 77, 77, 77, 78, 78, 78, 78, 78, 78, 78, 79, 79,\n",
      "         79, 79, 79, 79, 80, 80, 80, 80, 80, 81, 81, 81, 81, 82, 82, 82, 82, 83,\n",
      "         83, 83, 83, 83, 84, 84, 84, 84, 84, 85, 85, 85, 85, 86, 86, 86, 86, 86,\n",
      "         87, 87, 88, 88, 88, 88, 88, 89, 89, 89, 90, 90, 90, 90, 90, 90, 91, 91,\n",
      "         91, 91],\n",
      "        [ 1,  2, 41,  0,  2,  3,  4,  5,  0,  1,  3, 19, 30, 33,  1,  2,  4,  5,\n",
      "         19, 30, 33,  1,  3,  5, 16, 19, 20,  1,  3,  4,  6,  5,  7,  8,  6,  8,\n",
      "         15,  6,  7,  9, 10,  8, 10, 11, 12, 13,  8,  9, 11, 14,  9, 10, 12, 13,\n",
      "         14,  9, 11, 13, 24, 27, 44,  9, 11, 12, 10, 11, 18, 22, 23, 24,  7, 16,\n",
      "         17, 18,  4, 15, 17, 18, 19, 20, 15, 16, 18, 20, 21, 22, 14, 15, 16, 17,\n",
      "         22, 23, 24,  2,  3,  4, 16, 20, 30, 33,  4, 16, 17, 19, 21, 22, 17, 20,\n",
      "         22, 28, 29, 30, 31, 32, 14, 17, 18, 20, 21, 23, 24, 14, 18, 22, 24, 25,\n",
      "         26, 27, 12, 14, 18, 22, 23, 27, 44, 23, 26, 27, 36, 37, 23, 25, 27, 28,\n",
      "         12, 23, 24, 25, 26, 44, 21, 26, 29, 30, 31, 32, 21, 28, 30, 31, 32, 35,\n",
      "         38,  2,  3, 19, 21, 28, 29, 31, 32, 33, 21, 28, 29, 30, 32, 35, 36, 21,\n",
      "         28, 29, 30, 31, 33, 34,  2,  3, 19, 30, 32, 34, 32, 33, 38, 39, 40, 29,\n",
      "         31, 36, 38, 25, 31, 35, 37, 25, 36, 42, 44, 45, 29, 34, 35, 39, 40, 34,\n",
      "         38, 40, 41, 34, 38, 39, 42, 43,  0, 39, 37, 40, 43, 44, 45, 40, 42, 45,\n",
      "         12, 24, 27, 37, 42, 45, 37, 42, 43, 44, 47, 48, 87, 46, 48, 49, 50, 51,\n",
      "         46, 47, 49, 65, 76, 79, 47, 48, 50, 51, 65, 76, 79, 47, 49, 51, 62, 65,\n",
      "         66, 47, 49, 50, 52, 51, 53, 54, 52, 54, 61, 52, 53, 55, 56, 54, 56, 57,\n",
      "         58, 59, 54, 55, 57, 60, 55, 56, 58, 59, 60, 55, 57, 59, 70, 73, 90, 55,\n",
      "         57, 58, 56, 57, 64, 68, 69, 70, 53, 62, 63, 64, 50, 61, 63, 64, 65, 66,\n",
      "         61, 62, 64, 66, 67, 68, 60, 61, 62, 63, 68, 69, 70, 48, 49, 50, 62, 66,\n",
      "         76, 79, 50, 62, 63, 65, 67, 68, 63, 66, 68, 74, 75, 76, 77, 78, 60, 63,\n",
      "         64, 66, 67, 69, 70, 60, 64, 68, 70, 71, 72, 73, 58, 60, 64, 68, 69, 73,\n",
      "         90, 69, 72, 73, 82, 83, 69, 71, 73, 74, 58, 69, 70, 71, 72, 90, 67, 72,\n",
      "         75, 76, 77, 78, 67, 74, 76, 77, 78, 81, 84, 48, 49, 65, 67, 74, 75, 77,\n",
      "         78, 79, 67, 74, 75, 76, 78, 81, 82, 67, 74, 75, 76, 77, 79, 80, 48, 49,\n",
      "         65, 76, 78, 80, 78, 79, 84, 85, 86, 75, 77, 82, 84, 71, 77, 81, 83, 71,\n",
      "         82, 88, 90, 91, 75, 80, 81, 85, 86, 80, 84, 86, 87, 80, 84, 85, 88, 89,\n",
      "         46, 85, 83, 86, 89, 90, 91, 86, 88, 91, 58, 70, 73, 83, 88, 91, 83, 88,\n",
      "         89, 90]])\n",
      "x torch.Size([92, 4])\n",
      "tensor([[0.0000, 0.0721, 0.3291, 0.0000],\n",
      "        [0.0000, 0.0505, 0.0783, 0.0000],\n",
      "        [0.0000, 0.2023, 0.0434, 0.0000],\n",
      "        [0.0000, 0.1419, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2012, 0.0000, 0.0145],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1241, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2324, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2840, 0.0000, 0.0045],\n",
      "        [0.0000, 0.2317, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1208, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0686, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2231, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1627, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0376, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0895, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1096, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1615, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0712, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0994, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2316, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1345, 0.0756, 0.0000],\n",
      "        [0.0000, 0.0541, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1433, 0.0138, 0.0000],\n",
      "        [0.0000, 0.1570, 0.1535, 0.0000],\n",
      "        [0.0000, 0.0368, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2097, 0.2984, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0721, 0.3291, 0.0000],\n",
      "        [0.0000, 0.0505, 0.0783, 0.0000],\n",
      "        [0.0000, 0.2023, 0.0434, 0.0000],\n",
      "        [0.0000, 0.1419, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2012, 0.0000, 0.0145],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0438, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0004, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1890, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2356, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1178, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0933, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2231, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1627, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0376, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0451, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0163, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0243, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0895, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1096, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1615, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0712, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0994, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2316, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1345, 0.0756, 0.0000],\n",
      "        [0.0000, 0.0541, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0013, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1433, 0.0138, 0.0000],\n",
      "        [0.0000, 0.1570, 0.1535, 0.0000],\n",
      "        [0.0000, 0.0368, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2097, 0.2984, 0.0000],\n",
      "        [0.0000, 0.0140, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0106, 0.0000, 0.0000]], grad_fn=<MulBackward0>)\n",
      "Edge Index torch.Size([2, 488])\n",
      "tensor([[ 0,  0,  0,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,\n",
      "          3,  3,  3,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  6,  6,  6,  7,  7,\n",
      "          7,  8,  8,  8,  8,  9,  9,  9,  9,  9, 10, 10, 10, 10, 11, 11, 11, 11,\n",
      "         11, 12, 12, 12, 12, 12, 12, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15, 15,\n",
      "         15, 15, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18,\n",
      "         18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 21, 21,\n",
      "         21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23,\n",
      "         23, 23, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 26, 26, 26, 26,\n",
      "         27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29,\n",
      "         29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 32,\n",
      "         32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 35,\n",
      "         35, 35, 35, 36, 36, 36, 36, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 39,\n",
      "         39, 39, 39, 40, 40, 40, 40, 40, 41, 41, 42, 42, 42, 42, 42, 43, 43, 43,\n",
      "         44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 46, 46, 46, 47, 47, 47, 47, 47,\n",
      "         48, 48, 48, 48, 48, 48, 49, 49, 49, 49, 49, 49, 49, 50, 50, 50, 50, 50,\n",
      "         50, 51, 51, 51, 51, 52, 52, 52, 53, 53, 53, 54, 54, 54, 54, 55, 55, 55,\n",
      "         55, 55, 56, 56, 56, 56, 57, 57, 57, 57, 57, 58, 58, 58, 58, 58, 58, 59,\n",
      "         59, 59, 60, 60, 60, 60, 60, 60, 61, 61, 61, 61, 62, 62, 62, 62, 62, 62,\n",
      "         63, 63, 63, 63, 63, 63, 64, 64, 64, 64, 64, 64, 64, 65, 65, 65, 65, 65,\n",
      "         65, 65, 66, 66, 66, 66, 66, 66, 67, 67, 67, 67, 67, 67, 67, 67, 68, 68,\n",
      "         68, 68, 68, 68, 68, 69, 69, 69, 69, 69, 69, 69, 70, 70, 70, 70, 70, 70,\n",
      "         70, 71, 71, 71, 71, 71, 72, 72, 72, 72, 73, 73, 73, 73, 73, 73, 74, 74,\n",
      "         74, 74, 74, 74, 75, 75, 75, 75, 75, 75, 75, 76, 76, 76, 76, 76, 76, 76,\n",
      "         76, 76, 77, 77, 77, 77, 77, 77, 77, 78, 78, 78, 78, 78, 78, 78, 79, 79,\n",
      "         79, 79, 79, 79, 80, 80, 80, 80, 80, 81, 81, 81, 81, 82, 82, 82, 82, 83,\n",
      "         83, 83, 83, 83, 84, 84, 84, 84, 84, 85, 85, 85, 85, 86, 86, 86, 86, 86,\n",
      "         87, 87, 88, 88, 88, 88, 88, 89, 89, 89, 90, 90, 90, 90, 90, 90, 91, 91,\n",
      "         91, 91],\n",
      "        [ 1,  2, 41,  0,  2,  3,  4,  5,  0,  1,  3, 19, 30, 33,  1,  2,  4,  5,\n",
      "         19, 30, 33,  1,  3,  5, 16, 19, 20,  1,  3,  4,  6,  5,  7,  8,  6,  8,\n",
      "         15,  6,  7,  9, 10,  8, 10, 11, 12, 13,  8,  9, 11, 14,  9, 10, 12, 13,\n",
      "         14,  9, 11, 13, 24, 27, 44,  9, 11, 12, 10, 11, 18, 22, 23, 24,  7, 16,\n",
      "         17, 18,  4, 15, 17, 18, 19, 20, 15, 16, 18, 20, 21, 22, 14, 15, 16, 17,\n",
      "         22, 23, 24,  2,  3,  4, 16, 20, 30, 33,  4, 16, 17, 19, 21, 22, 17, 20,\n",
      "         22, 28, 29, 30, 31, 32, 14, 17, 18, 20, 21, 23, 24, 14, 18, 22, 24, 25,\n",
      "         26, 27, 12, 14, 18, 22, 23, 27, 44, 23, 26, 27, 36, 37, 23, 25, 27, 28,\n",
      "         12, 23, 24, 25, 26, 44, 21, 26, 29, 30, 31, 32, 21, 28, 30, 31, 32, 35,\n",
      "         38,  2,  3, 19, 21, 28, 29, 31, 32, 33, 21, 28, 29, 30, 32, 35, 36, 21,\n",
      "         28, 29, 30, 31, 33, 34,  2,  3, 19, 30, 32, 34, 32, 33, 38, 39, 40, 29,\n",
      "         31, 36, 38, 25, 31, 35, 37, 25, 36, 42, 44, 45, 29, 34, 35, 39, 40, 34,\n",
      "         38, 40, 41, 34, 38, 39, 42, 43,  0, 39, 37, 40, 43, 44, 45, 40, 42, 45,\n",
      "         12, 24, 27, 37, 42, 45, 37, 42, 43, 44, 47, 48, 87, 46, 48, 49, 50, 51,\n",
      "         46, 47, 49, 65, 76, 79, 47, 48, 50, 51, 65, 76, 79, 47, 49, 51, 62, 65,\n",
      "         66, 47, 49, 50, 52, 51, 53, 54, 52, 54, 61, 52, 53, 55, 56, 54, 56, 57,\n",
      "         58, 59, 54, 55, 57, 60, 55, 56, 58, 59, 60, 55, 57, 59, 70, 73, 90, 55,\n",
      "         57, 58, 56, 57, 64, 68, 69, 70, 53, 62, 63, 64, 50, 61, 63, 64, 65, 66,\n",
      "         61, 62, 64, 66, 67, 68, 60, 61, 62, 63, 68, 69, 70, 48, 49, 50, 62, 66,\n",
      "         76, 79, 50, 62, 63, 65, 67, 68, 63, 66, 68, 74, 75, 76, 77, 78, 60, 63,\n",
      "         64, 66, 67, 69, 70, 60, 64, 68, 70, 71, 72, 73, 58, 60, 64, 68, 69, 73,\n",
      "         90, 69, 72, 73, 82, 83, 69, 71, 73, 74, 58, 69, 70, 71, 72, 90, 67, 72,\n",
      "         75, 76, 77, 78, 67, 74, 76, 77, 78, 81, 84, 48, 49, 65, 67, 74, 75, 77,\n",
      "         78, 79, 67, 74, 75, 76, 78, 81, 82, 67, 74, 75, 76, 77, 79, 80, 48, 49,\n",
      "         65, 76, 78, 80, 78, 79, 84, 85, 86, 75, 77, 82, 84, 71, 77, 81, 83, 71,\n",
      "         82, 88, 90, 91, 75, 80, 81, 85, 86, 80, 84, 86, 87, 80, 84, 85, 88, 89,\n",
      "         46, 85, 83, 86, 89, 90, 91, 86, 88, 91, 58, 70, 73, 83, 88, 91, 83, 88,\n",
      "         89, 90]])\n",
      "Indices tensor([[33, 32, 31, 36, 25],\n",
      "        [41, 39, 34, 32, 28]])\n",
      "x torch.Size([92, 4])\n",
      "tensor([[0.0000e+00, 7.2055e-02, 3.2913e-01, 0.0000e+00],\n",
      "        [0.0000e+00, 5.0489e-02, 7.8265e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 1.9906e-01, 4.4998e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 1.3908e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 4.5402e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.3846e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.0536e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.7520e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.5683e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.3555e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.5654e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 7.3934e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 7.8945e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.3982e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.4519e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.6931e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.6745e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.9554e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.9269e-01, 0.0000e+00, 5.1424e-03],\n",
      "        [0.0000e+00, 3.3398e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.8042e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 3.0282e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.1939e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.4327e-01, 1.3791e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 1.5702e-01, 1.5353e-01, 0.0000e+00],\n",
      "        [0.0000e+00, 3.6775e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.0970e-01, 2.9835e-01, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.1592e-01, 2.2413e-01, 0.0000e+00],\n",
      "        [0.0000e+00, 5.0489e-02, 7.8265e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 1.1781e-01, 1.0757e-01, 0.0000e+00],\n",
      "        [0.0000e+00, 6.9809e-02, 2.4540e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 4.5402e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.3846e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.0536e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.7520e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 9.2396e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.3555e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.5826e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 7.2865e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.3435e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.4726e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.1774e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.0744e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.9319e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 3.0950e-01, 0.0000e+00, 1.6729e-02],\n",
      "        [0.0000e+00, 3.9323e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 5.4145e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 3.2273e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 4.6620e-01, 0.0000e+00, 1.7102e-02],\n",
      "        [0.0000e+00, 2.1774e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 5.5995e-01, 3.2607e-02, 1.0858e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Condition before torch.Size([92, 2])\n",
      "tensor([[-0.0957, -0.3014],\n",
      "        [-0.0843, -0.3045],\n",
      "        [-0.1536, -0.3574],\n",
      "        [-0.1253, -0.3385],\n",
      "        [-0.0815, -0.3060],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0402, -0.2892],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0601, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0685, -0.2964],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.1336, -0.3447],\n",
      "        [-0.0667, -0.2950],\n",
      "        [-0.1335, -0.3446],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0949, -0.3159],\n",
      "        [-0.0972, -0.3177],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.1724, -0.3734],\n",
      "        [-0.1749, -0.3753],\n",
      "        [-0.1862, -0.3836],\n",
      "        [-0.1853, -0.3830],\n",
      "        [-0.1984, -0.3927],\n",
      "        [-0.1974, -0.3914],\n",
      "        [-0.2164, -0.4061],\n",
      "        [-0.1914, -0.3875],\n",
      "        [-0.2018, -0.3953],\n",
      "        [-0.1161, -0.3317],\n",
      "        [-0.1274, -0.3394],\n",
      "        [-0.1345, -0.3382],\n",
      "        [-0.0775, -0.3030],\n",
      "        [-0.1598, -0.3504],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.1624, -0.3557],\n",
      "        [-0.0843, -0.3045],\n",
      "        [-0.1159, -0.3266],\n",
      "        [-0.0931, -0.3135],\n",
      "        [-0.0815, -0.3060],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0402, -0.2892],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0601, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0685, -0.2964],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.1035, -0.3223],\n",
      "        [-0.0667, -0.2950],\n",
      "        [-0.1343, -0.3452],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0944, -0.3156],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.1698, -0.3715],\n",
      "        [-0.1759, -0.3760],\n",
      "        [-0.1621, -0.3658],\n",
      "        [-0.1573, -0.3622],\n",
      "        [-0.1973, -0.3919],\n",
      "        [-0.2059, -0.3965],\n",
      "        [-0.2441, -0.4266],\n",
      "        [-0.0856, -0.3091],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.2111, -0.4022],\n",
      "        [-0.2792, -0.4508],\n",
      "        [-0.1621, -0.3658],\n",
      "        [-0.3285, -0.4761],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903]], grad_fn=<AddmmBackward0>)\n",
      "Encodings torch.Size([5, 2])\n",
      "tensor([[0.1198, 0.1403],\n",
      "        [0.1196, 0.1054],\n",
      "        [0.1080, 0.1321],\n",
      "        [0.1023, 0.1904],\n",
      "        [0.1013, 0.2107]], grad_fn=<SiluBackward0>)\n",
      "Condition after torch.Size([92, 4])\n",
      "tensor([[-0.0957, -0.3014,  0.0000,  0.0000],\n",
      "        [-0.0843, -0.3045,  0.0000,  0.0000],\n",
      "        [-0.1536, -0.3574,  0.0000,  0.0000],\n",
      "        [-0.1253, -0.3385,  0.0000,  0.0000],\n",
      "        [-0.0815, -0.3060,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0402, -0.2892,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0601, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0685, -0.2964,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.1336, -0.3447,  0.0000,  0.0000],\n",
      "        [-0.0667, -0.2950,  0.0000,  0.0000],\n",
      "        [-0.1335, -0.3446,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0949, -0.3159,  0.1013,  0.2107],\n",
      "        [-0.0972, -0.3177,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.1724, -0.3734,  0.0000,  0.0000],\n",
      "        [-0.1749, -0.3753,  0.0000,  0.0000],\n",
      "        [-0.1862, -0.3836,  0.0000,  0.0000],\n",
      "        [-0.1853, -0.3830,  0.1080,  0.1321],\n",
      "        [-0.1984, -0.3927,  0.1196,  0.1054],\n",
      "        [-0.1974, -0.3914,  0.1198,  0.1403],\n",
      "        [-0.2164, -0.4061,  0.0000,  0.0000],\n",
      "        [-0.1914, -0.3875,  0.0000,  0.0000],\n",
      "        [-0.2018, -0.3953,  0.1023,  0.1904],\n",
      "        [-0.1161, -0.3317,  0.0000,  0.0000],\n",
      "        [-0.1274, -0.3394,  0.0000,  0.0000],\n",
      "        [-0.1345, -0.3382,  0.0000,  0.0000],\n",
      "        [-0.0775, -0.3030,  0.0000,  0.0000],\n",
      "        [-0.1598, -0.3504,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.1624, -0.3557,  0.0000,  0.0000],\n",
      "        [-0.0843, -0.3045,  0.0000,  0.0000],\n",
      "        [-0.1159, -0.3266,  0.0000,  0.0000],\n",
      "        [-0.0931, -0.3135,  0.0000,  0.0000],\n",
      "        [-0.0815, -0.3060,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0402, -0.2892,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0601, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0685, -0.2964,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.1035, -0.3223,  0.0000,  0.0000],\n",
      "        [-0.0667, -0.2950,  0.0000,  0.0000],\n",
      "        [-0.1343, -0.3452,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0944, -0.3156,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.1698, -0.3715,  0.1013,  0.2107],\n",
      "        [-0.1759, -0.3760,  0.0000,  0.0000],\n",
      "        [-0.1621, -0.3658,  0.0000,  0.0000],\n",
      "        [-0.1573, -0.3622,  0.0000,  0.0000],\n",
      "        [-0.1973, -0.3919,  0.1023,  0.1904],\n",
      "        [-0.2059, -0.3965,  0.0000,  0.0000],\n",
      "        [-0.2441, -0.4266,  0.1080,  0.1321],\n",
      "        [-0.0856, -0.3091,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.2111, -0.4022,  0.0000,  0.0000],\n",
      "        [-0.2792, -0.4508,  0.1196,  0.1054],\n",
      "        [-0.1621, -0.3658,  0.0000,  0.0000],\n",
      "        [-0.3285, -0.4761,  0.1198,  0.1403],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000]], grad_fn=<CopySlices>)\n",
      "Edge Index torch.Size([2, 488])\n",
      "tensor([[ 0,  0,  0,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,\n",
      "          3,  3,  3,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  6,  6,  6,  7,  7,\n",
      "          7,  8,  8,  8,  8,  9,  9,  9,  9,  9, 10, 10, 10, 10, 11, 11, 11, 11,\n",
      "         11, 12, 12, 12, 12, 12, 12, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15, 15,\n",
      "         15, 15, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18,\n",
      "         18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 21, 21,\n",
      "         21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23,\n",
      "         23, 23, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 26, 26, 26, 26,\n",
      "         27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29,\n",
      "         29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 32,\n",
      "         32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 35,\n",
      "         35, 35, 35, 36, 36, 36, 36, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 39,\n",
      "         39, 39, 39, 40, 40, 40, 40, 40, 41, 41, 42, 42, 42, 42, 42, 43, 43, 43,\n",
      "         44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 46, 46, 46, 47, 47, 47, 47, 47,\n",
      "         48, 48, 48, 48, 48, 48, 49, 49, 49, 49, 49, 49, 49, 50, 50, 50, 50, 50,\n",
      "         50, 51, 51, 51, 51, 52, 52, 52, 53, 53, 53, 54, 54, 54, 54, 55, 55, 55,\n",
      "         55, 55, 56, 56, 56, 56, 57, 57, 57, 57, 57, 58, 58, 58, 58, 58, 58, 59,\n",
      "         59, 59, 60, 60, 60, 60, 60, 60, 61, 61, 61, 61, 62, 62, 62, 62, 62, 62,\n",
      "         63, 63, 63, 63, 63, 63, 64, 64, 64, 64, 64, 64, 64, 65, 65, 65, 65, 65,\n",
      "         65, 65, 66, 66, 66, 66, 66, 66, 67, 67, 67, 67, 67, 67, 67, 67, 68, 68,\n",
      "         68, 68, 68, 68, 68, 69, 69, 69, 69, 69, 69, 69, 70, 70, 70, 70, 70, 70,\n",
      "         70, 71, 71, 71, 71, 71, 72, 72, 72, 72, 73, 73, 73, 73, 73, 73, 74, 74,\n",
      "         74, 74, 74, 74, 75, 75, 75, 75, 75, 75, 75, 76, 76, 76, 76, 76, 76, 76,\n",
      "         76, 76, 77, 77, 77, 77, 77, 77, 77, 78, 78, 78, 78, 78, 78, 78, 79, 79,\n",
      "         79, 79, 79, 79, 80, 80, 80, 80, 80, 81, 81, 81, 81, 82, 82, 82, 82, 83,\n",
      "         83, 83, 83, 83, 84, 84, 84, 84, 84, 85, 85, 85, 85, 86, 86, 86, 86, 86,\n",
      "         87, 87, 88, 88, 88, 88, 88, 89, 89, 89, 90, 90, 90, 90, 90, 90, 91, 91,\n",
      "         91, 91],\n",
      "        [ 1,  2, 41,  0,  2,  3,  4,  5,  0,  1,  3, 19, 30, 33,  1,  2,  4,  5,\n",
      "         19, 30, 33,  1,  3,  5, 16, 19, 20,  1,  3,  4,  6,  5,  7,  8,  6,  8,\n",
      "         15,  6,  7,  9, 10,  8, 10, 11, 12, 13,  8,  9, 11, 14,  9, 10, 12, 13,\n",
      "         14,  9, 11, 13, 24, 27, 44,  9, 11, 12, 10, 11, 18, 22, 23, 24,  7, 16,\n",
      "         17, 18,  4, 15, 17, 18, 19, 20, 15, 16, 18, 20, 21, 22, 14, 15, 16, 17,\n",
      "         22, 23, 24,  2,  3,  4, 16, 20, 30, 33,  4, 16, 17, 19, 21, 22, 17, 20,\n",
      "         22, 28, 29, 30, 31, 32, 14, 17, 18, 20, 21, 23, 24, 14, 18, 22, 24, 25,\n",
      "         26, 27, 12, 14, 18, 22, 23, 27, 44, 23, 26, 27, 36, 37, 23, 25, 27, 28,\n",
      "         12, 23, 24, 25, 26, 44, 21, 26, 29, 30, 31, 32, 21, 28, 30, 31, 32, 35,\n",
      "         38,  2,  3, 19, 21, 28, 29, 31, 32, 33, 21, 28, 29, 30, 32, 35, 36, 21,\n",
      "         28, 29, 30, 31, 33, 34,  2,  3, 19, 30, 32, 34, 32, 33, 38, 39, 40, 29,\n",
      "         31, 36, 38, 25, 31, 35, 37, 25, 36, 42, 44, 45, 29, 34, 35, 39, 40, 34,\n",
      "         38, 40, 41, 34, 38, 39, 42, 43,  0, 39, 37, 40, 43, 44, 45, 40, 42, 45,\n",
      "         12, 24, 27, 37, 42, 45, 37, 42, 43, 44, 47, 48, 87, 46, 48, 49, 50, 51,\n",
      "         46, 47, 49, 65, 76, 79, 47, 48, 50, 51, 65, 76, 79, 47, 49, 51, 62, 65,\n",
      "         66, 47, 49, 50, 52, 51, 53, 54, 52, 54, 61, 52, 53, 55, 56, 54, 56, 57,\n",
      "         58, 59, 54, 55, 57, 60, 55, 56, 58, 59, 60, 55, 57, 59, 70, 73, 90, 55,\n",
      "         57, 58, 56, 57, 64, 68, 69, 70, 53, 62, 63, 64, 50, 61, 63, 64, 65, 66,\n",
      "         61, 62, 64, 66, 67, 68, 60, 61, 62, 63, 68, 69, 70, 48, 49, 50, 62, 66,\n",
      "         76, 79, 50, 62, 63, 65, 67, 68, 63, 66, 68, 74, 75, 76, 77, 78, 60, 63,\n",
      "         64, 66, 67, 69, 70, 60, 64, 68, 70, 71, 72, 73, 58, 60, 64, 68, 69, 73,\n",
      "         90, 69, 72, 73, 82, 83, 69, 71, 73, 74, 58, 69, 70, 71, 72, 90, 67, 72,\n",
      "         75, 76, 77, 78, 67, 74, 76, 77, 78, 81, 84, 48, 49, 65, 67, 74, 75, 77,\n",
      "         78, 79, 67, 74, 75, 76, 78, 81, 82, 67, 74, 75, 76, 77, 79, 80, 48, 49,\n",
      "         65, 76, 78, 80, 78, 79, 84, 85, 86, 75, 77, 82, 84, 71, 77, 81, 83, 71,\n",
      "         82, 88, 90, 91, 75, 80, 81, 85, 86, 80, 84, 86, 87, 80, 84, 85, 88, 89,\n",
      "         46, 85, 83, 86, 89, 90, 91, 86, 88, 91, 58, 70, 73, 83, 88, 91, 83, 88,\n",
      "         89, 90]])\n",
      "x torch.Size([92, 4])\n",
      "tensor([[0.0000e+00, 7.2055e-02, 3.2913e-01, 0.0000e+00],\n",
      "        [0.0000e+00, 5.0489e-02, 7.8265e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 1.9906e-01, 4.4998e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 1.3908e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 4.5402e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.3846e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.0536e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.7520e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.5683e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.3555e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.5654e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 7.3934e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 7.8945e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.3982e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.4519e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.6931e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.6745e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.9554e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.9269e-01, 0.0000e+00, 5.1424e-03],\n",
      "        [0.0000e+00, 3.3398e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.8042e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 3.0282e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.1939e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.4327e-01, 1.3791e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 1.5702e-01, 1.5353e-01, 0.0000e+00],\n",
      "        [0.0000e+00, 3.6775e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.0970e-01, 2.9835e-01, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.1592e-01, 2.2413e-01, 0.0000e+00],\n",
      "        [0.0000e+00, 5.0489e-02, 7.8265e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 1.1781e-01, 1.0757e-01, 0.0000e+00],\n",
      "        [0.0000e+00, 6.9809e-02, 2.4540e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 4.5402e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.3846e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.0536e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.7520e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 9.2396e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.3555e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.5826e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 7.2865e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.3435e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.4726e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.1774e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.0744e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.9319e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 3.0950e-01, 0.0000e+00, 1.6729e-02],\n",
      "        [0.0000e+00, 3.9323e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 5.4145e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 3.2273e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 4.6620e-01, 0.0000e+00, 1.7102e-02],\n",
      "        [0.0000e+00, 2.1774e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 5.5995e-01, 3.2607e-02, 1.0858e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for data in train_data_loader:\n",
    "    batch_size = data['history_indices'].size(0)\n",
    "    history_edge_features = data.x\n",
    "    history_indices = data.history_indices\n",
    "    #print(\"x\", history_edge_features.size())\n",
    "    # future_edge_indices_one_hot = data.y[:, :, 0]\n",
    "    edge_index = data.edge_index\n",
    "    '''edge_index_in = edge_index.clone()\n",
    "    for i in range(batch_size):\n",
    "        edge_index_in = torch.cat((edge_index_in, edge_index + i * train_dataset.num_edges), dim=1)\n",
    "'''    \n",
    "    c = model.forward(x=history_edge_features, edge_index=edge_index, indices=history_indices, mode='history', batch=data)\n",
    "    out = model.forward(history_edge_features, edge_index, t=torch.tensor([34, 10]), condition=c, mode='future', batch=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0\n",
      "Edge Index torch.Size([2, 244])\n",
      "tensor([[ 0,  0,  0,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,\n",
      "          3,  3,  3,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  6,  6,  6,  7,  7,\n",
      "          7,  8,  8,  8,  8,  9,  9,  9,  9,  9, 10, 10, 10, 10, 11, 11, 11, 11,\n",
      "         11, 12, 12, 12, 12, 12, 12, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15, 15,\n",
      "         15, 15, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18,\n",
      "         18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 21, 21,\n",
      "         21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23,\n",
      "         23, 23, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 26, 26, 26, 26,\n",
      "         27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29,\n",
      "         29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 32,\n",
      "         32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 35,\n",
      "         35, 35, 35, 36, 36, 36, 36, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 39,\n",
      "         39, 39, 39, 40, 40, 40, 40, 40, 41, 41, 42, 42, 42, 42, 42, 43, 43, 43,\n",
      "         44, 44, 44, 44, 44, 44, 45, 45, 45, 45],\n",
      "        [ 1,  2, 41,  0,  2,  3,  4,  5,  0,  1,  3, 19, 30, 33,  1,  2,  4,  5,\n",
      "         19, 30, 33,  1,  3,  5, 16, 19, 20,  1,  3,  4,  6,  5,  7,  8,  6,  8,\n",
      "         15,  6,  7,  9, 10,  8, 10, 11, 12, 13,  8,  9, 11, 14,  9, 10, 12, 13,\n",
      "         14,  9, 11, 13, 24, 27, 44,  9, 11, 12, 10, 11, 18, 22, 23, 24,  7, 16,\n",
      "         17, 18,  4, 15, 17, 18, 19, 20, 15, 16, 18, 20, 21, 22, 14, 15, 16, 17,\n",
      "         22, 23, 24,  2,  3,  4, 16, 20, 30, 33,  4, 16, 17, 19, 21, 22, 17, 20,\n",
      "         22, 28, 29, 30, 31, 32, 14, 17, 18, 20, 21, 23, 24, 14, 18, 22, 24, 25,\n",
      "         26, 27, 12, 14, 18, 22, 23, 27, 44, 23, 26, 27, 36, 37, 23, 25, 27, 28,\n",
      "         12, 23, 24, 25, 26, 44, 21, 26, 29, 30, 31, 32, 21, 28, 30, 31, 32, 35,\n",
      "         38,  2,  3, 19, 21, 28, 29, 31, 32, 33, 21, 28, 29, 30, 32, 35, 36, 21,\n",
      "         28, 29, 30, 31, 33, 34,  2,  3, 19, 30, 32, 34, 32, 33, 38, 39, 40, 29,\n",
      "         31, 36, 38, 25, 31, 35, 37, 25, 36, 42, 44, 45, 29, 34, 35, 39, 40, 34,\n",
      "         38, 40, 41, 34, 38, 39, 42, 43,  0, 39, 37, 40, 43, 44, 45, 40, 42, 45,\n",
      "         12, 24, 27, 37, 42, 45, 37, 42, 43, 44]])\n",
      "Indices tensor([ 8,  7, 15, 16, 19])\n",
      "x torch.Size([46, 4])\n",
      "tensor([[0.0000, 0.0721, 0.3291, 0.0000],\n",
      "        [0.0000, 0.0505, 0.0783, 0.0000],\n",
      "        [0.0000, 0.2023, 0.0434, 0.0000],\n",
      "        [0.0000, 0.1419, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2012, 0.0000, 0.0145],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1241, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2324, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2840, 0.0000, 0.0045],\n",
      "        [0.0000, 0.2317, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1208, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0686, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2231, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1627, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0376, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0895, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1096, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1615, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0712, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0994, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2316, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1345, 0.0756, 0.0000],\n",
      "        [0.0000, 0.0541, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1433, 0.0138, 0.0000],\n",
      "        [0.0000, 0.1570, 0.1535, 0.0000],\n",
      "        [0.0000, 0.0368, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2097, 0.2984, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000]], grad_fn=<MulBackward0>)\n",
      "Condition before torch.Size([46, 2])\n",
      "tensor([[-0.0957, -0.3014],\n",
      "        [-0.0843, -0.3045],\n",
      "        [-0.1551, -0.3586],\n",
      "        [-0.1267, -0.3395],\n",
      "        [-0.1552, -0.3591],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.1183, -0.3333],\n",
      "        [-0.1689, -0.3709],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.1933, -0.3884],\n",
      "        [-0.1686, -0.3706],\n",
      "        [-0.1168, -0.3322],\n",
      "        [-0.0924, -0.3141],\n",
      "        [-0.1646, -0.3676],\n",
      "        [-0.1364, -0.3467],\n",
      "        [-0.0779, -0.3033],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.1022, -0.3213],\n",
      "        [-0.1115, -0.3283],\n",
      "        [-0.1358, -0.3463],\n",
      "        [-0.0936, -0.3150],\n",
      "        [-0.1068, -0.3248],\n",
      "        [-0.1686, -0.3706],\n",
      "        [-0.1236, -0.3337],\n",
      "        [-0.0856, -0.3091],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.1274, -0.3394],\n",
      "        [-0.1345, -0.3382],\n",
      "        [-0.0775, -0.3030],\n",
      "        [-0.1598, -0.3504],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903]], grad_fn=<AddmmBackward0>)\n",
      "Encodings torch.Size([5, 2])\n",
      "tensor([[0.1198, 0.1403],\n",
      "        [0.1196, 0.1054],\n",
      "        [0.1080, 0.1321],\n",
      "        [0.1023, 0.1904],\n",
      "        [0.1013, 0.2107]], grad_fn=<SiluBackward0>)\n",
      "Condition after torch.Size([46, 4])\n",
      "tensor([[-0.0957, -0.3014,  0.0000,  0.0000],\n",
      "        [-0.0843, -0.3045,  0.0000,  0.0000],\n",
      "        [-0.1551, -0.3586,  0.0000,  0.0000],\n",
      "        [-0.1267, -0.3395,  0.0000,  0.0000],\n",
      "        [-0.1552, -0.3591,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.1183, -0.3333,  0.0000,  0.0000],\n",
      "        [-0.1689, -0.3709,  0.1196,  0.1054],\n",
      "        [-0.0603, -0.2903,  0.1198,  0.1403],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.1933, -0.3884,  0.1080,  0.1321],\n",
      "        [-0.1686, -0.3706,  0.1023,  0.1904],\n",
      "        [-0.1168, -0.3322,  0.0000,  0.0000],\n",
      "        [-0.0924, -0.3141,  0.0000,  0.0000],\n",
      "        [-0.1646, -0.3676,  0.1013,  0.2107],\n",
      "        [-0.1364, -0.3467,  0.0000,  0.0000],\n",
      "        [-0.0779, -0.3033,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.1022, -0.3213,  0.0000,  0.0000],\n",
      "        [-0.1115, -0.3283,  0.0000,  0.0000],\n",
      "        [-0.1358, -0.3463,  0.0000,  0.0000],\n",
      "        [-0.0936, -0.3150,  0.0000,  0.0000],\n",
      "        [-0.1068, -0.3248,  0.0000,  0.0000],\n",
      "        [-0.1686, -0.3706,  0.0000,  0.0000],\n",
      "        [-0.1236, -0.3337,  0.0000,  0.0000],\n",
      "        [-0.0856, -0.3091,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.1274, -0.3394,  0.0000,  0.0000],\n",
      "        [-0.1345, -0.3382,  0.0000,  0.0000],\n",
      "        [-0.0775, -0.3030,  0.0000,  0.0000],\n",
      "        [-0.1598, -0.3504,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000]], grad_fn=<CopySlices>)\n",
      "Edge Index torch.Size([2, 244])\n",
      "tensor([[ 0,  0,  0,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,\n",
      "          3,  3,  3,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  6,  6,  6,  7,  7,\n",
      "          7,  8,  8,  8,  8,  9,  9,  9,  9,  9, 10, 10, 10, 10, 11, 11, 11, 11,\n",
      "         11, 12, 12, 12, 12, 12, 12, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15, 15,\n",
      "         15, 15, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18,\n",
      "         18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 21, 21,\n",
      "         21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23,\n",
      "         23, 23, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 26, 26, 26, 26,\n",
      "         27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29,\n",
      "         29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 32,\n",
      "         32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 35,\n",
      "         35, 35, 35, 36, 36, 36, 36, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 39,\n",
      "         39, 39, 39, 40, 40, 40, 40, 40, 41, 41, 42, 42, 42, 42, 42, 43, 43, 43,\n",
      "         44, 44, 44, 44, 44, 44, 45, 45, 45, 45],\n",
      "        [ 1,  2, 41,  0,  2,  3,  4,  5,  0,  1,  3, 19, 30, 33,  1,  2,  4,  5,\n",
      "         19, 30, 33,  1,  3,  5, 16, 19, 20,  1,  3,  4,  6,  5,  7,  8,  6,  8,\n",
      "         15,  6,  7,  9, 10,  8, 10, 11, 12, 13,  8,  9, 11, 14,  9, 10, 12, 13,\n",
      "         14,  9, 11, 13, 24, 27, 44,  9, 11, 12, 10, 11, 18, 22, 23, 24,  7, 16,\n",
      "         17, 18,  4, 15, 17, 18, 19, 20, 15, 16, 18, 20, 21, 22, 14, 15, 16, 17,\n",
      "         22, 23, 24,  2,  3,  4, 16, 20, 30, 33,  4, 16, 17, 19, 21, 22, 17, 20,\n",
      "         22, 28, 29, 30, 31, 32, 14, 17, 18, 20, 21, 23, 24, 14, 18, 22, 24, 25,\n",
      "         26, 27, 12, 14, 18, 22, 23, 27, 44, 23, 26, 27, 36, 37, 23, 25, 27, 28,\n",
      "         12, 23, 24, 25, 26, 44, 21, 26, 29, 30, 31, 32, 21, 28, 30, 31, 32, 35,\n",
      "         38,  2,  3, 19, 21, 28, 29, 31, 32, 33, 21, 28, 29, 30, 32, 35, 36, 21,\n",
      "         28, 29, 30, 31, 33, 34,  2,  3, 19, 30, 32, 34, 32, 33, 38, 39, 40, 29,\n",
      "         31, 36, 38, 25, 31, 35, 37, 25, 36, 42, 44, 45, 29, 34, 35, 39, 40, 34,\n",
      "         38, 40, 41, 34, 38, 39, 42, 43,  0, 39, 37, 40, 43, 44, 45, 40, 42, 45,\n",
      "         12, 24, 27, 37, 42, 45, 37, 42, 43, 44]])\n",
      "x torch.Size([46, 4])\n",
      "tensor([[0.0000, 0.0721, 0.3291, 0.0000],\n",
      "        [0.0000, 0.0505, 0.0783, 0.0000],\n",
      "        [0.0000, 0.2023, 0.0434, 0.0000],\n",
      "        [0.0000, 0.1419, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2012, 0.0000, 0.0145],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1241, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2324, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2840, 0.0000, 0.0045],\n",
      "        [0.0000, 0.2317, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1208, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0686, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2231, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1627, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0376, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0895, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1096, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1615, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0712, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0994, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2316, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1345, 0.0756, 0.0000],\n",
      "        [0.0000, 0.0541, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1433, 0.0138, 0.0000],\n",
      "        [0.0000, 0.1570, 0.1535, 0.0000],\n",
      "        [0.0000, 0.0368, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2097, 0.2984, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000]], grad_fn=<MulBackward0>)\n",
      "i: 1\n",
      "Edge Index torch.Size([2, 244])\n",
      "tensor([[ 0,  0,  0,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,\n",
      "          3,  3,  3,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  6,  6,  6,  7,  7,\n",
      "          7,  8,  8,  8,  8,  9,  9,  9,  9,  9, 10, 10, 10, 10, 11, 11, 11, 11,\n",
      "         11, 12, 12, 12, 12, 12, 12, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15, 15,\n",
      "         15, 15, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18,\n",
      "         18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 21, 21,\n",
      "         21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23,\n",
      "         23, 23, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 26, 26, 26, 26,\n",
      "         27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29,\n",
      "         29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 32,\n",
      "         32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 35,\n",
      "         35, 35, 35, 36, 36, 36, 36, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 39,\n",
      "         39, 39, 39, 40, 40, 40, 40, 40, 41, 41, 42, 42, 42, 42, 42, 43, 43, 43,\n",
      "         44, 44, 44, 44, 44, 44, 45, 45, 45, 45],\n",
      "        [ 1,  2, 41,  0,  2,  3,  4,  5,  0,  1,  3, 19, 30, 33,  1,  2,  4,  5,\n",
      "         19, 30, 33,  1,  3,  5, 16, 19, 20,  1,  3,  4,  6,  5,  7,  8,  6,  8,\n",
      "         15,  6,  7,  9, 10,  8, 10, 11, 12, 13,  8,  9, 11, 14,  9, 10, 12, 13,\n",
      "         14,  9, 11, 13, 24, 27, 44,  9, 11, 12, 10, 11, 18, 22, 23, 24,  7, 16,\n",
      "         17, 18,  4, 15, 17, 18, 19, 20, 15, 16, 18, 20, 21, 22, 14, 15, 16, 17,\n",
      "         22, 23, 24,  2,  3,  4, 16, 20, 30, 33,  4, 16, 17, 19, 21, 22, 17, 20,\n",
      "         22, 28, 29, 30, 31, 32, 14, 17, 18, 20, 21, 23, 24, 14, 18, 22, 24, 25,\n",
      "         26, 27, 12, 14, 18, 22, 23, 27, 44, 23, 26, 27, 36, 37, 23, 25, 27, 28,\n",
      "         12, 23, 24, 25, 26, 44, 21, 26, 29, 30, 31, 32, 21, 28, 30, 31, 32, 35,\n",
      "         38,  2,  3, 19, 21, 28, 29, 31, 32, 33, 21, 28, 29, 30, 32, 35, 36, 21,\n",
      "         28, 29, 30, 31, 33, 34,  2,  3, 19, 30, 32, 34, 32, 33, 38, 39, 40, 29,\n",
      "         31, 36, 38, 25, 31, 35, 37, 25, 36, 42, 44, 45, 29, 34, 35, 39, 40, 34,\n",
      "         38, 40, 41, 34, 38, 39, 42, 43,  0, 39, 37, 40, 43, 44, 45, 40, 42, 45,\n",
      "         12, 24, 27, 37, 42, 45, 37, 42, 43, 44]])\n",
      "Indices tensor([44, 24, 18, 16, 19])\n",
      "x torch.Size([46, 4])\n",
      "tensor([[0.0000, 0.0721, 0.3291, 0.0000],\n",
      "        [0.0000, 0.0505, 0.0783, 0.0000],\n",
      "        [0.0000, 0.2023, 0.0434, 0.0000],\n",
      "        [0.0000, 0.1419, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2012, 0.0000, 0.0145],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0438, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0004, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1890, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2356, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1178, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0933, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2231, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1627, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0376, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0451, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0163, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0243, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0895, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1096, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1615, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0712, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0994, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2316, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1345, 0.0756, 0.0000],\n",
      "        [0.0000, 0.0541, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0013, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1433, 0.0138, 0.0000],\n",
      "        [0.0000, 0.1570, 0.1535, 0.0000],\n",
      "        [0.0000, 0.0368, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2097, 0.2984, 0.0000],\n",
      "        [0.0000, 0.0140, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0106, 0.0000, 0.0000]], grad_fn=<MulBackward0>)\n",
      "Condition before torch.Size([46, 2])\n",
      "tensor([[-0.0957, -0.3014],\n",
      "        [-0.0843, -0.3045],\n",
      "        [-0.1551, -0.3586],\n",
      "        [-0.1267, -0.3395],\n",
      "        [-0.1552, -0.3591],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0402, -0.2892],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0601, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.1487, -0.3558],\n",
      "        [-0.1704, -0.3720],\n",
      "        [-0.1154, -0.3311],\n",
      "        [-0.1039, -0.3226],\n",
      "        [-0.1646, -0.3676],\n",
      "        [-0.1364, -0.3467],\n",
      "        [-0.0779, -0.3033],\n",
      "        [-0.0814, -0.3059],\n",
      "        [-0.0680, -0.2960],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0717, -0.2987],\n",
      "        [-0.1022, -0.3213],\n",
      "        [-0.1115, -0.3283],\n",
      "        [-0.1358, -0.3463],\n",
      "        [-0.0936, -0.3150],\n",
      "        [-0.1068, -0.3248],\n",
      "        [-0.1686, -0.3706],\n",
      "        [-0.1236, -0.3337],\n",
      "        [-0.0856, -0.3091],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0610, -0.2908],\n",
      "        [-0.1274, -0.3394],\n",
      "        [-0.1345, -0.3382],\n",
      "        [-0.0775, -0.3030],\n",
      "        [-0.1598, -0.3504],\n",
      "        [-0.0669, -0.2952],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0653, -0.2940]], grad_fn=<AddmmBackward0>)\n",
      "Encodings torch.Size([5, 2])\n",
      "tensor([[0.1198, 0.1403],\n",
      "        [0.1196, 0.1054],\n",
      "        [0.1080, 0.1321],\n",
      "        [0.1023, 0.1904],\n",
      "        [0.1013, 0.2107]], grad_fn=<SiluBackward0>)\n",
      "Condition after torch.Size([46, 4])\n",
      "tensor([[-0.0957, -0.3014,  0.0000,  0.0000],\n",
      "        [-0.0843, -0.3045,  0.0000,  0.0000],\n",
      "        [-0.1551, -0.3586,  0.0000,  0.0000],\n",
      "        [-0.1267, -0.3395,  0.0000,  0.0000],\n",
      "        [-0.1552, -0.3591,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0402, -0.2892,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0601, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.1487, -0.3558,  0.0000,  0.0000],\n",
      "        [-0.1704, -0.3720,  0.1023,  0.1904],\n",
      "        [-0.1154, -0.3311,  0.0000,  0.0000],\n",
      "        [-0.1039, -0.3226,  0.1080,  0.1321],\n",
      "        [-0.1646, -0.3676,  0.1013,  0.2107],\n",
      "        [-0.1364, -0.3467,  0.0000,  0.0000],\n",
      "        [-0.0779, -0.3033,  0.0000,  0.0000],\n",
      "        [-0.0814, -0.3059,  0.0000,  0.0000],\n",
      "        [-0.0680, -0.2960,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.1196,  0.1054],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0717, -0.2987,  0.0000,  0.0000],\n",
      "        [-0.1022, -0.3213,  0.0000,  0.0000],\n",
      "        [-0.1115, -0.3283,  0.0000,  0.0000],\n",
      "        [-0.1358, -0.3463,  0.0000,  0.0000],\n",
      "        [-0.0936, -0.3150,  0.0000,  0.0000],\n",
      "        [-0.1068, -0.3248,  0.0000,  0.0000],\n",
      "        [-0.1686, -0.3706,  0.0000,  0.0000],\n",
      "        [-0.1236, -0.3337,  0.0000,  0.0000],\n",
      "        [-0.0856, -0.3091,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0610, -0.2908,  0.0000,  0.0000],\n",
      "        [-0.1274, -0.3394,  0.0000,  0.0000],\n",
      "        [-0.1345, -0.3382,  0.0000,  0.0000],\n",
      "        [-0.0775, -0.3030,  0.0000,  0.0000],\n",
      "        [-0.1598, -0.3504,  0.0000,  0.0000],\n",
      "        [-0.0669, -0.2952,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.1198,  0.1403],\n",
      "        [-0.0653, -0.2940,  0.0000,  0.0000]], grad_fn=<CopySlices>)\n",
      "Edge Index torch.Size([2, 244])\n",
      "tensor([[ 0,  0,  0,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,\n",
      "          3,  3,  3,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  6,  6,  6,  7,  7,\n",
      "          7,  8,  8,  8,  8,  9,  9,  9,  9,  9, 10, 10, 10, 10, 11, 11, 11, 11,\n",
      "         11, 12, 12, 12, 12, 12, 12, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15, 15,\n",
      "         15, 15, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18,\n",
      "         18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 21, 21,\n",
      "         21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23,\n",
      "         23, 23, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 26, 26, 26, 26,\n",
      "         27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29,\n",
      "         29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 32,\n",
      "         32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 35,\n",
      "         35, 35, 35, 36, 36, 36, 36, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 39,\n",
      "         39, 39, 39, 40, 40, 40, 40, 40, 41, 41, 42, 42, 42, 42, 42, 43, 43, 43,\n",
      "         44, 44, 44, 44, 44, 44, 45, 45, 45, 45],\n",
      "        [ 1,  2, 41,  0,  2,  3,  4,  5,  0,  1,  3, 19, 30, 33,  1,  2,  4,  5,\n",
      "         19, 30, 33,  1,  3,  5, 16, 19, 20,  1,  3,  4,  6,  5,  7,  8,  6,  8,\n",
      "         15,  6,  7,  9, 10,  8, 10, 11, 12, 13,  8,  9, 11, 14,  9, 10, 12, 13,\n",
      "         14,  9, 11, 13, 24, 27, 44,  9, 11, 12, 10, 11, 18, 22, 23, 24,  7, 16,\n",
      "         17, 18,  4, 15, 17, 18, 19, 20, 15, 16, 18, 20, 21, 22, 14, 15, 16, 17,\n",
      "         22, 23, 24,  2,  3,  4, 16, 20, 30, 33,  4, 16, 17, 19, 21, 22, 17, 20,\n",
      "         22, 28, 29, 30, 31, 32, 14, 17, 18, 20, 21, 23, 24, 14, 18, 22, 24, 25,\n",
      "         26, 27, 12, 14, 18, 22, 23, 27, 44, 23, 26, 27, 36, 37, 23, 25, 27, 28,\n",
      "         12, 23, 24, 25, 26, 44, 21, 26, 29, 30, 31, 32, 21, 28, 30, 31, 32, 35,\n",
      "         38,  2,  3, 19, 21, 28, 29, 31, 32, 33, 21, 28, 29, 30, 32, 35, 36, 21,\n",
      "         28, 29, 30, 31, 33, 34,  2,  3, 19, 30, 32, 34, 32, 33, 38, 39, 40, 29,\n",
      "         31, 36, 38, 25, 31, 35, 37, 25, 36, 42, 44, 45, 29, 34, 35, 39, 40, 34,\n",
      "         38, 40, 41, 34, 38, 39, 42, 43,  0, 39, 37, 40, 43, 44, 45, 40, 42, 45,\n",
      "         12, 24, 27, 37, 42, 45, 37, 42, 43, 44]])\n",
      "x torch.Size([46, 4])\n",
      "tensor([[0.0000, 0.0721, 0.3291, 0.0000],\n",
      "        [0.0000, 0.0505, 0.0783, 0.0000],\n",
      "        [0.0000, 0.2023, 0.0434, 0.0000],\n",
      "        [0.0000, 0.1419, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2012, 0.0000, 0.0145],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0438, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0004, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1890, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2356, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1178, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0933, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2231, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1627, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0376, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0451, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0163, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0243, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0895, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1096, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1615, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0712, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0994, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2316, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1345, 0.0756, 0.0000],\n",
      "        [0.0000, 0.0541, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0013, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1433, 0.0138, 0.0000],\n",
      "        [0.0000, 0.1570, 0.1535, 0.0000],\n",
      "        [0.0000, 0.0368, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2097, 0.2984, 0.0000],\n",
      "        [0.0000, 0.0140, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0106, 0.0000, 0.0000]], grad_fn=<MulBackward0>)\n",
      "i: 0\n",
      "Edge Index torch.Size([2, 244])\n",
      "tensor([[ 0,  0,  0,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,\n",
      "          3,  3,  3,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  6,  6,  6,  7,  7,\n",
      "          7,  8,  8,  8,  8,  9,  9,  9,  9,  9, 10, 10, 10, 10, 11, 11, 11, 11,\n",
      "         11, 12, 12, 12, 12, 12, 12, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15, 15,\n",
      "         15, 15, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18,\n",
      "         18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 21, 21,\n",
      "         21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23,\n",
      "         23, 23, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 26, 26, 26, 26,\n",
      "         27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29,\n",
      "         29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 32,\n",
      "         32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 35,\n",
      "         35, 35, 35, 36, 36, 36, 36, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 39,\n",
      "         39, 39, 39, 40, 40, 40, 40, 40, 41, 41, 42, 42, 42, 42, 42, 43, 43, 43,\n",
      "         44, 44, 44, 44, 44, 44, 45, 45, 45, 45],\n",
      "        [ 1,  2, 41,  0,  2,  3,  4,  5,  0,  1,  3, 19, 30, 33,  1,  2,  4,  5,\n",
      "         19, 30, 33,  1,  3,  5, 16, 19, 20,  1,  3,  4,  6,  5,  7,  8,  6,  8,\n",
      "         15,  6,  7,  9, 10,  8, 10, 11, 12, 13,  8,  9, 11, 14,  9, 10, 12, 13,\n",
      "         14,  9, 11, 13, 24, 27, 44,  9, 11, 12, 10, 11, 18, 22, 23, 24,  7, 16,\n",
      "         17, 18,  4, 15, 17, 18, 19, 20, 15, 16, 18, 20, 21, 22, 14, 15, 16, 17,\n",
      "         22, 23, 24,  2,  3,  4, 16, 20, 30, 33,  4, 16, 17, 19, 21, 22, 17, 20,\n",
      "         22, 28, 29, 30, 31, 32, 14, 17, 18, 20, 21, 23, 24, 14, 18, 22, 24, 25,\n",
      "         26, 27, 12, 14, 18, 22, 23, 27, 44, 23, 26, 27, 36, 37, 23, 25, 27, 28,\n",
      "         12, 23, 24, 25, 26, 44, 21, 26, 29, 30, 31, 32, 21, 28, 30, 31, 32, 35,\n",
      "         38,  2,  3, 19, 21, 28, 29, 31, 32, 33, 21, 28, 29, 30, 32, 35, 36, 21,\n",
      "         28, 29, 30, 31, 33, 34,  2,  3, 19, 30, 32, 34, 32, 33, 38, 39, 40, 29,\n",
      "         31, 36, 38, 25, 31, 35, 37, 25, 36, 42, 44, 45, 29, 34, 35, 39, 40, 34,\n",
      "         38, 40, 41, 34, 38, 39, 42, 43,  0, 39, 37, 40, 43, 44, 45, 40, 42, 45,\n",
      "         12, 24, 27, 37, 42, 45, 37, 42, 43, 44]])\n",
      "Indices tensor([33, 32, 31, 36, 25])\n",
      "x torch.Size([46, 4])\n",
      "tensor([[0.0000, 0.0721, 0.3291, 0.0000],\n",
      "        [0.0000, 0.0505, 0.0783, 0.0000],\n",
      "        [0.0000, 0.1991, 0.0450, 0.0000],\n",
      "        [0.0000, 0.1391, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0454, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0438, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0004, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0175, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1568, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0136, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1565, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0739, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0789, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2398, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2452, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2693, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2675, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2955, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2927, 0.0000, 0.0051],\n",
      "        [0.0000, 0.3340, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2804, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3028, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1194, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1433, 0.0138, 0.0000],\n",
      "        [0.0000, 0.1570, 0.1535, 0.0000],\n",
      "        [0.0000, 0.0368, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2097, 0.2984, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000]], grad_fn=<MulBackward0>)\n",
      "Condition before torch.Size([46, 2])\n",
      "tensor([[-0.0957, -0.3014],\n",
      "        [-0.0843, -0.3045],\n",
      "        [-0.1536, -0.3574],\n",
      "        [-0.1253, -0.3385],\n",
      "        [-0.0815, -0.3060],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0402, -0.2892],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0601, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0685, -0.2964],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.1336, -0.3447],\n",
      "        [-0.0667, -0.2950],\n",
      "        [-0.1335, -0.3446],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0949, -0.3159],\n",
      "        [-0.0972, -0.3177],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.1724, -0.3734],\n",
      "        [-0.1749, -0.3753],\n",
      "        [-0.1862, -0.3836],\n",
      "        [-0.1853, -0.3830],\n",
      "        [-0.1984, -0.3927],\n",
      "        [-0.1974, -0.3914],\n",
      "        [-0.2164, -0.4061],\n",
      "        [-0.1914, -0.3875],\n",
      "        [-0.2018, -0.3953],\n",
      "        [-0.1161, -0.3317],\n",
      "        [-0.1274, -0.3394],\n",
      "        [-0.1345, -0.3382],\n",
      "        [-0.0775, -0.3030],\n",
      "        [-0.1598, -0.3504],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903]], grad_fn=<AddmmBackward0>)\n",
      "Encodings torch.Size([5, 2])\n",
      "tensor([[0.1198, 0.1403],\n",
      "        [0.1196, 0.1054],\n",
      "        [0.1080, 0.1321],\n",
      "        [0.1023, 0.1904],\n",
      "        [0.1013, 0.2107]], grad_fn=<SiluBackward0>)\n",
      "Condition after torch.Size([46, 4])\n",
      "tensor([[-0.0957, -0.3014,  0.0000,  0.0000],\n",
      "        [-0.0843, -0.3045,  0.0000,  0.0000],\n",
      "        [-0.1536, -0.3574,  0.0000,  0.0000],\n",
      "        [-0.1253, -0.3385,  0.0000,  0.0000],\n",
      "        [-0.0815, -0.3060,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0402, -0.2892,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0601, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0685, -0.2964,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.1336, -0.3447,  0.0000,  0.0000],\n",
      "        [-0.0667, -0.2950,  0.0000,  0.0000],\n",
      "        [-0.1335, -0.3446,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0949, -0.3159,  0.1013,  0.2107],\n",
      "        [-0.0972, -0.3177,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.1724, -0.3734,  0.0000,  0.0000],\n",
      "        [-0.1749, -0.3753,  0.0000,  0.0000],\n",
      "        [-0.1862, -0.3836,  0.0000,  0.0000],\n",
      "        [-0.1853, -0.3830,  0.1080,  0.1321],\n",
      "        [-0.1984, -0.3927,  0.1196,  0.1054],\n",
      "        [-0.1974, -0.3914,  0.1198,  0.1403],\n",
      "        [-0.2164, -0.4061,  0.0000,  0.0000],\n",
      "        [-0.1914, -0.3875,  0.0000,  0.0000],\n",
      "        [-0.2018, -0.3953,  0.1023,  0.1904],\n",
      "        [-0.1161, -0.3317,  0.0000,  0.0000],\n",
      "        [-0.1274, -0.3394,  0.0000,  0.0000],\n",
      "        [-0.1345, -0.3382,  0.0000,  0.0000],\n",
      "        [-0.0775, -0.3030,  0.0000,  0.0000],\n",
      "        [-0.1598, -0.3504,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000]], grad_fn=<CopySlices>)\n",
      "Edge Index torch.Size([2, 244])\n",
      "tensor([[ 0,  0,  0,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,\n",
      "          3,  3,  3,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  6,  6,  6,  7,  7,\n",
      "          7,  8,  8,  8,  8,  9,  9,  9,  9,  9, 10, 10, 10, 10, 11, 11, 11, 11,\n",
      "         11, 12, 12, 12, 12, 12, 12, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15, 15,\n",
      "         15, 15, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18,\n",
      "         18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 21, 21,\n",
      "         21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23,\n",
      "         23, 23, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 26, 26, 26, 26,\n",
      "         27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29,\n",
      "         29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 32,\n",
      "         32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 35,\n",
      "         35, 35, 35, 36, 36, 36, 36, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 39,\n",
      "         39, 39, 39, 40, 40, 40, 40, 40, 41, 41, 42, 42, 42, 42, 42, 43, 43, 43,\n",
      "         44, 44, 44, 44, 44, 44, 45, 45, 45, 45],\n",
      "        [ 1,  2, 41,  0,  2,  3,  4,  5,  0,  1,  3, 19, 30, 33,  1,  2,  4,  5,\n",
      "         19, 30, 33,  1,  3,  5, 16, 19, 20,  1,  3,  4,  6,  5,  7,  8,  6,  8,\n",
      "         15,  6,  7,  9, 10,  8, 10, 11, 12, 13,  8,  9, 11, 14,  9, 10, 12, 13,\n",
      "         14,  9, 11, 13, 24, 27, 44,  9, 11, 12, 10, 11, 18, 22, 23, 24,  7, 16,\n",
      "         17, 18,  4, 15, 17, 18, 19, 20, 15, 16, 18, 20, 21, 22, 14, 15, 16, 17,\n",
      "         22, 23, 24,  2,  3,  4, 16, 20, 30, 33,  4, 16, 17, 19, 21, 22, 17, 20,\n",
      "         22, 28, 29, 30, 31, 32, 14, 17, 18, 20, 21, 23, 24, 14, 18, 22, 24, 25,\n",
      "         26, 27, 12, 14, 18, 22, 23, 27, 44, 23, 26, 27, 36, 37, 23, 25, 27, 28,\n",
      "         12, 23, 24, 25, 26, 44, 21, 26, 29, 30, 31, 32, 21, 28, 30, 31, 32, 35,\n",
      "         38,  2,  3, 19, 21, 28, 29, 31, 32, 33, 21, 28, 29, 30, 32, 35, 36, 21,\n",
      "         28, 29, 30, 31, 33, 34,  2,  3, 19, 30, 32, 34, 32, 33, 38, 39, 40, 29,\n",
      "         31, 36, 38, 25, 31, 35, 37, 25, 36, 42, 44, 45, 29, 34, 35, 39, 40, 34,\n",
      "         38, 40, 41, 34, 38, 39, 42, 43,  0, 39, 37, 40, 43, 44, 45, 40, 42, 45,\n",
      "         12, 24, 27, 37, 42, 45, 37, 42, 43, 44]])\n",
      "x torch.Size([46, 4])\n",
      "tensor([[0.0000, 0.0721, 0.3291, 0.0000],\n",
      "        [0.0000, 0.0505, 0.0783, 0.0000],\n",
      "        [0.0000, 0.1991, 0.0450, 0.0000],\n",
      "        [0.0000, 0.1391, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0454, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0438, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0004, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0175, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1568, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0136, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1565, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0739, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0789, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2398, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2452, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2693, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2675, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2955, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2927, 0.0000, 0.0051],\n",
      "        [0.0000, 0.3340, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2804, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3028, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1194, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1433, 0.0138, 0.0000],\n",
      "        [0.0000, 0.1570, 0.1535, 0.0000],\n",
      "        [0.0000, 0.0368, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2097, 0.2984, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000]], grad_fn=<MulBackward0>)\n",
      "i: 1\n",
      "Edge Index torch.Size([2, 244])\n",
      "tensor([[ 0,  0,  0,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,\n",
      "          3,  3,  3,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  6,  6,  6,  7,  7,\n",
      "          7,  8,  8,  8,  8,  9,  9,  9,  9,  9, 10, 10, 10, 10, 11, 11, 11, 11,\n",
      "         11, 12, 12, 12, 12, 12, 12, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15, 15,\n",
      "         15, 15, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18,\n",
      "         18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 21, 21,\n",
      "         21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23,\n",
      "         23, 23, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 26, 26, 26, 26,\n",
      "         27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29,\n",
      "         29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 32,\n",
      "         32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 35,\n",
      "         35, 35, 35, 36, 36, 36, 36, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 39,\n",
      "         39, 39, 39, 40, 40, 40, 40, 40, 41, 41, 42, 42, 42, 42, 42, 43, 43, 43,\n",
      "         44, 44, 44, 44, 44, 44, 45, 45, 45, 45],\n",
      "        [ 1,  2, 41,  0,  2,  3,  4,  5,  0,  1,  3, 19, 30, 33,  1,  2,  4,  5,\n",
      "         19, 30, 33,  1,  3,  5, 16, 19, 20,  1,  3,  4,  6,  5,  7,  8,  6,  8,\n",
      "         15,  6,  7,  9, 10,  8, 10, 11, 12, 13,  8,  9, 11, 14,  9, 10, 12, 13,\n",
      "         14,  9, 11, 13, 24, 27, 44,  9, 11, 12, 10, 11, 18, 22, 23, 24,  7, 16,\n",
      "         17, 18,  4, 15, 17, 18, 19, 20, 15, 16, 18, 20, 21, 22, 14, 15, 16, 17,\n",
      "         22, 23, 24,  2,  3,  4, 16, 20, 30, 33,  4, 16, 17, 19, 21, 22, 17, 20,\n",
      "         22, 28, 29, 30, 31, 32, 14, 17, 18, 20, 21, 23, 24, 14, 18, 22, 24, 25,\n",
      "         26, 27, 12, 14, 18, 22, 23, 27, 44, 23, 26, 27, 36, 37, 23, 25, 27, 28,\n",
      "         12, 23, 24, 25, 26, 44, 21, 26, 29, 30, 31, 32, 21, 28, 30, 31, 32, 35,\n",
      "         38,  2,  3, 19, 21, 28, 29, 31, 32, 33, 21, 28, 29, 30, 32, 35, 36, 21,\n",
      "         28, 29, 30, 31, 33, 34,  2,  3, 19, 30, 32, 34, 32, 33, 38, 39, 40, 29,\n",
      "         31, 36, 38, 25, 31, 35, 37, 25, 36, 42, 44, 45, 29, 34, 35, 39, 40, 34,\n",
      "         38, 40, 41, 34, 38, 39, 42, 43,  0, 39, 37, 40, 43, 44, 45, 40, 42, 45,\n",
      "         12, 24, 27, 37, 42, 45, 37, 42, 43, 44]])\n",
      "Indices tensor([41, 39, 34, 32, 28])\n",
      "x torch.Size([46, 4])\n",
      "tensor([[0.0000e+00, 2.1592e-01, 2.2413e-01, 0.0000e+00],\n",
      "        [0.0000e+00, 5.0489e-02, 7.8265e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 1.1781e-01, 1.0757e-01, 0.0000e+00],\n",
      "        [0.0000e+00, 6.9809e-02, 2.4540e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 4.5402e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.3846e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.0536e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.7520e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 9.2396e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.3555e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.5826e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 7.2865e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.3435e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.4726e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.1774e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.0744e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.9319e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 3.0950e-01, 0.0000e+00, 1.6729e-02],\n",
      "        [0.0000e+00, 3.9323e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 5.4145e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 3.2273e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 4.6620e-01, 0.0000e+00, 1.7102e-02],\n",
      "        [0.0000e+00, 2.1774e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 5.5995e-01, 3.2607e-02, 1.0858e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Condition before torch.Size([46, 2])\n",
      "tensor([[-0.1624, -0.3557],\n",
      "        [-0.0843, -0.3045],\n",
      "        [-0.1159, -0.3266],\n",
      "        [-0.0931, -0.3135],\n",
      "        [-0.0815, -0.3060],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0402, -0.2892],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0601, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0685, -0.2964],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.1035, -0.3223],\n",
      "        [-0.0667, -0.2950],\n",
      "        [-0.1343, -0.3452],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0944, -0.3156],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.1698, -0.3715],\n",
      "        [-0.1759, -0.3760],\n",
      "        [-0.1621, -0.3658],\n",
      "        [-0.1573, -0.3622],\n",
      "        [-0.1973, -0.3919],\n",
      "        [-0.2059, -0.3965],\n",
      "        [-0.2441, -0.4266],\n",
      "        [-0.0856, -0.3091],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.2111, -0.4022],\n",
      "        [-0.2792, -0.4508],\n",
      "        [-0.1621, -0.3658],\n",
      "        [-0.3285, -0.4761],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903],\n",
      "        [-0.0603, -0.2903]], grad_fn=<AddmmBackward0>)\n",
      "Encodings torch.Size([5, 2])\n",
      "tensor([[0.1198, 0.1403],\n",
      "        [0.1196, 0.1054],\n",
      "        [0.1080, 0.1321],\n",
      "        [0.1023, 0.1904],\n",
      "        [0.1013, 0.2107]], grad_fn=<SiluBackward0>)\n",
      "Condition after torch.Size([46, 4])\n",
      "tensor([[-0.1624, -0.3557,  0.0000,  0.0000],\n",
      "        [-0.0843, -0.3045,  0.0000,  0.0000],\n",
      "        [-0.1159, -0.3266,  0.0000,  0.0000],\n",
      "        [-0.0931, -0.3135,  0.0000,  0.0000],\n",
      "        [-0.0815, -0.3060,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0402, -0.2892,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0601, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0685, -0.2964,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.1035, -0.3223,  0.0000,  0.0000],\n",
      "        [-0.0667, -0.2950,  0.0000,  0.0000],\n",
      "        [-0.1343, -0.3452,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0944, -0.3156,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.1698, -0.3715,  0.1013,  0.2107],\n",
      "        [-0.1759, -0.3760,  0.0000,  0.0000],\n",
      "        [-0.1621, -0.3658,  0.0000,  0.0000],\n",
      "        [-0.1573, -0.3622,  0.0000,  0.0000],\n",
      "        [-0.1973, -0.3919,  0.1023,  0.1904],\n",
      "        [-0.2059, -0.3965,  0.0000,  0.0000],\n",
      "        [-0.2441, -0.4266,  0.1080,  0.1321],\n",
      "        [-0.0856, -0.3091,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.2111, -0.4022,  0.0000,  0.0000],\n",
      "        [-0.2792, -0.4508,  0.1196,  0.1054],\n",
      "        [-0.1621, -0.3658,  0.0000,  0.0000],\n",
      "        [-0.3285, -0.4761,  0.1198,  0.1403],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000],\n",
      "        [-0.0603, -0.2903,  0.0000,  0.0000]], grad_fn=<CopySlices>)\n",
      "Edge Index torch.Size([2, 244])\n",
      "tensor([[ 0,  0,  0,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,\n",
      "          3,  3,  3,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  6,  6,  6,  7,  7,\n",
      "          7,  8,  8,  8,  8,  9,  9,  9,  9,  9, 10, 10, 10, 10, 11, 11, 11, 11,\n",
      "         11, 12, 12, 12, 12, 12, 12, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15, 15,\n",
      "         15, 15, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18,\n",
      "         18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 21, 21,\n",
      "         21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23,\n",
      "         23, 23, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 26, 26, 26, 26,\n",
      "         27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29,\n",
      "         29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 32,\n",
      "         32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 35,\n",
      "         35, 35, 35, 36, 36, 36, 36, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 39,\n",
      "         39, 39, 39, 40, 40, 40, 40, 40, 41, 41, 42, 42, 42, 42, 42, 43, 43, 43,\n",
      "         44, 44, 44, 44, 44, 44, 45, 45, 45, 45],\n",
      "        [ 1,  2, 41,  0,  2,  3,  4,  5,  0,  1,  3, 19, 30, 33,  1,  2,  4,  5,\n",
      "         19, 30, 33,  1,  3,  5, 16, 19, 20,  1,  3,  4,  6,  5,  7,  8,  6,  8,\n",
      "         15,  6,  7,  9, 10,  8, 10, 11, 12, 13,  8,  9, 11, 14,  9, 10, 12, 13,\n",
      "         14,  9, 11, 13, 24, 27, 44,  9, 11, 12, 10, 11, 18, 22, 23, 24,  7, 16,\n",
      "         17, 18,  4, 15, 17, 18, 19, 20, 15, 16, 18, 20, 21, 22, 14, 15, 16, 17,\n",
      "         22, 23, 24,  2,  3,  4, 16, 20, 30, 33,  4, 16, 17, 19, 21, 22, 17, 20,\n",
      "         22, 28, 29, 30, 31, 32, 14, 17, 18, 20, 21, 23, 24, 14, 18, 22, 24, 25,\n",
      "         26, 27, 12, 14, 18, 22, 23, 27, 44, 23, 26, 27, 36, 37, 23, 25, 27, 28,\n",
      "         12, 23, 24, 25, 26, 44, 21, 26, 29, 30, 31, 32, 21, 28, 30, 31, 32, 35,\n",
      "         38,  2,  3, 19, 21, 28, 29, 31, 32, 33, 21, 28, 29, 30, 32, 35, 36, 21,\n",
      "         28, 29, 30, 31, 33, 34,  2,  3, 19, 30, 32, 34, 32, 33, 38, 39, 40, 29,\n",
      "         31, 36, 38, 25, 31, 35, 37, 25, 36, 42, 44, 45, 29, 34, 35, 39, 40, 34,\n",
      "         38, 40, 41, 34, 38, 39, 42, 43,  0, 39, 37, 40, 43, 44, 45, 40, 42, 45,\n",
      "         12, 24, 27, 37, 42, 45, 37, 42, 43, 44]])\n",
      "x torch.Size([46, 4])\n",
      "tensor([[0.0000e+00, 2.1592e-01, 2.2413e-01, 0.0000e+00],\n",
      "        [0.0000e+00, 5.0489e-02, 7.8265e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 1.1781e-01, 1.0757e-01, 0.0000e+00],\n",
      "        [0.0000e+00, 6.9809e-02, 2.4540e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 4.5402e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.3846e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.0536e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.7520e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 9.2396e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.3555e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.5826e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 7.2865e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.3435e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.4726e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.1774e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.0744e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.9319e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 3.0950e-01, 0.0000e+00, 1.6729e-02],\n",
      "        [0.0000e+00, 3.9323e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 5.4145e-02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 3.2273e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 4.6620e-01, 0.0000e+00, 1.7102e-02],\n",
      "        [0.0000e+00, 2.1774e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 5.5995e-01, 3.2607e-02, 1.0858e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for data in old_train_data_loader:\n",
    "    history_edge_features = data[\"history_edge_features\"]\n",
    "    #print(\"x\", history_edge_features.size())\n",
    "    history_indices = data[\"history_indices\"]\n",
    "    future_edge_indices_one_hot = data[\"future_edge_features\"][:, :, 0]\n",
    "    t = torch.tensor([34, 10])\n",
    "    for i in range(min(2, history_edge_features.size(0))):\n",
    "        print(\"i:\", i)\n",
    "        #print(history_indices[i].unsqueeze(0))\n",
    "        #print(history_edge_features[i].unsqueeze(0))\n",
    "        \n",
    "        c = model.forward(x=history_edge_features[i].unsqueeze(0), edge_index=train_dataset.edge_index, indices=history_indices[i], mode='history')\n",
    "        out = model.forward(history_edge_features[i].unsqueeze(0), train_dataset.edge_index, t=t[i].unsqueeze(0), condition=c, mode='future')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "\n",
    "# Define a simple dataset with two graphs\n",
    "data_list = [\n",
    "    Data(x=torch.randn(3, 3), edge_index=torch.tensor([[0, 1, 2], [1, 2, 0]], dtype=torch.long)),\n",
    "    Data(x=torch.randn(2, 3), edge_index=torch.tensor([[0, 1], [1, 0]], dtype=torch.long))\n",
    "]\n",
    "\n",
    "# Create a DataLoader with batch size of 2\n",
    "loader = DataLoader(data_list, batch_size=2, shuffle=False)\n",
    "\n",
    "# Define a simple GATv2Conv model\n",
    "class SimpleGAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(SimpleGAT, self).__init__()\n",
    "        self.conv = GATv2Conv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        print(\"Edge index\", edge_index.size())\n",
    "        print(edge_index)\n",
    "        x = self.conv(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = SimpleGAT(in_channels=3, out_channels=2)\n",
    "\n",
    "# Inspect the batched data\n",
    "for batch in loader:\n",
    "    #print(\"Batched x shape:\", batch.x.shape)\n",
    "    #print(\"Batched edge_index shape:\", batch.edge_index.shape)\n",
    "    #print(\"Batch tensor shape:\", batch.batch.shape)\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(batch.x, batch.edge_index, batch.batch)\n",
    "    #print(\"Model output shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_G = nx.line_graph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(map(sorted, line_G.edges())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "samples = torch.load('/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/experiments/tdrive_residual/samples_tdrive_residual_hist5_fut5_custom_linear_hidden_dim_64_time_dim_16_condition_dim_32.pth')\n",
    "ground_truth_fut = torch.load('/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/experiments/tdrive_residual/ground_truth_fut_tdriveresidual_hist5_fut5_custom_linear_hidden_dim_64_time_dim_16_condition_dim_32.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([ 1142,  3252,  3253,  3556,  3557,  5259,  5261,  6751, 10065, 13200]), tensor([ 3073, 11357, 12375, 12376, 13148, 13149, 13198, 15607, 15914]), tensor([  198,   200,  3376,  4517,  4674,  5460,  5462,  6734,  6735,  6742,\n",
      "         6779,  6781,  6831,  8671,  8672,  8674, 12172, 14968, 16141, 16452]), tensor([ 2395,  2396,  3874,  3876,  5101,  5169,  5213,  5244,  5529,  7008,\n",
      "         7628,  7629, 16619]), tensor([  320,   895,   898,  2761,  3118,  3119,  4961,  5092,  5095,  5549,\n",
      "         6515,  6684,  6686,  6800,  7361,  7485, 11095, 11369, 13265, 15982,\n",
      "        15983, 16150]), tensor([ 1147,  3423,  3424,  5873,  5875,  6562,  6564,  7846,  7944,  7947,\n",
      "        11910, 11911]), tensor([  577,  1228,  1230,  4272,  4273,  5307,  8220,  8998,  8999, 11148,\n",
      "        11867, 13058, 13802, 14842]), tensor([ 1397,  1398,  1399,  1400,  4249,  4250,  7566,  7624,  8056,  9531,\n",
      "         9533,  9618,  9619,  9627, 10868, 11220, 12693, 12940, 14575, 16364,\n",
      "        16601, 16710]), tensor([ 2248,  5207,  6017,  6042,  6043,  6727, 11835, 12829, 13398, 13583,\n",
      "        14082, 16643]), tensor([ 1998,  3453,  4586,  6041,  6049,  6642,  6643,  6725,  7880,  7882,\n",
      "         8994,  8995,  9592, 10998, 10999, 11620, 11665, 12072, 13070, 13141,\n",
      "        15132, 16657]), tensor([   60,    61,  3053,  3054,  3055,  3056,  3088,  3116,  5699,  6441,\n",
      "         7590,  7647,  7837,  7838,  8241,  9005,  9736, 10383, 10384, 11275,\n",
      "        11359, 11765, 11772, 14369, 16303, 16305, 16403]), tensor([   58,    59,  1422,  4130,  4298,  4301,  5289,  8082,  8084,  8724,\n",
      "         8792,  8794,  9617,  9618,  9627, 10701, 12229, 12231, 14017, 15111,\n",
      "        16496]), tensor([  350,   354,  6928,  8940,  8986,  9476,  9487,  9488, 11059, 11060,\n",
      "        13908, 15861, 16016]), tensor([  181,   258,   359,   362,   374,  1641,  1648,  2173,  2194,  2195,\n",
      "         2216,  2217,  5104,  5107,  5212,  5214,  5245,  5503,  6596,  7865,\n",
      "         7866,  8902,  9657,  9659, 11912, 12826, 12882, 13066, 13701, 13723,\n",
      "        14253, 15120, 15121, 16462, 16465]), tensor([ 2078,  2079,  6501,  6504,  6848,  7001,  7563,  7566,  9056,  9720,\n",
      "         9721, 10175, 14729, 15881]), tensor([ 3047,  3053,  3242,  5056,  6042,  6070,  6072,  7590,  9131,  9282,\n",
      "         9283, 11595, 12575, 12580, 13059, 13062, 14301, 14897, 14898, 15184,\n",
      "        15185, 16012, 16618]), tensor([  145,   729,   731,   734,  1846,  1847,  6487,  6634,  6635,  6710,\n",
      "         9331, 11323, 11324, 11349, 11417, 11425, 11998, 12000, 12004, 12009,\n",
      "        13741, 13743, 15279, 15280]), tensor([   59,   323,  1501,  1843,  3049,  4468,  5027,  5028,  5035,  5059,\n",
      "         6740,  8420, 11376, 11377, 11766, 14765, 16496]), tensor([ 7226,  9142,  9143, 10823, 12436, 12438, 13244, 13770, 14525, 14527,\n",
      "        14531, 15184, 15276, 15278]), tensor([ 1359,  1360,  1362,  2796,  2799,  4214,  4216,  5032,  6654,  6873,\n",
      "         6874, 10056, 10485, 11018, 11019, 11020, 11021, 11022, 12486, 14127,\n",
      "        14128, 16428, 16433]), tensor([  179,   181,   802,   803,   804,  1213,  1216,  2091,  2172,  2453,\n",
      "         2455,  3141,  3143,  4275,  7614, 10823, 11387, 11423, 11424, 14727,\n",
      "        14728]), tensor([  356,  3372,  5648,  5886,  8245,  8246, 11521, 14865]), tensor([ 1856,  3109,  4510,  4533,  4534,  5718,  5719,  8992,  8994,  8995,\n",
      "         9076,  9143,  9669,  9738, 10145, 11423, 11424, 12988, 13422, 13423,\n",
      "        13424, 13425, 13426, 13658, 15989]), tensor([ 8799,  8800,  8974,  8976, 10133, 10134, 10135, 10732, 10967, 11901,\n",
      "        13797, 14951, 15605, 15737]), tensor([ 5173,  6143,  6144,  6145,  6485,  6490,  6639,  6640,  6641,  6655,\n",
      "         8082,  8084,  9893, 11350, 11369, 11410, 11853, 11871, 11872, 12002,\n",
      "        12096, 13744, 14723, 15212, 15871, 15872, 16178, 16522, 16597]), tensor([  317,  3423,  3795,  7719, 12938, 13017, 13600, 14124, 14654, 14655,\n",
      "        15523, 15788]), tensor([ 1397,  1398,  1400,  1408,  1410,  5814,  5815,  8604,  9684, 11156,\n",
      "        11296, 11298, 12748, 13061, 13764, 14452, 14575, 14576]), tensor([  351,  1258,  1259,  1275,  4053,  4624,  5706,  8086, 10642, 10647,\n",
      "        11359, 11744, 11745, 11746, 11765, 11772, 12564, 12565, 14540]), tensor([  954,   959,  2502,  5213,  5243,  7007,  7340,  7341,  8668,  9207,\n",
      "        12359]), tensor([ 3061,  3282,  3284,  3411,  3721,  5131,  5460,  5462,  6212,  9666,\n",
      "        11761, 12098, 12713, 12714, 13535, 15480, 16141, 16759]), tensor([ 4424,  4426,  4636,  5125,  5212,  5215,  8996, 11208, 11211, 12938,\n",
      "        13017, 13160, 15041, 15664, 15870, 15872, 16428, 16429]), tensor([ 2155,  2156,  2999,  3126,  5254,  6142,  7126,  7127,  7128,  9625,\n",
      "        11417, 11425, 12095]), tensor([  317,  1450,  1918,  1919,  2246,  5851,  5965,  6225,  7315,  7992,\n",
      "        12295, 12350]), tensor([ 4324,  4451,  4452,  6478,  6875,  8317, 13202, 13295, 13550, 15681]), tensor([  300,   301,   305,  1375,  3358,  3360,  5372,  5374,  5481,  6615,\n",
      "         6617,  9453,  9625, 11323, 11395]), tensor([ 1599,  2342,  3378,  4229,  4267,  4281,  6635,  6637,  6839,  8238,\n",
      "         8240,  9084, 10500, 11948, 12562, 12564, 12846, 13512, 13523, 15273,\n",
      "        15625, 15630, 16531, 16562, 16698]), tensor([ 4192,  4194,  5085,  6159,  6477,  6478,  8225,  8229,  8241, 12100,\n",
      "        12102, 12103, 12515, 13019, 13020, 13297, 14214, 14215]), tensor([ 1051,  4353,  4589,  5223,  6587,  6849,  6850,  6851,  6852,  7361,\n",
      "         8609,  8610,  9350,  9606, 11095, 11899, 12100, 12615, 12616, 12775,\n",
      "        13067, 13295, 13649, 14506, 16479, 16480, 16729]), tensor([ 4251,  4253,  6522,  6523,  7188,  7190,  8634, 11911]), tensor([  416,   418,  1333,  2034,  2151,  2153,  4190,  4265,  4266,  4633,\n",
      "         4634,  5131,  5134,  6105,  6577,  6584,  6586,  8676,  8677, 11120,\n",
      "        12361, 13085]), tensor([  426,   428,  1204,  1205,  1424,  3447,  5198,  5361,  5362,  5363,\n",
      "         5364,  5985,  6059,  6061,  6410,  6412,  9289, 10695, 13305, 16469]), tensor([   14,   148,  1434,  1435,  2200,  3214,  3216,  4504,  5334,  5845,\n",
      "         5846,  6643,  6683,  7590,  8034,  8729,  8733,  8786, 10102, 10601,\n",
      "        11048, 13144, 13797]), tensor([ 4459,  4818,  4823,  5409,  5410,  6390,  7886,  9362,  9363,  9654,\n",
      "        11114, 11412, 11413, 12006, 12940, 15308, 16005]), tensor([ 3344,  4189,  4191,  5076,  5131,  5150,  5458,  7593,  7611,  7944,\n",
      "         7946,  7947,  9711, 10418, 13023, 13535, 14730, 15714, 16719]), tensor([3467, 3468, 4058, 4059, 8231, 8232, 8239]), tensor([  728,   729,  1810,  3099,  3101,  3231,  3725, 10009, 11170, 11174,\n",
      "        11556, 12053, 12058, 12062, 12809, 12811, 13476, 13638, 13639, 14242,\n",
      "        14576, 15281, 16027, 16244]), tensor([ 2797,  5707,  5709,  5747,  7929, 10217, 11433, 12781, 12782, 13024,\n",
      "        13026, 13597, 13598, 14791]), tensor([ 1224,  1227,  1448,  1452,  2830,  3477,  6360,  6361,  6604,  8248,\n",
      "         9718, 14575, 14576]), tensor([  359,  1748,  2025,  2027,  2698,  2957,  2958,  3350,  3365,  7142,\n",
      "         8709,  8966,  9668, 11021, 11022, 11911, 13196, 14955]), tensor([ 3118,  3119,  5019,  5129,  5132,  5549,  5803,  5804,  5805,  6962,\n",
      "         7873, 10493, 11331, 11674, 12619, 13356]), tensor([ 1282,  1283,  2352,  2793,  2795,  3458,  4510,  4881,  6078,  6485,\n",
      "         9606, 11401, 11750, 11770, 11812, 11814, 11900, 12093, 13104, 13665,\n",
      "        13670, 14982, 15373]), tensor([  368,  1806,  2248,  2250,  3405,  4959,  6837,  8060,  8280,  8282,\n",
      "         8864,  9015, 10545, 11761, 12089, 12090, 13122, 13354, 13394, 13398,\n",
      "        13535, 14217, 15480]), tensor([   62,   325,  6499,  6584,  6585, 13204, 13658, 13660, 14869]), tensor([ 2483,  2484,  2488,  2522,  8282,  8283, 11310, 11764, 11765, 13953,\n",
      "        13954]), tensor([    6,     8,    10,  3899,  4537,  7961,  8280,  8827,  8829,  8884,\n",
      "        10819, 11226, 11228, 11309, 13305, 13306, 14005, 14006, 14217]), tensor([ 5746,  5747,  6046,  6047,  6627,  6629,  7000,  7119,  7909,  8288,\n",
      "         9009, 10656, 11437, 11869, 15998]), tensor([ 2960,  5253,  5257,  6044,  6502,  6581,  6582,  7340,  7341,  8987,\n",
      "        11060, 11148, 11326, 12103, 14587, 14727]), tensor([    9,    10,   416,   419,  4191,  4211,  5038,  5040,  5041,  5207,\n",
      "         5208,  5210,  5254,  5302,  5303,  5429,  5841,  5843,  6629,  7003,\n",
      "         7004,  7302,  8052,  8391,  9525, 10656, 11665, 11673, 11758, 13582,\n",
      "        13583, 14795, 15326, 15659, 16419]), tensor([  261,  4189,  4190,  4355,  5236,  8495,  8496,  8674, 10491, 10519,\n",
      "        12993]), tensor([  261,  7691,  7693,  8233,  8234,  8249,  8250,  9208, 11092, 11120,\n",
      "        12516, 12517]), tensor([  123,   124,   126,  2736,  2738,  2739,  2740,  3362,  3363,  3795,\n",
      "         4333,  4336,  7853,  7855,  7860, 11708, 11709, 12375, 15275, 16522]), tensor([ 2358,  2360,  4422,  6144,  6145,  7679,  7721,  7722,  7938,  9625,\n",
      "        10353, 10662, 10663, 14441]), tensor([ 1429,  1430,  1431,  9280, 10139, 11088, 12877]), tensor([ 1198,  1200,  4455,  4456,  4972,  4973,  5040,  5410,  5492,  5535,\n",
      "         5823,  6999,  7071,  7587,  7588,  7975,  8929,  8930, 14723, 16771]), tensor([ 1713,  1714,  2123,  2358,  4032,  5483,  5484,  5841,  5842,  6823,\n",
      "         7051,  8879,  8884,  8885,  8943,  8969,  8970,  9037,  9974, 10016,\n",
      "        10126, 10215, 10368, 10375, 10507, 11065, 11067, 11068, 11453, 11454,\n",
      "        12796, 13394, 13918, 15048]), tensor([ 1745,  2354,  3198,  3199,  3200,  3201,  5313,  5521,  5524,  8337,\n",
      "         8895,  8896, 11919, 13141, 14383]), tensor([  793,  2501,  3456,  3457,  3458,  3654,  3718,  4880,  4881,  4882,\n",
      "         6060,  8094,  8095, 13429, 14540, 15313, 15874]), tensor([ 1470,  1472,  1921,  6487,  6490,  6709,  7321,  7322,  7325,  7573,\n",
      "         9257, 10976, 10977, 11474, 12229, 12575, 12576, 13119, 14860, 15437]), tensor([ 1374,  1375,  1376,  1377,  4534,  5708,  6442,  6444,  6615,  6639,\n",
      "        11378, 11485, 11590, 11591, 11851, 11854, 13026]), tensor([ 1005,  1228,  1230,  1577,  1578,  1579,  3927,  4252,  4357,  5063,\n",
      "         5064,  5065,  5131,  5192,  5194,  5202,  5354,  8231,  9651,  9652,\n",
      "        10318, 12667, 12828, 13535, 14896, 15132, 15310]), tensor([ 5073,  5074,  5169,  5170,  5770,  5771, 10056, 10417, 16433]), tensor([  493,  3323,  6060,  6061,  6062,  6685,  6687,  6867,  6869,  8086,\n",
      "        10980, 11226, 11228, 13139, 13953, 13954, 15406, 15640, 16082, 16083]), tensor([   61,    62,  1415,  4475,  5406,  5755,  5757,  5864,  6039,  6103,\n",
      "         6870,  6871,  6962,  8243,  8916,  9896, 10059, 10740, 11330, 12212,\n",
      "        13953, 13954, 15929]), tensor([ 6747, 12294, 12427, 12529, 13296]), tensor([ 3163,  4667,  5805,  8423, 10905, 12360, 12365, 12366, 12851, 12852,\n",
      "        13350]), tensor([  416,   418,  2797,  2799,  6866, 10360, 10361, 11120, 11195, 11366,\n",
      "        11368, 12363, 12376, 13026]), tensor([  126,  3171,  3172,  5030,  5054,  5055,  5068,  5070,  5258,  6185,\n",
      "         6186, 10998, 10999, 11415, 11416, 11448, 11449, 12937, 13140, 16141,\n",
      "        16146]), tensor([ 2076,  2151,  2153,  2158,  5336,  6020, 10739, 10740, 11226, 11228,\n",
      "        12799, 14785, 15808, 15809]), tensor([  232,  2493,  3355,  3357,  4551,  5291,  5292,  6220,  6594,  7332,\n",
      "         8280,  8423,  9559,  9561, 10360, 10489, 10671, 11810, 12073, 12081,\n",
      "        12985, 13439, 14215]), tensor([ 6588,  7261,  7262,  7901,  8245,  8247, 12375, 12376, 12936, 12938,\n",
      "        14866]), tensor([ 1432,  1433,  9564, 11048, 11089, 12498, 12731, 13080, 13081, 13089]), tensor([ 1854,  1855,  6038,  6039,  6040,  6042,  6044,  6115,  6277,  6278,\n",
      "         8221,  8222,  8233,  9207, 10823, 10824, 11093, 11406, 11707, 11708,\n",
      "        11735, 13067, 13074, 13395, 13546, 14728, 16066]), tensor([ 6678,  6679,  6872,  6873,  6874,  6875,  6876,  6900,  7256,  8764,\n",
      "         8784,  8956,  9977,  9978, 10265, 10486, 15979, 15980, 15998]), tensor([ 9259,  9352, 14430]), tensor([ 3874,  5925,  5926,  5927,  6104,  6105,  8326,  8844,  8879,  9111,\n",
      "         9113,  9432, 12367, 14453, 14741]), tensor([ 2538,  2611,  3163,  5477,  5480,  5803,  5804,  5805,  5886,  8226,\n",
      "         8227,  9623, 10413, 10493, 11521, 11751, 13244, 13245, 14865, 14869,\n",
      "        16064]), tensor([ 8733,  8734,  8786,  9349,  9350,  9352, 11452, 11455, 12555, 12785,\n",
      "        15648, 15649, 15700, 16387]), tensor([15428, 15429]), tensor([ 1649,  2251,  4603,  5755,  5756,  6039,  6040,  7005,  9130, 10397,\n",
      "        10398, 10481, 10700, 10998, 10999, 11000, 11981, 12572, 12665, 12936,\n",
      "        12938, 14860, 15440]), tensor([ 1435,  1436,  5260,  5302,  5304,  5305,  7121,  7122,  7728,  7733,\n",
      "         7735,  8687,  8693,  8875,  8893,  8894, 13283, 13329, 14648, 15049,\n",
      "        16448, 16449, 16478]), tensor([ 2096,  2098,  2152,  5332,  5333,  7260,  7261,  7262,  7899,  7900,\n",
      "         7901,  8031,  8037,  8828,  8968, 11301, 11302, 14218, 15662, 15663,\n",
      "        15714]), tensor([  327,   328,  3376,  3966,  3967,  4517,  4595,  6537,  6831,  7105,\n",
      "         7628,  7629,  8242, 10270, 13352, 13353, 13479, 16710]), tensor([ 2807,  4192,  4630,  4631,  4633,  4979,  4980,  4981,  5774,  6085,\n",
      "         6086,  6728,  7071,  7072,  7719,  7721,  7949,  7950,  8736,  8774,\n",
      "        11744, 11772, 11853, 12614, 16079, 16083]), tensor([ 6137,  9281,  9282, 13122, 16410]), tensor([ 2799,  3069,  5227,  5427,  5428,  5942,  6511,  7588,  8715, 10472,\n",
      "        10473, 12485, 12486, 12871, 13023, 13271, 13537, 13538, 14533, 14840,\n",
      "        14873, 15916]), tensor([ 2139,  2141,  3902,  5656,  6411,  6574,  8677,  8929,  8931,  9142,\n",
      "         9143,  9484,  9738, 10344, 10693, 10694, 13876, 13920]), tensor([ 1228,  1229,  5077,  5081,  6708,  7048,  8221,  8855, 11436, 12776,\n",
      "        12834, 12836, 13350, 15218, 15910]), tensor([ 1225,  3890,  4746,  4748,  4751,  4752,  4753,  7341, 10137, 10141,\n",
      "        10274, 10276, 10317, 10499, 11521, 11577, 12040, 12041, 12055, 14260]), tensor([ 1282,  1285,  1887,  1888,  1889,  4586,  4589,  7261,  8665,  8666,\n",
      "         9205, 12665, 13857]), tensor([   56,    58,   321,  3654,  3655,  4586,  4588,  4589,  6038,  6039,\n",
      "         6219,  6221,  7971,  7973,  8075,  8095, 10739, 10740, 10998, 12665,\n",
      "        13142, 14076, 14251, 16509]), tensor([ 1648,  1650,  3900,  3902,  4454,  5457,  6146,  6497,  6498,  6510,\n",
      "         6717,  7121,  8705,  8706, 11352, 11405, 11761, 13017, 13074, 13160,\n",
      "        13441, 16509]), tensor([ 1213,  1477,  1480,  2139,  2143,  2172,  2174,  2768,  5226,  5227,\n",
      "         5229,  5428,  6229,  6677,  7057,  8236,  8246, 11301, 11302, 11894,\n",
      "        11895, 12834, 12850, 12851, 15484, 16621]), tensor([ 5028,  5029,  5034,  8282, 10069, 12069, 12071, 12094, 15481, 16464]), tensor([ 6137, 11999, 12000, 12007, 12009, 13955, 14030, 16070]), tensor([ 3175,  3177,  3178,  6684,  6912,  6951,  6952,  6960,  8238,  8240,\n",
      "         9036,  9566, 10370, 10376, 11249, 11540, 11703, 15947]), tensor([ 2338,  2340,  2798,  2799,  4251,  4632,  8226,  8422,  8423,  9618,\n",
      "         9622, 12562, 12563, 12944, 13025, 13484, 13485, 14267, 16423]), tensor([ 2332,  2333,  3118,  3231,  3232,  5404,  7227,  7228,  8932,  9339,\n",
      "        10844, 11163, 11457, 13141, 13157, 13197, 13638, 13639, 14723, 15298,\n",
      "        16244]), tensor([  303,  4228,  5233,  5362,  5949,  5950,  6514,  6515,  6615,  8755,\n",
      "        10843, 11086, 11087, 11153, 11154, 11386, 11407, 11408, 11653, 11673,\n",
      "        11736, 12120, 12263, 13245, 13259]), tensor([ 4468,  4469,  7414,  7415,  8682, 10598, 10599, 10604, 11058, 13309,\n",
      "        16404, 16405, 16440]), tensor([ 1577,  2457,  3555,  4408,  5454,  5772,  5773,  7905,  7958,  7961,\n",
      "         7974,  9434, 10313, 10314, 10315, 11533, 11534, 11592, 12655, 12826,\n",
      "        12832, 13063, 13072, 13182, 14241, 14242, 14621, 15121]), tensor([ 2674,  3936,  4472,  6335,  9087,  9089, 11539, 11769, 11770, 11831,\n",
      "        11890, 12010, 13463]), tensor([ 1803,  1804,  1807,  2231,  5898,  6072,  6073,  6341,  8893,  8894,\n",
      "        11215, 11596, 14531, 14532, 14534, 15682, 16009, 16371]), tensor([ 3361,  4489,  5024,  5138,  5140,  5144,  5146,  5402,  5403,  6496,\n",
      "         6497,  6639,  8869,  8870,  9606,  9620, 10671, 10962, 11426, 11589,\n",
      "        11590, 11899, 11900, 12993, 13142, 14076, 14841]), tensor([ 1139,  1142,  1403,  1405,  2399,  2400,  4629,  6078,  6079,  6686,\n",
      "         7862,  7892,  7893, 11770, 11852, 11869, 11870, 11879, 15658, 15659,\n",
      "        15679]), tensor([ 3071,  7974, 10515, 12471, 12472, 13063, 13197, 13394, 15048]), tensor([   65,   549,  1244,  3232,  4470,  6103,  6142,  6143,  6145,  8075,\n",
      "         8095,  9532,  9534,  9896,  9897, 11177, 13998, 15177]), tensor([ 6041,  6044,  6049,  6684,  6685,  6686,  6764,  6766,  6767,  8634,\n",
      "         8997,  8998,  9675, 11369, 11409, 11410, 11415, 11554, 11616, 11769,\n",
      "        12790, 15313, 15874, 15875]), tensor([ 1928,  1931,  5331,  5332,  5333,  5334,  7942,  8060,  9206, 10277,\n",
      "        10278, 10279, 11226, 11227, 11351, 11352, 12536, 13245, 14075, 14539]), tensor([ 4526,  4531,  4532,  4745,  5131,  5778,  5800,  6640,  6656,  9355,\n",
      "         9684, 11149, 11156, 15509]), tensor([ 2613,  2615,  2675,  3406,  5336,  5757,  6877,  6900,  8070,  8094,\n",
      "        10739, 10740, 10741, 12799, 12847, 13355, 14342, 14540]), tensor([ 6508,  6868,  6870,  6871,  6877,  7907,  8530,  8532, 10485, 10486,\n",
      "        10487, 10834, 11885, 12360, 14622, 14623, 14636]), tensor([ 4529,  4532,  5777,  5778,  7118, 10629, 10631, 11149, 11865]), tensor([ 1869,  2466,  2468,  3231,  3232,  3233,  4634,  5423,  6860,  7513,\n",
      "         7515,  7564,  7565, 11170, 11171, 11172, 11174, 11176, 14209]), tensor([ 2125,  5647,  8947,  8964,  9027, 12436, 13842, 14556, 14558, 14607,\n",
      "        14608, 15214, 15808, 15809, 15876]), tensor([ 6486,  6488,  6489, 11312]), tensor([ 2532,  2759,  2794,  2796,  5293,  5294,  6039,  6040,  7093,  8060,\n",
      "         8871, 10972, 10979, 11040, 11885, 11904, 11905, 12130, 12131, 12471,\n",
      "        12472, 12487, 13157, 13206, 14598, 15747, 15748, 15852, 16444, 16445,\n",
      "        16529]), tensor([ 9684, 11155, 11156, 11157, 11384, 11828, 16712]), tensor([ 5392, 10417, 11412, 11413, 11997, 12000, 12004, 12009]), tensor([ 5133,  5142,  5143,  6488, 13019]), tensor([ 2789,  2791,  3074,  4326,  5209,  9986,  9993, 10494, 10497, 10692,\n",
      "        11296, 11297, 11298, 14583, 15912, 15914, 16070]), tensor([   60,    63,  1244,  1245,  2452,  2526,  2527,  2528,  2529,  2613,\n",
      "         2615,  2688,  2714,  2715,  2987,  3030,  3176,  5548,  6709,  6711,\n",
      "         7081,  8230,  9622,  9895,  9896, 10375, 10376, 11879, 14342, 14515,\n",
      "        14516, 14873, 15572, 15894]), tensor([ 1202,  1539,  1540,  3216,  5460,  5463,  6682,  6684,  7042,  7044,\n",
      "         7808, 10547, 11538, 13427, 15911]), tensor([ 3557,  3723,  3724,  5850,  8627,  8628,  9350,  9351,  9548,  9551,\n",
      "        10998, 10999, 11224, 11226, 11571, 12642, 12850, 12852, 13185, 13295,\n",
      "        16563]), tensor([ 1448,  1454,  5052,  5054,  5410,  5823,  6104,  6106,  9204, 11705,\n",
      "        12358, 15048, 16020, 16244, 16385, 16386, 16387]), tensor([ 1903,  1905,  4464,  4538,  4539,  8344, 11222, 11223, 12972, 15601,\n",
      "        15736]), tensor([ 4160,  6607,  6821,  6822,  8088,  8089,  9078,  9141,  9142,  9143,\n",
      "        10003, 10004, 10073, 10074, 13244, 13483, 14110, 14312]), tensor([  57,  321, 1199, 2396, 3172, 3173, 4229, 5377, 6051, 7000, 7001, 8244,\n",
      "        8885, 8968, 9086, 9298, 9594, 9596, 9597]), tensor([ 1418,  1421,  1422,  1423,  2151,  2153,  2158,  4592,  4595,  4596,\n",
      "         5039,  5259,  5261,  5438,  6503,  6728,  6946, 10972, 10978, 10979,\n",
      "        11745, 13582, 13583, 16614]), tensor([  419,  3361,  4488,  4619,  4621,  4622,  4623,  4626,  5464,  5465,\n",
      "         6137,  6441,  6442,  7646,  7647,  8392, 11866, 13057, 13058, 13584]), tensor([ 3172,  3174,  3208,  6333,  6343,  6877,  8262,  9089, 10739, 10741,\n",
      "        12789]), tensor([  258,  4538,  4540,  5656,  6732,  6735,  6757,  8053,  8054,  9561,\n",
      "        11810, 12567, 12785, 13795, 16144, 16692]), tensor([ 1359,  1360,  2465,  2468,  3724,  3726,  4634,  5016,  5017,  5034,\n",
      "         9259,  9260,  9261, 10693, 10694, 10977, 11177, 11839, 11840, 11899,\n",
      "        11900, 13009, 14860]), tensor([  417,   418,  1930,  1931,  2675,  5756,  7332,  8709,  8712,  8739,\n",
      "        10562, 10671, 11092, 11571, 12877, 12993, 14955]), tensor([    8,  1144,  1145,  4982,  4984,  5864,  6596,  7837,  8865,  8866,\n",
      "        10059, 10596, 10671, 11072, 11535, 12985, 13953, 13954, 14738, 15982,\n",
      "        16542, 16543]), tensor([ 1154,  1244,  2787,  5229,  5534,  6199,  6746,  6752,  7175,  9162,\n",
      "        12202, 14752, 15176, 15177]), tensor([ 5607,  6868,  6870,  8907,  8911,  8951,  9132,  9133,  9596,  9597,\n",
      "        10807, 10972, 10978, 11396, 11664, 11759, 12101, 12799, 13549, 13550,\n",
      "        15729, 15929]), tensor([ 2247,  3417,  3418,  3423,  4209,  4210,  4211,  6562,  6564,  8934,\n",
      "         9019,  9140,  9143,  9738,  9786, 11325, 11352, 11405, 12073, 12081,\n",
      "        12988, 13148, 13154, 13155, 14594, 15788, 15981, 16425]), tensor([ 2675,  3242,  3243,  4230,  4231,  5756,  7252, 13309, 16392, 16408]), tensor([ 3351,  3352,  4347,  4349,  4350,  4351,  4353,  4355,  4356,  5234,\n",
      "         5239,  6849,  6851,  6858,  6859,  9738,  9786, 10592, 12073, 12081,\n",
      "        12099, 12936, 12937, 12938, 13017, 13665, 13666, 16425]), tensor([ 1726,  1745,  2675,  5755,  5756,  5757,  6486,  6487,  6488,  6490,\n",
      "         6725,  9011, 10562, 10739, 10740, 10741, 11571, 12093, 12363, 12376,\n",
      "        12377, 12609, 12799, 13675, 13676, 14383]), tensor([ 5886,  5888,  9977,  9978, 10265, 11470, 11472, 11601]), tensor([ 2237,  2238,  2338,  2340,  2397,  2798,  2799,  2958,  2960,  4209,\n",
      "         4211,  5291,  6061,  6847,  6848,  6859,  7935,  8086,  8423,  8928,\n",
      "         8930,  9787, 10308, 10395, 10396, 10647, 12360, 12518, 12564, 12838,\n",
      "        12841, 13024, 13026, 13285, 14785]), tensor([ 3477,  3653,  5699,  5757,  6877,  8752,  8870, 10739, 10740, 10741,\n",
      "        11764, 12799, 14684]), tensor([  177,   178,   531,  3173,  3174,  3339,  6641,  7059,  7061,  7299,\n",
      "         8229,  8233,  8234,  8970, 11065, 11326, 11327, 11353, 11396, 13576,\n",
      "        13578, 15257]), tensor([ 2532,  2533,  2710,  4455,  5770,  5771,  8842,  8845,  8948,  8955,\n",
      "        11211, 13135, 14541, 14542, 16705]), tensor([ 5293,  6570,  7045,  7048,  8786, 10967, 12355, 12473, 13065, 13149,\n",
      "        13953, 13954, 14950, 14951, 15393, 15459, 15910, 16525]), tensor([  258,   260,  4754,  4761,  4764,  6684,  7251,  7253,  7254,  9151,\n",
      "        11369, 11409, 11770, 15103, 16193, 16383, 16385]), tensor([  355,   357,  2796,  4452,  4454,  6726,  7817,  8035,  8270, 10385,\n",
      "        12486, 12839, 12871, 13883, 14070, 14876, 14877, 15877]), tensor([ 1846,  2025,  2028,  2031,  2403,  3242,  3243,  5336,  6589,  6591,\n",
      "         6845,  8850,  8857,  8906,  8953,  8955,  9037, 13953, 13954, 14741]), tensor([  518,   519,   520,   524,   525,  2118,  2120,  3445,  5697,  6142,\n",
      "         6144,  6145,  6675,  6677,  6681,  8723,  8795, 11358, 16495]), tensor([  519,   521,  2504,  2732,  3359,  3360,  3361,  3558,  4470,  4475,\n",
      "         4488,  4587,  6136,  8283, 11735, 11952, 13074, 13398, 13399, 14804]), tensor([  139,   141,   368,   369,  3355,  6104,  8382,  8512, 10252, 10253,\n",
      "        10259, 10264, 10595, 10596, 11309, 12277, 12288, 12289, 13637, 13916,\n",
      "        13918, 14217, 16245]), tensor([  358,  1455,  1458,  2358,  2360,  4628,  5405,  5406,  5950,  6039,\n",
      "         6042,  6598,  8195,  8885,  8968, 10234, 10823, 10824, 10826, 11379,\n",
      "        12941, 12942, 14728, 16589]), tensor([ 3287,  5129,  5130,  5244,  6502,  7007,  7692,  7693,  8392,  9622,\n",
      "         9623,  9627, 10823, 11835, 14727, 14728]), tensor([ 1258,  1272,  1275,  3802, 11452, 11453, 11469, 13125, 13295, 14988]), tensor([ 4210,  4211,  5335,  5379,  6050,  6052,  9007, 10485, 10486, 12275,\n",
      "        12778, 14515, 16425]), tensor([ 1864,  2151,  3432,  5052,  5326,  5327,  7944,  7946, 10824, 12361,\n",
      "        12364, 12575, 12580]), tensor([  316,  1885,  8851,  8852,  8853,  8854,  9014,  9015,  9016, 10669,\n",
      "        10670, 10691]), tensor([ 1417,  1418,  1421,  1423,  4503,  4504,  4592,  4596,  5464,  5869,\n",
      "         6410,  6642,  8908, 10695, 10698, 12362, 13001, 13002, 13017, 13160,\n",
      "        13417, 15038, 15039, 15275, 15276, 15465]), tensor([  179,   182,  3654,  4953,  6335,  7513,  7515,  8095, 15894, 15895]), tensor([ 2216,  2217,  2741,  2742,  4460,  5864,  6439,  6440,  7941,  7943,\n",
      "         8059,  8974, 10059, 11134, 11139, 11194, 13073, 14077, 14081, 14542,\n",
      "        15721]), tensor([ 1904,  3365,  3366,  3372,  5648, 11454, 12097, 12099, 15101, 15103,\n",
      "        16083, 16387]), tensor([  418,  1444,  4190,  5401,  5402,  6860,  7513,  7515,  7623,  7624,\n",
      "         7645,  8643,  9354, 11120, 12632, 12633]), tensor([ 1460,  1461,  3074,  4621,  5848,  5849,  6634,  6635,  6636,  6710,\n",
      "         7050,  7950,  9461,  9464, 10963, 11015, 11056, 11162, 11417, 11425,\n",
      "        11536, 11537, 14075, 14076, 15629, 15676, 15915]), tensor([  145,   146,  1844,  5846,  5847,  6591,  6649,  7846,  8087, 12358,\n",
      "        12363, 12364, 12936, 12937, 12938, 14071, 14076]), tensor([ 1202,  1204,  2194,  2762,  2764,  3607,  4706,  5111,  8384, 10604,\n",
      "        10606, 10684, 10691, 10964, 10965, 11056, 15185, 15196, 15434, 16280,\n",
      "        16408, 16675]), tensor([ 5241,  5343,  5344,  6537,  6538, 13253, 13254, 13439, 13540, 14079,\n",
      "        14539, 16180]), tensor([ 1280,  1392,  1393,  5052,  5326,  5328,  5498,  6019,  6020,  7209,\n",
      "         7210,  7240,  9541, 11948, 14785, 15273]), tensor([ 1143,  1146,  4189,  4190,  4480,  4481,  4710,  4721,  5481,  6867,\n",
      "         6869,  8129,  8664,  8665,  8674, 10897, 10979, 12638, 12640, 13000,\n",
      "        13002, 13664, 13666, 15465]), tensor([ 1660,  1662,  2497,  8674, 13022, 13183, 13184, 13350, 14877, 16428,\n",
      "        16429, 16670]), tensor([  223,   225,   729,   730,  2251,  2252,  2253,  2254,  4408,  4789,\n",
      "         6766,  7005,  7591,  8032,  8033, 12833, 15662]), tensor([ 5253,  5254,  5255,  5256,  5257,  5294,  5478,  5479,  5482,  5605,\n",
      "         5848,  5849,  8634,  8702,  8998,  9000, 11885, 11886, 12360, 12365,\n",
      "        13004, 13084, 15532, 16487]), tensor([ 1143,  1144,  1148,  2215,  4136,  4623,  4626,  5705,  5949,  5950,\n",
      "         6441,  6442,  6444,  6592,  6962,  7647,  7863,  7864,  7951,  8846,\n",
      "         8848,  8849,  8964, 11331, 11379, 12055, 12065, 12066, 14880]), tensor([ 1375,  1376,  1706,  1707,  4266,  4267,  6364,  6615,  6616,  7228,\n",
      "        12059, 12060, 12066, 12365, 12367, 13971, 14838, 16244]), tensor([ 2184,  2185,  3065,  4795,  4796,  6019,  8343,  9621,  9622,  9626,\n",
      "        10383, 10385, 10386, 11397, 11398, 11671, 11672, 11973, 12067, 14072,\n",
      "        14073, 14301, 15070]), tensor([   60,    63,   325,  1360,  1363,  6039,  6040,  7254, 10450]), tensor([ 4537,  4539,  6224,  6507,  6508,  8015,  8017, 11209, 11210, 12972,\n",
      "        13270, 13306, 14841]), tensor([ 3332,  3333,  4998,  5030,  5031,  5068,  5217,  5359,  5827,  5828,\n",
      "         7224,  7846,  7945,  7947,  9453, 10194, 16109, 16237]), tensor([ 1225,  1226,  1228,  1229,  1282,  1284,  1285,  8233,  8270,  9983,\n",
      "         9985,  9986, 10494, 13263, 13857, 14582, 14583]), tensor([ 5065,  5226,  5360,  5428,  5460,  5461,  5462,  5463,  5527,  5846,\n",
      "         5849,  5873,  5875,  8636, 10238, 11536, 11537, 11538, 11899, 14265,\n",
      "        16312, 16467, 16598]), tensor([   46,  1216,  5096,  5097,  5401,  5403,  5404,  5502,  5530,  5534,\n",
      "         6199,  6627,  6629,  7361,  8094,  8095,  8235, 10193, 10194, 10645,\n",
      "        10647, 10648, 10656, 11093, 11387, 11428, 11848, 12565, 13394, 15048,\n",
      "        16109]), tensor([ 2960,  3455,  3459,  6011,  7728,  9692,  9693, 11059, 11060, 11326,\n",
      "        11397, 12072, 12575, 12580, 15069, 15302, 15523, 15529, 16590]), tensor([3749, 3966, 6035, 6037, 6767, 6768, 6863, 6867, 6868, 7105, 8928, 8929]), tensor([ 2358,  2359,  2360,  2402,  4628,  4982,  4983,  5442,  7852,  7861,\n",
      "         7892,  7893,  7938,  8842,  8885,  8944,  8946,  9702, 12936, 12937]), tensor([ 5208,  5209,  5210,  5429, 11296]), tensor([ 5532,  6443,  6444,  6498,  6502,  6504,  6528,  6530,  7062,  7065,\n",
      "         7662,  7663,  7690,  7693, 11546, 11548, 14727, 16393, 16615]), tensor([ 2341,  2342,  6429,  7081,  7728,  7950,  8421,  9531,  9532,  9533,\n",
      "         9534, 10125, 10642, 10644, 10648, 10696, 11925, 12565, 13254, 13347,\n",
      "        13486, 13540, 14034, 15529]), tensor([ 2028,  2031,  6043,  6502,  6503,  6597,  7908,  9666, 11911, 11912,\n",
      "        12713, 12715, 12882, 14730]), tensor([ 1869,  6036,  6037,  6511,  6512,  6513,  7906,  9532,  9534, 11177,\n",
      "        11222, 11301, 11303, 12094, 12816, 14207, 15670]), tensor([13206, 13316, 14727, 14729, 14730, 16196]), tensor([ 4982,  4983,  4984,  5135,  5137,  5140,  5142,  5919,  5920,  7339,\n",
      "         9702, 10671, 11535, 12715, 12985]), tensor([11760, 11761, 15482]), tensor([ 1147,  2237,  4627,  4629,  5344,  5345,  5437,  6060,  6063,  7861,\n",
      "         7863,  7952,  8086, 10985, 11910, 11912, 15048]), tensor([  240,   243,  1135,  1136,  1360,  1362,  2400,  2404,  2405,  5096,\n",
      "         5098,  9566,  9567,  9898, 10056, 15409, 15413, 15880, 16294]), tensor([   14,   145,   147,   150,  1842,  1847,  3414,  8829, 12672, 12673,\n",
      "        13212, 13493, 15861]), tensor([ 1770,  2461,  2466,  2606,  5436,  6106,  6684,  6686,  8241,  8242,\n",
      "         9020,  9021,  9617, 10349, 10350, 10361, 10449, 10451, 11243, 11369,\n",
      "        11410, 11521, 11578, 13123, 13124, 13637, 13639, 14420, 16180, 16683]), tensor([ 3213,  8709,  8711,  9495, 11692, 11824, 13660, 14945, 15208]), tensor([  327,  1224,  6077,  6078,  6080,  8248,  8839,  8840,  8956, 11769,\n",
      "        11770, 11988, 11990, 11991]), tensor([ 1139,  1392,  1393,  5411,  5412,  6767,  6768,  9288, 13906]), tensor([  225,  3350,  3358,  3360,  4531,  4991,  5124,  5125,  5166,  5167,\n",
      "         5172,  5842,  5843,  6433,  6435,  6489,  6657,  7723,  7724,  7909,\n",
      "         7952,  7983, 11045, 12095, 12096, 13460, 13462, 14075, 14539, 15529,\n",
      "        16443]), tensor([ 2810,  2811,  2812,  4224,  5292,  5293,  6683,  6688, 12220, 12472]), tensor([  360,   361,  2139,  2142,  2143,  3653,  4938,  5325,  5699,  7046,\n",
      "         7048,  9566,  9568, 11009, 11010, 11764, 15461]), tensor([ 1051,  2467,  5345,  5438,  6652,  7510,  7705,  7706,  7709,  7974,\n",
      "        12367, 13215, 15096, 16196, 16198, 16244]), tensor([1175, 1199, 1200, 8774, 8925, 8926, 9035]), tensor([  263,  1659,  2040,  2799,  4620,  4623,  4624,  4722,  4723,  5705,\n",
      "         5747,  5748, 11435, 11674, 11675, 12518, 12872, 13056, 13057, 13356,\n",
      "        13894, 16026, 16705]), tensor([ 5430,  5431,  6522,  8238,  8239,  8672,  8673,  8800,  8887,  9691,\n",
      "         9693, 12850, 15199, 15584, 15586, 15616, 16422]), tensor([ 4209,  9362,  9365,  9474,  9737,  9787, 12714, 15174, 15175, 15176,\n",
      "        15177, 16146, 16479]), tensor([ 4265,  4266,  4267,  4268,  4483,  6011,  6606,  8906,  9282, 11370,\n",
      "        11579, 11611, 11897, 12089, 12846, 13122, 14740, 15068, 15069, 15302]), tensor([  309,  3778,  4265, 11283, 12936, 12938, 14397, 16149, 16150, 16542]), tensor([  356,   358,  3370,  3372,  4217,  5253,  5257,  5445,  5464,  5465,\n",
      "         5647,  5648,  6642,  6643, 13205, 13206, 13316, 14827, 15808]), tensor([ 1051,  1432,  1435,  1436,  2139,  2143,  5054,  5055,  5091,  5092,\n",
      "         5093,  5094,  5226,  5355,  5356,  5409,  5410,  5411,  5412,  5413,\n",
      "         5428,  8047,  8050,  8786,  9435, 12714, 12747, 12748, 15458]), tensor([ 1244,  2773,  4189,  4464,  4466,  4957,  4958,  8230,  9942,  9943,\n",
      "        10910, 12515, 12516, 12517, 12562, 12636, 15176, 15177, 15411, 15412,\n",
      "        16154]), tensor([ 1441,  1443,  1997,  1999,  4939,  5460,  5463,  6525, 11445, 11761,\n",
      "        11794, 12097, 12099, 12632, 12878, 13082, 13439, 13953, 13954, 14550,\n",
      "        15480, 15482, 15515, 15516, 15593, 16012, 16618]), tensor([ 4518,  4792,  4793,  4795,  5816,  8045,  8046,  9444,  9606, 10266,\n",
      "        11900, 12201, 12202, 13439, 13441, 15177, 15572, 15821]), tensor([  126,  1299,  1300,  1301,  2218,  2493,  2737,  5298,  8800,  8801,\n",
      "         8827,  8829,  8886,  8940,  8986,  9075,  9076, 10014, 10015, 10197,\n",
      "        11059, 12988, 13191]), tensor([ 8420,  8828,  8968,  9086,  9694, 11324, 11353, 11746, 12615, 12616,\n",
      "        12776, 15218]), tensor([ 5109,  5111,  7944,  7946, 11010, 16280]), tensor([  350,  3310,  3412,  3416,  3422,  3423,  8082,  8084,  8613,  8616,\n",
      "         8749,  9329,  9330,  9331, 11663, 11811, 13626, 15788]), tensor([ 1215,  1216,  1359,  1360,  1362,  2793,  2795,  4719,  5698,  6063,\n",
      "         7107,  7190,  7191,  8082,  8084,  9090,  9091, 10594, 10662, 11125,\n",
      "        11127, 11312, 11670, 11781, 11782, 11798, 13154, 13155, 13185, 14425,\n",
      "        14601, 15894, 15895, 16522]), tensor([ 1229,  1230,  2248,  2250,  5038,  5039,  5042,  5074,  5406,  6039,\n",
      "         8232, 12363, 12376, 12828, 13582]), tensor([ 2174,  3207,  3208,  4711,  4714,  9594, 12775, 12922, 12936, 12937,\n",
      "        15048]), tensor([ 1488,  1489,  1490,  1491,  4471,  4600,  4604,  4616,  4617,  5359,\n",
      "         5360,  5461,  5462,  5527,  6768,  7928,  7929,  9130,  9245,  9698,\n",
      "         9699, 10228, 10972, 10979, 13596, 14303, 14305, 15134, 16544]), tensor([ 1705,  1708,  1709,  3071,  3175,  3176,  3462,  4460,  4461,  5127,\n",
      "         5128,  6335,  8803,  8804,  9090, 10515, 10823, 10826, 11391, 11397,\n",
      "        14966, 15876, 15894]), tensor([  179,   181,  1809,  2032,  2172,  2854,  3107,  4477,  6605,  7711,\n",
      "        10056, 11115, 11904, 11907, 11908, 13204, 13547, 13548, 14739, 14740,\n",
      "        15145, 16067, 16433, 16503, 16719]), tensor([ 3175,  3177,  5848,  8998,  9090, 13665, 13666, 16487]), tensor([ 2129,  2130,  3966,  4294,  4534,  5707,  5709,  5746,  5814,  5815,\n",
      "         6198,  6324,  7105, 10594, 12937, 13061, 13140, 13644, 13645]), tensor([ 5360,  8980,  8981, 10140, 13480, 13481, 13483]), tensor([ 1361,  1479,  1480,  2920,  3356,  4266,  4268,  4717,  5207,  5208,\n",
      "         5211,  5216,  5217,  5492,  5898,  5899,  5900,  5901,  5902,  5903,\n",
      "         7061,  7226,  7475,  7477,  8422, 11348, 11349, 11352, 11370, 11371,\n",
      "        11579, 12471, 12473, 13397, 13399, 13582, 14528, 14531, 16747]), tensor([3654, 3655, 4529, 4531, 5091, 5092, 5409, 5410, 6046, 7871, 8075, 8095]), tensor([  368,   369,   371,   373,  2392,  2394,  2398,  3357,  4451,  4454,\n",
      "         4939,  6477,  6724, 11760]), tensor([ 1641,  5038,  5092,  5207,  5208,  5211,  5823,  6496,  6498,  6507,\n",
      "         7003,  7004, 10117, 12831, 13067, 13582, 13583]), tensor([ 6257, 10372, 10373, 12673]), tensor([ 8088,  8089,  8245,  8246,  8928,  8931, 11008, 11383, 13954, 14865,\n",
      "        14869, 15463]), tensor([  321,   323,  6341,  6746,  6751,  6917,  6918,  6920,  7476,  7478,\n",
      "         7480,  7483, 16495]), tensor([  373,  2253,  2254,  2363,  3355,  4039,  6962,  7003,  8831, 11308,\n",
      "        11330, 13058, 13253, 13254, 13376, 13582, 13802, 13916, 13917, 13918,\n",
      "        15410, 15656]), tensor([  302,  1272,  1274,  2139,  2142,  2143,  2172,  4708,  4709,  4710,\n",
      "         5443,  5445,  6269,  7266,  7622,  7624,  7647,  9138,  9457, 14610,\n",
      "        15974, 16149, 16287, 16542, 16621]), tensor([   57,    58,   259,   260,  1415,  1416,  5430,  5431,  7835,  8244,\n",
      "        16193]), tensor([ 2191,  5060,  5061,  5100,  5253,  5254,  5255,  5257,  5848, 11404,\n",
      "        11405, 11406, 11994, 11995, 11998, 16382]), tensor([ 1448,  1450,  1930,  1931,  5405,  5406,  5412,  5851,  6039,  6040,\n",
      "         7073,  8909,  8996,  9131,  9281,  9282, 11905, 11906, 12715, 12938,\n",
      "        13017, 13160, 13196, 16278, 16289, 16290]), tensor([ 8048,  8049,  8226,  8227,  9623, 15627]), tensor([ 6512,  8239,  8240,  9566,  9973,  9977, 10264, 10266, 10828, 10829,\n",
      "        11529, 11766, 12555, 12557, 15616, 16523]), tensor([ 4194,  5486,  5488,  6131,  9673,  9674,  9679, 11617, 12172, 12515,\n",
      "        12516, 12517, 12563, 14968, 15631]), tensor([ 1708,  2151,  7189,  7190,  8088, 12362, 13024, 13025, 13026, 13271,\n",
      "        14344, 14939, 15001, 15276, 16725]), tensor([ 1139,  1147,  1405,  1406,  6507,  8087,  8088,  8671,  8672,  8674,\n",
      "         8996, 13253, 13254, 13376, 13539, 13540, 13548, 14841]), tensor([ 2032,  2033,  2234,  2235,  2236,  2238,  5845,  5847,  6581,  6582,\n",
      "         6583,  7629,  7944,  7947,  8079,  8087,  8088,  8089,  8093,  9363,\n",
      "        10601, 10603, 11114, 11556, 11909, 11914, 12794, 13845, 14025, 14747,\n",
      "        16148]), tensor([ 5847,  6616,  8087,  8089,  8843,  8845,  8943,  9642,  9711, 10281,\n",
      "        13616, 15505, 15506, 16719]), tensor([  321,   322,  1715,  3483,  3491,  5116,  5120,  5121,  5873,  5875,\n",
      "         7115,  7117,  8244,  9008,  9029,  9030,  9711, 10056, 11094, 14222,\n",
      "        15064, 16433]), tensor([ 3378,  3380,  3724,  3726,  4216,  6839, 12041, 12043, 12056, 13523,\n",
      "        16197, 16198]), tensor([ 1652,  1653,  2191,  2338, 10162, 10646, 11008, 12562, 13953, 16384]), tensor([  144,   145,   832,  1162,  1164,  1165,  1166,  1356,  3175,  3177,\n",
      "         4213,  8449,  9091, 10485, 10486, 11010, 12358, 12361, 12364, 12511,\n",
      "        13664, 13666, 15461]), tensor([7573, 8958, 9102, 9103]), tensor([  368,   370,  2468,  2827,  2829,  2833,  3377,  3378,  3582,  3585,\n",
      "         4631,  4634,  5060,  5061,  5101,  6002,  6039,  6040,  6523,  6525,\n",
      "         6536,  6839,  8671,  8673,  8763, 12850, 14218, 15677]), tensor([ 1479,  3462,  3463,  4483,  5127,  5647,  5871,  6059,  6606,  9000,\n",
      "         9691,  9692,  9693,  9694, 10073, 10826, 11324, 11325, 11327, 11352,\n",
      "        11353, 11404, 12367, 12848, 12849, 13575, 13637, 14267, 15876, 16245,\n",
      "        16619, 16620, 16621, 16632]), tensor([  735,   737,  1477,  1479,  3232,  5499,  6362,  6365,  7662,  7674,\n",
      "         9330,  9338, 11824, 12936, 12937, 13362, 14522, 14524, 14527, 14839,\n",
      "        15190]), tensor([ 1284,  1285,  2400,  2401,  2773,  2776,  2777,  2829,  2832,  3795,\n",
      "         6581,  7225,  7893, 12995, 13309, 13467, 15646, 15696, 15920, 16503,\n",
      "        16589, 16590, 16666]), tensor([ 2353,  2354,  2612,  3342,  5065,  6980, 10515, 11538, 15738, 16467]), tensor([  260,  1284,  1854,  1855,  2628,  2631,  3742,  5548,  6652,  6841,\n",
      "         6842,  7510,  8708, 10663, 12117, 12996, 13000, 13159, 13370, 13481,\n",
      "        13482, 15133, 15516, 15518, 16193]), tensor([ 2028,  2029,  2175,  2176,  6411,  6412,  6485,  8663,  8666,  9205,\n",
      "        11911, 11912, 12093, 12358, 12361, 12363, 12364, 12376, 12377, 15873]), tensor([  260,   262,  1374,  2391,  2466,  2467,  5193,  5493, 11988, 11990,\n",
      "        12010, 12367, 12815, 12817, 16193]), tensor([   63,   326,   327,  5240,  6844, 11008, 13953]), tensor([ 1062,  1865,  4059,  4062,  5500,  5501,  5503,  7362,  7946, 13078,\n",
      "        13342, 13345, 16413]), tensor([  263,  2027,  2237,  2238,  4476,  5215,  5218,  7636, 10603, 11008,\n",
      "        11009, 11326, 13271, 13272, 13669, 13954, 14265, 16180, 16598]), tensor([ 2226,  3232,  7260,  9330,  9338, 11920, 13078]), tensor([ 1227,  3373,  3376,  3427,  4408,  4518,  5816,  6766,  6767,  6950,\n",
      "         6952,  8235,  8237,  8780,  8848,  8849,  8868,  8960, 11901, 11902,\n",
      "        12221, 12222, 13085, 13480, 13481, 16771]), tensor([ 3373,  3374,  4250,  4252,  4253,  4454,  6727,  6728, 11744, 13481,\n",
      "        14678, 14679, 14685]), tensor([  360,   361,   728,   729,  2342,  2359,  2360,  2400,  3477,  5092,\n",
      "         5756,  6035,  7115,  7117,  7852,  7869,  7892,  7893,  7948,  8048,\n",
      "         8049, 10485, 10486, 10562, 10648, 10979, 11571, 12062, 12064, 12065,\n",
      "        12565, 14541, 14542]), tensor([ 2018,  2191,  7944,  7945, 11222, 11223, 11611, 11613, 11750, 13394,\n",
      "        14694, 14695, 15048, 15336, 16383]), tensor([ 3557,  3558,  5346,  5348,  8222,  8223,  9565,  9567, 10596, 10597,\n",
      "        10599, 11371, 11661, 11670, 11672, 11864, 12835, 12836, 13060, 13157,\n",
      "        13194, 13195, 13295, 15631, 16015, 16410, 16426, 16427, 16764]), tensor([  181,  2174,  2783,  4951,  5071,  7640,  7641,  8224,  8233,  8250,\n",
      "         8856,  9029, 10296, 12096, 13768, 13769, 14446]), tensor([ 2246,  2247,  2810,  3936,  5355,  6616,  7476,  7477,  8934,  9711,\n",
      "        11093, 11094, 11890, 13307, 13308, 13309, 13310, 13395, 13486, 13539,\n",
      "        13540, 13546, 13547, 13548, 14969, 16066, 16067]), tensor([  355,   366,  1229,  1231,  1456,  1705,  2151,  3936,  4952,  5169,\n",
      "         5170,  5528,  5529,  8233,  8874,  9604, 12361, 12364, 12575, 12580,\n",
      "        13079, 16464, 16465]), tensor([ 1377,  1423,  2139,  2140,  4534,  4592,  4593,  5708,  6574,  6575,\n",
      "         7366,  7367,  7702,  7703,  8262,  8265,  8676, 11171, 11417, 11425,\n",
      "        13637, 13638, 15276]), tensor([ 3358,  3361,  4488,  4976, 10368, 10370, 11596, 11597, 11692, 11696,\n",
      "        11698, 11728, 11740, 11761, 11823, 13394, 13398, 13982, 15048, 15480,\n",
      "        15483, 15948]), tensor([ 4793,  7673,  8542,  9673,  9681, 10864, 11517, 14984, 15736]), tensor([   58,   322,  1215,  2739,  6059,  7189,  7190, 11393, 12936, 12938,\n",
      "        12972, 13305]), tensor([ 2173,  2174, 10117, 16467]), tensor([ 1341,  1344,  2639,  2641,  3241,  3243,  6041,  6049,  6485,  6490,\n",
      "         6725,  8243,  8244,  8351,  8918,  9283,  9623, 13142, 14076, 14301]), tensor([ 1143,  1144,  1148,  1307,  1309,  5072,  8763, 12775, 15701]), tensor([ 1216,  4238,  4241,  5095,  5823,  6439,  6582,  6583,  7414,  8235,\n",
      "         8679,  8682, 11059, 11387, 11411, 11413, 11670, 11797, 11913, 13067,\n",
      "        13084, 14527, 14532, 14534, 14602, 14874, 15530]), tensor([ 2025,  2028,  2029,  2030,  4628,  4629,  5534,  7806,  7863, 10123,\n",
      "        13023, 13026, 13884, 13885, 14873, 14878]), tensor([ 3739,  3742,  4087,  5291,  7189,  7190,  7369,  7370,  7371,  7382,\n",
      "         7383,  7397,  7718,  8032,  8423, 12360, 15247]), tensor([   88,   139,   141,  1153,  1259,  1844,  1845,  2040,  2929,  4053,\n",
      "         5124,  5125,  5215,  5866,  5867,  5887,  5888,  6652,  7511,  9050,\n",
      "        10011, 10012, 10740, 11613, 11813, 12058, 12291, 12586, 12587, 12631,\n",
      "        12632, 12644, 12694, 13741, 13743, 13887, 13895, 15047]), tensor([ 1272,  1275,  1650,  3427,  4241,  6573,  6577,  7218,  7221,  8333,\n",
      "         8892,  8902,  8903, 11302, 11842, 11843, 13085, 14217, 14218, 15121,\n",
      "        15131, 15910, 15911]), tensor([  368,   370,  3654,  4477,  4938,  6859,  7631,  8095,  9142,  9737,\n",
      "         9786,  9787, 11351, 13244, 13245, 14218, 16070, 16071, 16425, 16670]), tensor([ 1228,  1231,  5217,  5492,  5530,  7415,  7721,  8249,  9244, 11848,\n",
      "        12221]), tensor([  338,   339,   731,   732,  1642,  3243,  3330,  4250,  4251,  6858,\n",
      "         6859,  8833, 12988]), tensor([  139,   141,  3343,  3344,  3853,  5540,  5615,  5619,  5771,  7478,\n",
      "         7480,  7908,  8514,  8518,  8928, 14785, 16443]), tensor([ 1145,  2338,  2389,  2697,  2792,  4192,  4633,  5344,  5345,  5437,\n",
      "         5542,  5618,  6031,  6597,  6682,  6683,  8112,  8708,  9352,  9353,\n",
      "        11369, 11912, 11947, 11948, 11949, 12516, 12563, 12615, 12642, 12916,\n",
      "        13118, 13349, 13376, 14351, 15273, 15679, 15717, 16008, 16010, 16398,\n",
      "        16482, 16483, 16692]), tensor([ 3282,  3284,  7832,  7833,  8863,  9003, 11426, 11427, 13597, 13598,\n",
      "        14795, 15104, 16759]), tensor([ 2358,  8884,  8885, 12046, 12047, 13336]), tensor([ 1713,  1714,  1770,  1907,  1909,  4525,  8225,  8230,  8326,  8346,\n",
      "         8838,  8851,  8852,  8879,  9895, 11452, 11454, 15101]), tensor([ 4037,  5885,  5888,  8088,  8089, 15656]), tensor([ 1272,  1273,  1376,  1377,  4487,  4533,  4534,  5707,  5708,  5746,\n",
      "         5747,  5748,  6105,  6106,  6141,  6496,  6498,  9472,  9473,  9618,\n",
      "         9627, 11436, 12054, 12055, 12065, 12066, 12375, 12376, 12440, 14729,\n",
      "        14730, 15342, 16011, 16244, 16289]), tensor([ 2392,  2395,  2398,  2775,  6495,  6496,  6507,  6509,  6746,  6752,\n",
      "         7051,  9680,  9681,  9691, 13918, 16423, 16424]), tensor([ 2395,  5060,  5061,  5101,  5212,  5214,  5485,  6002,  8083,  8084,\n",
      "        10694, 13063, 13920, 13927, 16138, 16387]), tensor([  144,   146,  1357,  4257,  7514,  7515, 12851, 12852, 13350, 15035,\n",
      "        16248]), tensor([ 4357,  4358,  5058,  5059,  8047,  8992,  8993, 12093, 12094, 15481,\n",
      "        16463, 16522]), tensor([   88,   141,  1402,  1434,  1854,  1856,  2010,  2011,  2625,  2626,\n",
      "         3948,  3950,  4215,  4530,  4532,  4627,  5827,  5828,  6678,  6875,\n",
      "         6876,  7257,  8222,  8225,  8229,  8995,  9132,  9565,  9566,  9568,\n",
      "        11019, 11038, 11039, 11911, 12570, 12571, 13467, 13576, 14006, 15301,\n",
      "        16425, 16443]), tensor([  65,   66, 1507, 1510, 1540, 1591, 5274, 5403, 6629, 7339, 7340]), tensor([  419,  1153,  2796,  2797,  2798,  2799,  2929,  6616,  7928,  7931,\n",
      "         8391,  8392,  8393,  9050,  9711, 11428, 11451, 12485, 12486, 12487,\n",
      "        14101, 14704, 14706, 16433, 16719]), tensor([ 3358,  3361,  3373,  4470,  4475,  4488,  4489,  4517,  5065,  5360,\n",
      "         5869,  6360, 16467]), tensor([ 3216,  6682,  6684,  6951,  6952,  8955,  9037,  9698,  9701, 11550,\n",
      "        13394, 14741, 15048, 16698]), tensor([ 1374,  1376,  1377,  4534,  4952,  5170,  5228,  5229,  5406,  5429,\n",
      "         5430,  5707,  5709,  5746,  5747,  5748,  6039,  6071,  6073,  6870,\n",
      "         6871,  7647, 10487, 11037, 11433, 11436, 11697, 11762, 12376, 12377,\n",
      "        13351]), tensor([ 5464,  5465,  6642,  6643,  6651,  9570,  9738, 11301, 13316, 14895,\n",
      "        15616, 16196, 16197, 16198]), tensor([ 4627,  4628,  5222,  5457,  6226,  6228,  7476,  7477,  7559,  7952,\n",
      "        10005, 12471, 12473, 12616, 12775, 13149, 13480, 13482, 15121]), tensor([   60,    61,    62,   258,   262,  3353,  4537,  4539,  6489,  8241,\n",
      "         9618, 10836, 12095, 12096, 13038, 16521]), tensor([  297,   310,  2124,  2205,  2206,  2208,  7007,  7008,  8088,  8089,\n",
      "         8124,  8126,  8423,  8835,  8877, 10689, 10690, 10834, 10965, 10966,\n",
      "        11001, 11003, 11004, 11005, 11051, 11055, 11056, 11761, 11885, 13584,\n",
      "        13883, 13884, 14876, 14877, 14950, 14952, 14953]), tensor([ 1649,  1650,  1769,  3317,  4106,  4209,  4212,  5942,  6710,  6711,\n",
      "         6917,  6920,  7949,  7950,  9567, 10125, 10126, 10473, 11852, 11853,\n",
      "        15871]), tensor([  14,  149, 1756, 1757, 3333, 3334, 3340, 4592, 5098, 8082, 8084, 8228]), tensor([ 1144,  1148,  1283,  1284,  1656,  2080,  2528,  2922,  5887,  6228,\n",
      "         6229,  8091,  8842,  8843,  8953,  9861, 12995, 13482, 13917, 14664,\n",
      "        15197, 16386]), tensor([ 3351,  3352,  4161,  4165,  4369,  6337,  6753,  7117,  7808,  7944,\n",
      "         7945,  8281,  9013,  9682,  9683, 11502, 12294, 12628, 12630, 13397,\n",
      "        14739, 15511]), tensor([  325,   326,   327,  3342,  3344,  4709,  5027,  5028,  5037,  5038,\n",
      "         5039,  5040,  5041,  5042,  5043,  5124,  5125,  5211,  5215,  5484,\n",
      "         5771,  5841,  5842,  5843,  5844, 12776, 13582, 13583, 15218, 16462]), tensor([ 2191,  5647,  8686,  8687,  9026, 10350, 10826, 15693, 15876, 16382,\n",
      "        16665]), tensor([ 2099,  2259,  2338,  9565,  9567,  9897, 10646, 10647, 10648, 12562,\n",
      "        12564]), tensor([ 2248,  2249,  3172,  3207,  8094,  8095,  8220,  8222,  8232,  9594,\n",
      "         9597,  9717, 15599, 16197]), tensor([  794,  1213,  1929,  1930,  1931,  2363,  2365,  5519,  6580,  6582,\n",
      "         6867,  6869,  7059,  7610,  8237, 10427, 10486, 11401, 12041, 12045,\n",
      "        12883, 13578, 14867, 15373, 15398, 15677, 16307]), tensor([  417,   419,  1489,  1491,  1856,  1857,  1869,  3653,  4193,  4533,\n",
      "         5405,  5699,  5755,  5757,  8382,  8384,  8503,  8991,  8992,  8993,\n",
      "         8994,  8995,  9076,  9077, 10595, 11359, 11764, 11866, 12988, 13056,\n",
      "        13057, 13195, 13546, 13547, 14073, 14074, 14077, 14209, 16756]), tensor([ 3556,  3558,  9979, 10740, 12305, 15253, 16037, 16038, 16428]), tensor([ 5004,  5007,  8771, 11452, 11454, 13063, 13394, 13637, 13639, 13927,\n",
      "        16244, 16245]), tensor([ 1659,  1854,  1856,  4193,  4194,  4249,  4252,  5431,  5533,  5534,\n",
      "         6142,  6477,  6640,  6656,  6724,  6726,  8228,  8994,  9619,  9624,\n",
      "         9626, 12516, 12694, 12748, 13894, 13895]), tensor([ 1215,  1216,  2338,  2339,  2439,  6588,  6589,  8750,  8751, 10077,\n",
      "        10604, 11071, 11072, 11411, 11413, 11693, 12562, 14894, 15463, 15629,\n",
      "        15657, 15861]), tensor([ 5347,  5348,  7210, 14005, 14006, 14007, 15091, 15203]), tensor([ 7055,  7902,  7903,  7907,  8855,  8856,  8897,  8899,  8952,  8954,\n",
      "         9030,  9534, 10485, 10487, 10694, 11177, 12816, 14738, 15911, 15972,\n",
      "        15983]), tensor([  182,  1375,  2334,  4014,  4211,  4222,  4223,  4880,  4953,  5983,\n",
      "         9976,  9993, 10213, 10485, 10486, 10515, 10823, 10826, 11483, 11485,\n",
      "        11812, 11813, 11848, 11849, 11850, 11851, 11854, 12839, 13024, 14728,\n",
      "        15326, 15518, 15536, 15537, 16037]), tensor([ 1538,  2395,  2398,  5060,  5099,  5100,  5101,  5131,  5141,  5230,\n",
      "         5231,  5274,  5353,  5354,  6002,  6962,  7550, 10703, 11821, 11948,\n",
      "        15273]), tensor([ 1244,  1245,  1856,  4193,  5948,  5949,  6591,  8991,  8992,  8994,\n",
      "         8996, 12816, 12817, 12938, 13017, 13160, 15177]), tensor([ 2628,  6052,  6200,  6838,  6839,  7056,  7218, 11925, 11926, 12842,\n",
      "        13253, 13376, 13486, 13523, 14342, 14343, 14532, 14534, 14981, 15835,\n",
      "        15836, 15838, 16142]), tensor([ 1648,  1649,  1650,  3377,  3712,  3716,  5456,  5457,  5821,  5822,\n",
      "         8094,  8243,  8244,  9623, 12779, 15979, 16000]), tensor([ 1539,  5091,  5092,  5095,  5409,  5410,  5411,  5412,  5413,  5823,\n",
      "         6489,  7116,  9654, 12096, 13023, 13067, 14873]), tensor([ 2158,  4227,  4253,  5786,  6523,  6524,  9000,  9534,  9693,  9694,\n",
      "        10825, 10826, 11178, 11354, 16594]), tensor([ 2114,  2116,  4217,  5466,  6059,  6060,  6061,  6062,  6063,  6607,\n",
      "         6769,  7081,  7082,  8076,  8094,  8200, 11772, 12847, 12848, 12849,\n",
      "        14109, 14540]), tensor([ 5037,  5038,  5039,  5041,  5042,  5043,  5124,  5125,  5841,  5842,\n",
      "         5843,  5844,  6070, 11612, 11613, 12831, 13307, 13310, 13583, 16066]), tensor([ 2795,  5043,  9565,  9895, 10500, 11349, 11353, 11404, 13103, 13104,\n",
      "        13768, 13769, 14265, 15283, 16597, 16598]), tensor([   60,    61,   416,   418,  2395,  2397,  2405,  4189,  4214,  5100,\n",
      "         5101,  5355,  5356,  5357,  5358,  5500,  5501,  5502,  6505,  7361,\n",
      "         7362,  8288,  8609,  9616,  9618,  9622, 11093, 11095, 11112, 11120,\n",
      "        11841, 13394, 14727, 14728, 14969, 15048, 16428, 16429, 16468]), tensor([ 3379,  5099,  5100,  5353,  6606, 10073, 10178, 14207, 14995, 15011,\n",
      "        16383, 16385, 16388]), tensor([ 1394,  3069,  4533,  5218,  6487,  7050,  7052,  7477,  7478, 10079,\n",
      "        11014, 11015, 11162, 12093, 12152, 12391, 12936, 12937, 12938, 13140,\n",
      "        13141, 15721, 15916, 16193, 16522]), tensor([   60,  1805,  1807,  1869,  5253,  5257,  5464,  6642,  6769,  7941,\n",
      "         7995,  9593,  9622,  9623, 11548, 14208, 15428, 15777, 15780, 15833,\n",
      "        15834]), tensor([ 3329,  5032,  5033,  5098,  6656, 12223, 12224, 12229, 13743]), tensor([ 1459,  5154,  6257,  8929,  8930, 10372, 10373, 10383, 10384, 10386,\n",
      "        11547, 11548, 14072, 14073, 14074, 14939, 15001, 15070]), tensor([ 1431,  2078,  2080,  2923,  2924,  6822,  6824, 11039, 11088, 11529]), tensor([ 1245,  1736,  1871,  1872,  3242,  3243,  4955,  4956,  6429,  6430,\n",
      "         6629,  6711,  8675,  8676, 10656, 11879, 11880, 11943, 15326, 15820]), tensor([   59,  1809,  1810,  4360,  6158,  6160,  6414,  8816,  8817,  8819,\n",
      "        11746, 11765, 12210, 12780, 12782, 15323, 15325, 16544]), tensor([ 1175,  1198,  1199,  2148,  2150,  2741,  2742,  6198,  6324,  6634,\n",
      "         6635,  6708,  8198,  8199,  8317, 11454, 11455, 11761, 14779, 15101,\n",
      "        15677, 16381, 16465]), tensor([ 1410,  4106,  5202,  5210,  5398,  5530,  6626,  6627,  6680,  6846,\n",
      "         6847,  7257,  8800,  8801,  8887,  9245, 11001, 14425, 15134]), tensor([   12,   352,   354,  2706,  4106,  4107,  4217,  5037,  5212,  5215,\n",
      "         5406,  5442,  5464,  6038,  6642,  7678,  7849,  9252,  9564, 13908]), tensor([ 2788,  2791,  4154,  4349,  5143,  5714,  5715,  5717,  8106, 11706,\n",
      "        11828, 12376, 13019, 13020, 15188, 15886, 16712]), tensor([ 4534,  5707,  6743,  8106, 10386, 14072, 14074, 15188]), tensor([  356,   357,  1649,  6746,  6750, 12832, 12833, 15877, 16381]), tensor([  935,   938,   939,  4359,  5100,  5101,  5207,  5354,  6002,  6104,\n",
      "         6106, 13159, 13441, 13481, 13482, 13583, 16244, 16509]), tensor([ 1230,  1344,  1929,  1931,  2391,  2392,  2396,  2398,  6587,  6588,\n",
      "         8220,  8223,  9501,  9502,  9503,  9570, 15635, 15636, 15729, 16138,\n",
      "        16197, 16198])]\n"
     ]
    }
   ],
   "source": [
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 5218,   260,   263, 12872,  2799]]), tensor([[ 4153,  4154,  5714,  5716, 14795]]), tensor([[6637, 5403,   -1,   -1,   -1]]), tensor([[12091, 12089,  9281,    -1,    -1]]), tensor([[ 898,  897, 3166,  908,  910]]), tensor([[ 2998, 10792,  3115,  3116,  3056]]), tensor([[4360, 1023, 1024, 9247, 9156]]), tensor([[10134,  3384,  3382, 13377, 16166]]), tensor([[16167, 16156,  5765,  5768, 12908]]), tensor([[ 4369,  4294,  4295, 13413,  4274]]), tensor([[ 3056,  3116,  3115, 10792,  2998]]), tensor([[8936, 4271,  798,  800, 9432]]), tensor([[ 8936, 14334,  4107,    -1,    -1]]), tensor([[  830,   829,  9025,  9026, 15049]]), tensor([[ 2079,  2080,  2922,  6474, 11890]]), tensor([[10384,  5334,  5333, 10606, 10604]]), tensor([[ 2079,  9331,  9329, 11175,  5776]]), tensor([[14452, 16727, 16026, 13057,  2363]]), tensor([[ 1100,  1103,  4329,  4330, 15781]]), tensor([[11021, 11020,  9786,  9737,  9140]]), tensor([[  803, 11423, 12022, 12020, 14401]]), tensor([[ 4329,  4328, 16434, 15833, 15777]]), tensor([[11423,   803,   801,  5306, 15746]]), tensor([[10135, 10134,  1101,  1103,  4329]]), tensor([[15871, 10697, 10644,    -1,    -1]]), tensor([[10402, 13143, 10386, 10384,  5334]]), tensor([[ 1408,  1410,  4107, 14334,  8936]]), tensor([[ 5292,  5291,  8421, 13253,  8708]]), tensor([[ 4223,  4880,   793,   794, 12245]]), tensor([[ 2150,  2148, 15813, 15755,  4327]]), tensor([[15813,  2148,  2150,  3000,  3059]]), tensor([[11936, 15787, 15846, 15754,  4327]]), tensor([[5965, 5964, 1421, 1417, 1419]]), tensor([[6875, 6900, 5336, 4594, 1418]]), tensor([[12136,  9117,  2106,  2108,  2180]]), tensor([[6709, 5709, 1376, 1375, 6615]]), tensor([[12102, 12100,  4589,  4586, 10998]]), tensor([[4587, 9350, 9349, 9259, 9133]]), tensor([[14340,  4329,  4330, 14576,    -1]]), tensor([[ 4252,  5063,  5065, 11536, 11537]]), tensor([[ 5364,  5361, 16365,  9563,  6038]]), tensor([[10100,  6484,  4458,    -1,    -1]]), tensor([[4329,   -1,   -1,   -1,   -1]]), tensor([[4329, 1103, 1100, 3395, 3396]]), tensor([[ 5765, 15220, 15219, 13382,  3388]]), tensor([[-1, -1, -1, -1, -1]]), tensor([[5709, 1376, 1375, 6615, 6616]]), tensor([[ 3396,  9628, 13377, 16167, 16156]]), tensor([[16167, 13377,  3382,  3384, 10134]]), tensor([[12102, 12100,  4589,  4587,  9350]]), tensor([[ 4882, 15313, 15312,  5303,  5304]]), tensor([[15562,  5526,  5461,  5462,  5068]]), tensor([[ 6976,  6977, 12298, 13780, 13456]]), tensor([[12298,  6977,  6976,  5711,  5712]]), tensor([[    6,     7, 16319, 10509, 10511]]), tensor([[5323, 5321,   -1,   -1,   -1]]), tensor([[12102, 12100, 14506,  3558,  3557]]), tensor([[8392, 8391, 6616, 6615, 1375]]), tensor([[14349, 14748,  2573,  2571,  2524]]), tensor([[11000, 14860, 10980,  6869,  6868]]), tensor([[ 126,  124, 6774,   -1,   -1]]), tensor([[8917, 9326, 9327, 3970, 3968]]), tensor([[10139, 12877,    -1,    -1,    -1]]), tensor([[ 1198,  1200,  7071,  7072, 15210]]), tensor([[10507, 12796,  7303,  7302,  9299]]), tensor([[ 5302,  5303, 15312, 15313,  4882]]), tensor([[ 4882, 15313, 15312,  5303,  5304]]), tensor([[10977, 10980,  6869,  6868,  6870]]), tensor([[1376, 1375, 6615, 6616, 8391]]), tensor([[14896, 12667, 12666, 12818,  1611]]), tensor([[  911, 16354, 16355, 14559,  1615]]), tensor([[6867,   -1,   -1,   -1,   -1]]), tensor([[15929, 12799,  5336,  4594,  1418]]), tensor([[5323, 5322,   -1,   -1,   -1]]), tensor([[12102, 12101, 13201, 13200,  3556]]), tensor([[11021, 16426, 16427,  5295,  5297]]), tensor([[ 3174,  6874,  6873, 10487, 15929]]), tensor([[ 3173, 11396,  5607,  5606, 12790]]), tensor([[ 5230,  5233,  4354,  4353, 10592]]), tensor([[7262, 6588, 6589, 2403, 2402]]), tensor([[13080, 12530, 12532, 11829,  4809]]), tensor([[14712,  5972,  5971,  6242, 10058]]), tensor([[6876, 9133,   -1,   -1,   -1]]), tensor([[15929, 12799,  5336,  4594,  1418]]), tensor([[5323, 5322,   -1,   -1,   -1]]), tensor([[12102, 12100,  4589,  4587,    -1]]), tensor([[-1, -1, -1, -1, -1]]), tensor([[  260,   263, 12872, 12486, 12487]]), tensor([[10998, 11000, 14860, 10980,  6869]]), tensor([[ 5304, 13329,  4618,  1488,  1489]]), tensor([[7901, 7899, 4953, 4951, 5071]]), tensor([[ 5337,  5865,  5866, 12291,  5316]]), tensor([[ 5865,  5337,  5335,  5336, 12799]]), tensor([[16434, 15833, 15777, 15775, 10301]]), tensor([[10472,  3069,  3071, 10516,  5301]]), tensor([[ 1489,  5755,  5757, 15929, 10487]]), tensor([[9259, 9349, 9350, 4587, 4588]]), tensor([[14260, 14324, 14333, 14235,  9999]]), tensor([[4587, 9350, 9349, 9259, 9260]]), tensor([[10741, 10740,  5757,  5755,  1489]]), tensor([[14590,    -1,    -1,    -1,    -1]]), tensor([[ 5226,  5224,  6200, 15835,  6052]]), tensor([[ 3071, 10516,  5301,  4042,  4040]]), tensor([[11988, 12010, 11496, 11494,    -1]]), tensor([[ 6684,  6686, 13744, 15406,  4743]]), tensor([[ 6522,  6523,  8634, 16487, 16486]]), tensor([[ 5949, 11652, 11697, 11699,  9560]]), tensor([[11154,  5608,  5605,  5479,  5480]]), tensor([[3207, 9594, 9596, 3173, 3174]]), tensor([[5772, 4979, 1898, 1901, 5316]]), tensor([[11890,  6474,  2922,  2924, 11528]]), tensor([[ 7975, 13067, 11095,  7361,  7362]]), tensor([[ 4985,  5326,  7975, 13067, 11095]]), tensor([[7260, 5503, 5356, 5358, 6200]]), tensor([[ 6335, 15894,  7107,  3966,  3965]]), tensor([[ 3231, 15819,  9329,  9331,  2079]]), tensor([[11401,  1882,  1884,  7711,  6960]]), tensor([[ 7052,  7050, 11194, 11428,  5401]]), tensor([[7118, 4529, 4527, 4528, 8262]]), tensor([[ 3171,  5475, 15920,    -1,    -1]]), tensor([[10487,  6873,  6874,  3174,  3173]]), tensor([[7118, 4529, 4527, 4525, 8507]]), tensor([[11652, 11697, 11699,  9560,  9561]]), tensor([[1615, 1610, 1609, 4798, 3932]]), tensor([[ 1433,  1430,  5220,  5222, 12775]]), tensor([[ 5932,  5929, 13641,  8277,  8279]]), tensor([[11156, 11155, 11154,  5608,  5605]]), tensor([[12291,  5866,  5865,  5337,  4595]]), tensor([[ 5755,  1489,  1488,  4618, 13329]]), tensor([[15912, 15915, 15916,  3069,  3071]]), tensor([[2529, 3030,   -1,   -1,   -1]]), tensor([[ 7808,  7806, 10676, 13429,  5022]]), tensor([[9350, 4587, 4588, 4811, 4814]]), tensor([[13072, 13073,  1422,  1423,  4595]]), tensor([[ 6874,  3174,  3173, 11396,  5607]]), tensor([[11348, 11323, 11322, 16595, 16719]]), tensor([[ 3173,  3174,  6874,  6873, 10487]]), tensor([[ 6869,  6868,  6870, 15929, 10740]]), tensor([[7647, 7646, 8507, 4525, 4527]]), tensor([[3174, 3171, 5475, 2776, 2775]]), tensor([[11396,  3173,  3174,  6874,  6873]]), tensor([[-1, -1, -1, -1, -1]]), tensor([[ 3171,  5475, 15920,  2784,  2787]]), tensor([[ 4527,  4525,  8507, 11037, 13351]]), tensor([[12202, 12201, 16505,  9560,  9562]]), tensor([[11396,  5607,  5606, 12790, 10511]]), tensor([[-1, -1, -1, -1, -1]]), tensor([[10978, 10976, 10884, 10883, 16301]]), tensor([[ 4353, 10592, 10593, 11448, 10881]]), tensor([[ 3173, 11396,  5607,  5606, 12790]]), tensor([[ 8507,  7646,  7647, 14880,    -1]]), tensor([[8729, 8728, 4707, 2210, 2209]]), tensor([[ 3173, 11396,  5607,  5606, 12790]]), tensor([[ 177,  532, 3030, 2529, 2530]]), tensor([[4158, 3109, 3108, 7550, 5230]]), tensor([[12356, 10314,  9422,  9423,  8480]]), tensor([[ 6683,  2812,  2811, 11809,  7329]]), tensor([[ 5403,  5402, 11426, 15104, 10126]]), tensor([[6589, 2403, 2402, 2359, 2358]]), tensor([[  520,   521, 15380, 13929, 13933]]), tensor([[519,  -1,  -1,  -1,  -1]]), tensor([[10595,  8382,  8383,  7052,  7050]]), tensor([[8885, 2358, 2361,  180,  181]]), tensor([[ 5323,  5317,  5318, 12106, 12104]]), tensor([[10398,  8276,  8278,  5742,  4652]]), tensor([[ 4349, 11156, 11155, 11154,  5608]]), tensor([[12202, 12201, 16505,  9560,  9562]]), tensor([[1713, 8844, 8845, 8948, 8947]]), tensor([[ 1423,  4595,  5335,  5336, 12799]]), tensor([[ 5402, 11426,    -1,    -1,    -1]]), tensor([[11194,  7050,  7051, 13918,    -1]]), tensor([[11454, 11452, 11427,  5402,  5401]]), tensor([[5401, 5403, 6637,   -1,   -1]]), tensor([[ 7050,  7052,  8383,  8382, 10596]]), tensor([[  261,   262,  4537,  4539, 12848]]), tensor([[10604, 10606, 12536,  8667,  8663]]), tensor([[12636,  5619,  5617, 16539, 16116]]), tensor([[9541, 9527, 9526, 9434, 7905]]), tensor([[ 2340, 12517, 12516,  4194,  1857]]), tensor([[10647, 10644, 10697, 11853,  7949]]), tensor([[2251, 2254, 7003, 5038, 5043]]), tensor([[ 2142,  2140,  5770, 16705, 16729]]), tensor([[6442, 7647, 7646, 8507, 4525]]), tensor([[6615, 1375, 1376, 5709, 6709]]), tensor([[10386, 10384,  5334,  5331,    -1]]), tensor([[  856,   987, 12232,  6730,  5570]]), tensor([[4539, 4540,  258,  259,  418]]), tensor([[ 856,  857, 1263, 1264, 1000]]), tensor([[ 426,  429, 2229, 2227, 3269]]), tensor([[ 5463,  5460, 13082,  5099,  5060]]), tensor([[10644, 10646, 12515,  4194,  4192]]), tensor([[4265, 4268, 6318, 6319, 4278]]), tensor([[4628,   -1,   -1,   -1,   -1]]), tensor([[ 5241,  2251,  2254,  7003, 13582]]), tensor([[ 5776, 11173, 11172,  7564,  7566]]), tensor([[ 6441,  6444,  5950,  5948, 15177]]), tensor([[ 7950,  7949, 11852, 11869, 11437]]), tensor([[12564, 12565, 10648, 10645, 10649]]), tensor([[ 9691,  6522,  6523,  8634, 16487]]), tensor([[ 5207,  5208,  5429,  5431, 12748]]), tensor([[12713,  9666,  5580,  5581,  5374]]), tensor([[ 5328, 11149,  7114,  7115,  7948]]), tensor([[6652, 6650, 6653, 6654, 8990]]), tensor([[  242,   240,  4653, 16452,  6779]]), tensor([[13211,  6256,  3965,  3966,  7105]]), tensor([[11243, 11237, 11240,    -1,    -1]]), tensor([[11769, 11409, 11369,  6682,  6683]]), tensor([[ 6077, 11989, 11247, 11248, 11243]]), tensor([[9662, 5051, 5048, 5372, 9453]]), tensor([[16443,  4627,  4628,  2360,  2359]]), tensor([[6688, 4224, 4223, 4880,   -1]]), tensor([[11535,  4982,    -1,    -1,    -1]]), tensor([[6589, 6588, 7262, 7260, 5503]]), tensor([[16705,  5770,  2140,  2143,  5325]]), tensor([[-1, -1, -1, -1, -1]]), tensor([[-1, -1, -1, -1, -1]]), tensor([[14302, 10307, 10306, 14301,  9283]]), tensor([[-1, -1, -1, -1, -1]]), tensor([[ 8908, 13144,  6018,  6019, 10385]]), tensor([[ 8663,  8669, 12517, 12516, 12515]]), tensor([[ 6046,  7909, 16443,  7952,  7951]]), tensor([[4189,  416,  417, 5406, 6038]]), tensor([[11809,  7329,  7332,  4984,  4985]]), tensor([[5254, 5253, 4709, 2142, 2140]]), tensor([[13190, 16440,  5297,  5295, 16427]]), tensor([[16469,  5434,  5079,  5076,  5151]]), tensor([[7254, 7251, 7252, 4231, 4230]]), tensor([[ 9331,  9329, 11175,  5776,  5777]]), tensor([[10368, 15948,  1396,  1356,  1358]]), tensor([[8994, 8991, 5746, 5707, 5708]]), tensor([[2174, 5242, 5241, 2251, 2254]]), tensor([[13596,  6768,  6766,  4408,  4409]]), tensor([[ 6335, 15894,  7107,  3966,  3965]]), tensor([[11297, 11298,  5431,  5429,  6053]]), tensor([[11692, 11824, 16601, 11413, 11412]]), tensor([[5709, 1376, 1375, 6615, 6616]]), tensor([[5364, 1424, 1428, 1432, 1435]]), tensor([[1479, 1478, 4516, 4517, 6831]]), tensor([[5410, 5411, 9661, 5051, 5048]]), tensor([[4192, 1857, 1854, 8670, 8671]]), tensor([[7003, 5038, 5040, 5535, 5492]]), tensor([[9000, 8997, 1363, 1361, 1358]]), tensor([[6917, 6916,  429,  427, 6920]]), tensor([[7559, 1395, 1356, 1358, 1361]]), tensor([[14267,  9000,  8997,  4841,  4843]]), tensor([[ 9000, 14267, 16423, 16424, 16719]]), tensor([[ 5533, 12748, 11298, 11297,  2252]]), tensor([[ 5254,  5256, 10193,  5372,  5048]]), tensor([[5405, 6536, 6537, 5483, 5484]]), tensor([[4582, 5059, 5058, 5036, 5034]]), tensor([[1335, 1336, 8022, 8021, 8027]]), tensor([[6040, 6536, 6537, 5483, 5484]]), tensor([[ 6335, 15894,  7107,  3966,  3965]]), tensor([[13253,  8708,  4192,  1857,  1854]]), tensor([[ 6583,  6582,  2449,  2450, 14739]]), tensor([[ 8994,  8991,  5746,  5747, 11437]]), tensor([[13927, 13944,  8018,  8016,  8015]]), tensor([[11353,  9694,    -1,    -1,    -1]]), tensor([[5121, 1455, 1457, 3714, 3715]]), tensor([[ 3599, 10774, 14130,  1538,  1540]]), tensor([[10368, 15948,  1396,  1356,  1358]]), tensor([[ 6522,  6525,  5463,  5460, 13082]]), tensor([[ 1361,  1358,  1356,  1396, 15948]]), tensor([[11989,  6077,  6079,  6686,  6685]]), tensor([[4743, 4745, 6656, 6640, 3339]]), tensor([[11693, 11239, 11240,    -1,    -1]]), tensor([[11996, 11994, 13741,  3338,  3339]]), tensor([[4194, 1857, 1854, 8670, 8671]]), tensor([[  260,   263, 12872, 12486, 12485]]), tensor([[ 1308,  5362,  5364, 16469,  5434]]), tensor([[ 7362, 13078, 13079, 15845,  6199]]), tensor([[ 5043,  5039,  5211,  5208, 11296]]), tensor([[ 5099, 13082,  5460,  5463,  6525]]), tensor([[15623, 10841, 10498, 10499, 10507]]), tensor([[ 6525,  5463,  5460, 13082,  5493]]), tensor([[2360, 2359, 2402, 2403, 6589]]), tensor([[ 4084,  2486,  2485, 16413,  1865]]), tensor([[12138, 11372, 11370, 11580,  6443]]), tensor([[5038, 5043, 7002, 7007, 8392]]), tensor([[ 416,  417, 5405, 6536, 6537]]), tensor([[5429, 6053, 5535, 5492, 5493]]), tensor([[7107, 7105,   -1,   -1,   -1]]), tensor([[10368,  7558,  7482,  7481, 13212]]), tensor([[11299,  9243,  7589,  7590, 10384]]), tensor([[9281,   -1,   -1,   -1,   -1]]), tensor([[ 4084,  2486,  2485, 16413,  1865]]), tensor([[10384,  5334,  5333, 10606, 10605]]), tensor([[11243, 11248, 11247, 12088, 12005]]), tensor([[13067,  7975,  5326,  4985,  4984]]), tensor([[ 941,  942, 1896, 1897, 8452]]), tensor([[15248,  1217,  1220,  1876, 14299]]), tensor([[5757, 5755, 1489, 1488, 4618]]), tensor([[5709, 1376, 1375, 6615, 6616]]), tensor([[13244,  9142,  9141,  9078,  9075]]), tensor([[15104,    -1,    -1,    -1,    -1]]), tensor([[8186, 8626, 6126, 6124, 6010]]), tensor([[ 1433,  1430,  5220,  5222, 12775]]), tensor([[ 5344, 12616, 12775,  1309,  1308]]), tensor([[11426, 15104, 15105, 15873, 15871]]), tensor([[11735,  2732,  1373,  1376,  5709]]), tensor([[1198, 7006, 9753, 6846, 6844]]), tensor([[ 4633,  4634,  6105,  6106, 13639]]), tensor([[1376, 1375, 6615, 6616, 8391]]), tensor([[10829, 10828, 12538,  4031,  4029]]), tensor([[ 5060,  5099, 13082,  5460,  5463]]), tensor([[11056, 11004,    -1,    -1,    -1]]), tensor([[ 8993,  4193,  4192,  8708, 13253]]), tensor([[ 2026,  2027, 10603,  2238,  2237]]), tensor([[10697, 10644, 10645,  8993,  4193]]), tensor([[ 2799,  2797, 13027,  2793,  2759]]), tensor([[ 6160, 11746, 11764, 10602,  5845]]), tensor([[10645, 10646,    -1,    -1,    -1]]), tensor([[5707, 5746, 8991, 4193, 4192]]), tensor([[16198, 16196, 13215,  9605,  9603]]), tensor([[ 5401,  5402, 11426, 15104, 10126]]), tensor([[  260,   263, 12872,  2799,  2797]]), tensor([[ 4707,  2210,  2209, 16030, 11373]]), tensor([[ 4209, 13244,  9142,  9141,  9078]]), tensor([[ 2394, 16109, 10194,  9453,  5769]]), tensor([[2922, 2080, 2079, 9331, 9329]]), tensor([[12294, 13427,   957,   903,   905]]), tensor([[5041, 5043, 7002, 7007, 8392]]), tensor([[ 5708, 11854,  4212,  4210, 11019]]), tensor([[ 5707,  5708, 11854,  4212,  4209]]), tensor([[6815, 6832, 3606, 3607, 1721]]), tensor([[ 9011, 15280, 15465, 15999,  1656]]), tensor([[  417,  5406,  6038,  9563, 16365]]), tensor([[10741, 10740,  5757,  5755,  9130]]), tensor([[15104,    -1,    -1,    -1,    -1]]), tensor([[10644, 10646, 12515,  4194,  1857]]), tensor([[11535,  4982,  4985,  5328,  5777]]), tensor([[4031, 4029, 2699, 2696, 8967]]), tensor([[10656,  6637,  6636,  7950, 10126]]), tensor([[15326,  4211,  4209, 13244, 13245]]), tensor([[ 5100,  5060,  5062,  6199, 15845]]), tensor([[8994, 4193, 4192, 4633, 4634]]), tensor([[ 6200,  5534,  5533, 12748, 11298]]), tensor([[ 8075,  8094, 11772,  2760,  2761]]), tensor([[ 7332,  7329, 11809,    -1,    -1]]), tensor([[10697, 10644, 10645,  8993,  4193]]), tensor([[2026, 2029, 2034, 6584, 6585]]), tensor([[ 5041,  5042,  5073, 10056,    -1]]), tensor([[ 5431, 12748,  5533,  5225,  5229]]), tensor([[8609, 8608,  180,  179, 9086]]), tensor([[ 9354, 11199,  3637,  3640,  7891]]), tensor([[10257,  8056,  8057, 10255, 15428]]), tensor([[16118, 16587, 14592, 14591, 10142]]), tensor([[3329, 3326, 3327, 7331, 7330]]), tensor([[10386, 10384,  7590,  7589,  9243]]), tensor([[4532, 4531, 7908, 7982, 2401]]), tensor([[1872, 4955,   -1,   -1,   -1]]), tensor([[8816, 4360, 1023, 1024, 9247]]), tensor([[15777, 15775, 10301, 10300, 10381]]), tensor([[ 4106,  1410,  1408, 14590,    12]]), tensor([[ 4107, 14334,  8936,  4271,   798]]), tensor([[-1, -1, -1, -1, -1]]), tensor([[ 5717, 11295,    -1,    -1,    -1]]), tensor([[ 2148,  2150,  2998, 10792,  3115]]), tensor([[ 939,  938, 5689, 8447,   -1]]), tensor([[  928,   921,   919,   924, 16353]])]\n"
     ]
    }
   ],
   "source": [
    "print(ground_truth_fut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fut_ratio(sample_list, ground_truth_fut):\n",
    "    \"\"\"\n",
    "    Calculates the ratio of samples in `sample_list` that have at least n edges in common with the ground truth future trajectory for each n up to future_len.\n",
    "\n",
    "    Args:\n",
    "        sample_list (list): A list of samples.\n",
    "        ground_truth_fut (list): A list of ground truth future trajectories.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are the minimum number of common edges (from 1 to future_len) and values are the ratios of samples meeting that criterion.\n",
    "    \"\"\"\n",
    "    # Initialize counts for each number of common edges from 1 up to future_len\n",
    "    counts = {i: 0 for i in range(1, 5 + 1)}\n",
    "    total = len(sample_list)\n",
    "\n",
    "    for i, sample in enumerate(sample_list):\n",
    "        # Convert tensors to lists if they are indeed tensors\n",
    "        sample = sample.tolist() if isinstance(sample, torch.Tensor) else sample\n",
    "        ground_truth = ground_truth_fut[i].flatten().tolist()\n",
    "        \n",
    "        edges_count = sum(1 for edge in ground_truth if edge in sample)\n",
    "        for n in range(1, min(edges_count, 5) + 1):\n",
    "            counts[n] += 1\n",
    "\n",
    "    ratios = {n: counts[n] / total for n in counts}\n",
    "    return ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [torch.tensor([ 5, 1, 10, 12, 13, 18]), torch.tensor([ 1, 4, 5, 2, 10]), torch.tensor([  5, 8, 9, 11, 10])]\n",
    "ground_truth_fut = [torch.tensor([[ 5,   1,   10, 12,  13]]), torch.tensor([[ 1,  4,  5,  2, 10]]), torch.tensor([[5, 8,   -1,   -1,   -1]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1.0,\n",
       " 2: 1.0,\n",
       " 3: 0.6666666666666666,\n",
       " 4: 0.6666666666666666,\n",
       " 5: 0.6666666666666666}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_fut_ratio(samples, ground_truth_fut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1000000000.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def masked_cross_entropy(logits, target, mask):\n",
    "    \"\"\"\n",
    "    Compute cross-entropy loss for only the neighbors specified in the mask.\n",
    "\n",
    "    Args:\n",
    "        logits (torch.Tensor): The raw logits output from the model (batch_size x num_classes).\n",
    "        target (torch.Tensor): The target class indices (batch_size).\n",
    "        mask (torch.Tensor): A binary mask (batch_size x num_classes) where 1 indicates a neighbor\n",
    "                             and 0 indicates a non-neighbor.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The computed masked cross-entropy loss.\n",
    "    \"\"\"\n",
    "    # Set non-neighbors in logits to a large negative value, effectively zero after softmax\n",
    "    masked_logits = logits + (mask * -1e9)  # Using -1e9 to mask non-neighbors\n",
    "\n",
    "    # Compute cross-entropy loss using the modified logits\n",
    "    return F.cross_entropy(masked_logits, target)\n",
    "\n",
    "# Example usage\n",
    "batch_size = 3\n",
    "num_classes = 5\n",
    "\n",
    "# Random logits\n",
    "logits = torch.randn(batch_size, num_classes)\n",
    "\n",
    "# Target indices\n",
    "targets = torch.tensor([0, 2, 1])\n",
    "\n",
    "# Mask: 1 for valid neighbors, 0 for non-neighbors\n",
    "mask = torch.tensor([\n",
    "    [1, 0, 1, 0, 0],\n",
    "    [1, 0, 1, 0, 0],\n",
    "    [0, 1, 0, 1, 0]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Calculate loss\n",
    "loss = masked_cross_entropy(logits, targets, mask)\n",
    "print(\"Loss:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

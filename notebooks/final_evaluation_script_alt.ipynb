{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for multiple future lengths with different settings\n",
    "folder = '/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/experiments'\n",
    "dataset = 'geolife'  # Common dataset for all configurations\n",
    "test = True\n",
    "history = 5\n",
    "conditional = True  # Set to True if using conditional future lengths\n",
    "\n",
    "# List of configurations, one per future length\n",
    "configurations = [\n",
    "    {\n",
    "        'future_len': 0,\n",
    "        'conditional_fut_len': None,\n",
    "        'model': 'residual',\n",
    "        'features': 'one_hot_edges_coordinates_pos_encoding_pw_distance_edge_length_edge_angles_num_pred_edges_future_len',\n",
    "        'transition_matrix': 'custom',\n",
    "        'noising': 'cosine',\n",
    "    },\n",
    "    {\n",
    "        'future_len': 0,\n",
    "        'conditional_fut_len': None,\n",
    "        'model': 'residual',\n",
    "        'features': 'one_hot_edges_coordinates_pos_encoding_pw_distance_edge_length_edge_angles_num_pred_edges_future_len',\n",
    "        'transition_matrix': 'custom',\n",
    "        'noising': 'cosine',\n",
    "    },\n",
    "]\n",
    "#one_hot_edges_coordinates_pos_encoding_pw_distance_edge_length_edge_angles_num_pred_edges\n",
    "\n",
    "# Ensure that only one of 'future_len' or 'conditional_fut_len' is set per configuration\n",
    "for config in configurations:\n",
    "    if conditional:\n",
    "        config['future_len'] = None\n",
    "    else:\n",
    "        config['conditional_fut_len'] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1818895/4088672273.py:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sample_list = torch.load(f'{base_path}/{prefix}fut_len_{fut_len}_samples_one_shot_{file_suffix}.pth')\n",
      "/tmp/ipykernel_1818895/4088672273.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  valid_ids = torch.load(f'{base_path}/{prefix}fut_len_{fut_len}_valid_ids_{file_suffix}.pth')\n",
      "/tmp/ipykernel_1818895/4088672273.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  samples_raw = torch.load(f'{base_path}/{prefix}fut_len_{fut_len}_samples_raw_{file_suffix}.pth')\n",
      "/tmp/ipykernel_1818895/4088672273.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  samples_valid = torch.load(f'{base_path}/{prefix}fut_len_{fut_len}_samples_valid_{file_suffix}.pth')\n",
      "/tmp/ipykernel_1818895/4088672273.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ground_truth_hist = torch.load(f'{base_path}/{prefix}fut_len_{fut_len}_gt_hist_{file_suffix}.pth')\n",
      "/tmp/ipykernel_1818895/4088672273.py:35: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ground_truth_fut = torch.load(f'{base_path}/{prefix}fut_len_{fut_len}_gt_fut_{file_suffix}.pth')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "res_dict = {}\n",
    "\n",
    "for idx, config in enumerate(configurations):\n",
    "    model = config['model']\n",
    "    features = config['features']\n",
    "    transition_matrix = config['transition_matrix']\n",
    "    noising = config['noising']\n",
    "    future_len = config['future_len']\n",
    "    conditional_fut_len = config['conditional_fut_len']\n",
    "\n",
    "    if conditional:\n",
    "        fut_len = conditional_fut_len\n",
    "        prefix = 'cond_'\n",
    "        if test:\n",
    "            prefix = 'test_' + prefix\n",
    "    elif test:\n",
    "        fut_len = future_len\n",
    "        prefix = 'test_'\n",
    "    else:\n",
    "        fut_len = future_len\n",
    "        prefix = ''\n",
    "\n",
    "    # Construct the file path using the configuration settings\n",
    "    base_path = f'{folder}/{dataset}_{model}/{transition_matrix}_{noising}'\n",
    "    file_suffix = f'{features}_hist{history}_fut_{0 if conditional else fut_len}'\n",
    "\n",
    "    if conditional:\n",
    "        sample_list = torch.load(f'{base_path}/{prefix}fut_len_{fut_len}_samples_one_shot_{file_suffix}.pth')\n",
    "        valid_ids = torch.load(f'{base_path}/{prefix}fut_len_{fut_len}_valid_ids_{file_suffix}.pth')\n",
    "        samples_raw = torch.load(f'{base_path}/{prefix}fut_len_{fut_len}_samples_raw_{file_suffix}.pth')\n",
    "        samples_valid = torch.load(f'{base_path}/{prefix}fut_len_{fut_len}_samples_valid_{file_suffix}.pth')\n",
    "        ground_truth_hist = torch.load(f'{base_path}/{prefix}fut_len_{fut_len}_gt_hist_{file_suffix}.pth')\n",
    "        ground_truth_fut = torch.load(f'{base_path}/{prefix}fut_len_{fut_len}_gt_fut_{file_suffix}.pth')\n",
    "    else:\n",
    "        sample_list = torch.load(f'{base_path}/{prefix}samples_one_shot_{file_suffix}.pth')\n",
    "        valid_ids = torch.load(f'{base_path}/{prefix}valid_ids_{file_suffix}.pth')\n",
    "        samples_raw = torch.load(f'{base_path}/{prefix}samples_raw_{file_suffix}.pth')\n",
    "        samples_valid = torch.load(f'{base_path}/{prefix}samples_valid_{file_suffix}.pth')\n",
    "        ground_truth_hist = torch.load(f'{base_path}/{prefix}gt_hist_{file_suffix}.pth')\n",
    "        ground_truth_fut = torch.load(f'{base_path}/{prefix}gt_fut_{file_suffix}.pth')\n",
    "\n",
    "    res = {\n",
    "        'sample_list': sample_list,\n",
    "        'samples_valid': samples_valid,\n",
    "        'valid_ids': valid_ids,\n",
    "        'samples_raw': samples_raw,\n",
    "        'ground_truth_hist': ground_truth_hist,\n",
    "        'ground_truth_fut': ground_truth_fut,\n",
    "        'config': config,  # Store the configuration for reference\n",
    "    }\n",
    "    # Use a tuple of (future_length, configuration index) as the key\n",
    "    res_dict[(fut_len, idx)] = res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/dataset/trajectory_dataset_geometric.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nodes = [(i, {'pos': torch.tensor(pos, device=device)}) for i, pos in enumerate(node_coordinates)]\n",
      "100%|██████████| 2665/2665 [00:02<00:00, 942.94it/s] \n"
     ]
    }
   ],
   "source": [
    "'''def load_new_format(file_path, edge_features, device):\n",
    "        paths = []\n",
    "        with h5py.File(file_path, 'r') as new_hf:\n",
    "            node_coordinates = torch.tensor(new_hf['graph']['node_coordinates'][:], dtype=torch.float, device=device)\n",
    "            # Normalize the coordinates to (0, 1) if any of the coordinates is larger than 1\n",
    "            if node_coordinates.max() > 1:\n",
    "                max_values = node_coordinates.max(0)[0]\n",
    "                min_values = node_coordinates.min(0)[0]\n",
    "                node_coordinates[:, 0] = (node_coordinates[:, 0] - min_values[0]) / (max_values[0] - min_values[0])\n",
    "                node_coordinates[:, 1] = (node_coordinates[:, 1] - min_values[1]) / (max_values[1] - min_values[1])\n",
    "            edges = new_hf['graph']['edges'][:]\n",
    "            edge_coordinates = node_coordinates[edges]\n",
    "            nodes = [(i, {'pos': torch.tensor(pos, device=device)}) for i, pos in enumerate(node_coordinates)]\n",
    "            edges = [tuple(edge) for edge in edges]\n",
    "\n",
    "            for i in tqdm(new_hf['trajectories'].keys()):\n",
    "                path_group = new_hf['trajectories'][i]\n",
    "                path = {attr: torch.tensor(path_group[attr][()], device=device) for attr in path_group.keys() if attr in ['coordinates', 'edge_idxs', 'edge_orientations']}\n",
    "                paths.append(path)\n",
    "            if 'road_type' in edge_features:\n",
    "                onehot_encoded_road_type = new_hf['graph']['road_type'][:]\n",
    "                return paths, nodes, edges, edge_coordinates, onehot_encoded_road_type\n",
    "            else:\n",
    "                return paths, nodes, edges, edge_coordinates\n",
    "        return paths, nodes, edges, edge_coordinates'''\n",
    "\n",
    "import sys\n",
    "sys.path.append('/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction')\n",
    "\n",
    "from dataset.trajectory_dataset_geometric import TrajectoryGeoDataset\n",
    "\n",
    "if test:\n",
    "    paths, nodes, edges, edge_coordinates = TrajectoryGeoDataset.load_new_format(f'/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/data/{dataset}_test.h5', features, 'cpu')\n",
    "else:\n",
    "    paths, nodes, edges, edge_coordinates = TrajectoryGeoDataset.load_new_format(f'/ceph/hdd/students/schmitj/MA_Diffusion_based_trajectory_prediction/data/{dataset}_val.h5', features, 'cpu')\n",
    "indexed_edges = [((start, end), index) for index, (start, end) in enumerate(edges)]\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "for (start, end), index in indexed_edges:\n",
    "        G.add_edge(start, end, index=index, default_orientation=(start, end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_paths_random_multiple_configs(res_dict, edge_coordinates, configurations, conditional=True, valid=False,\n",
    "                                       num_paths_per_config=8, num_cols=4, zoom_in=True,\n",
    "                                       save_path='trajectory_grid.png'):\n",
    "    \"\"\"\n",
    "    Plots a grid of trajectories for multiple configurations.\n",
    "\n",
    "    Parameters:\n",
    "    - res_dict: Dictionary with keys as (future_length, config index), values as data dictionaries.\n",
    "    - edge_coordinates: Tensor of shape (num_edges, 2, 2) with edge coordinates.\n",
    "    - configurations: List of configuration dictionaries.\n",
    "    - conditional: Boolean indicating whether the model is conditional.\n",
    "    - num_paths_per_config: Number of trajectories to plot per configuration.\n",
    "    - num_cols: Number of columns in the grid.\n",
    "    - zoom_in: If True, zooms into the trajectory area.\n",
    "    - save_path: File path to save the figure.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from matplotlib.lines import Line2D\n",
    "\n",
    "    # Set the plotting style and parameters\n",
    "    plt.style.use('seaborn-v0_8-paper')\n",
    "    plt.rcParams.update({\n",
    "        'axes.labelsize': 14,\n",
    "        'axes.titlesize': 16,\n",
    "        'xtick.labelsize': 12,\n",
    "        'ytick.labelsize': 12,\n",
    "        'legend.fontsize': 12,\n",
    "        'axes.grid': False,\n",
    "        'grid.alpha': 0.4,\n",
    "        'lines.linewidth': 2,\n",
    "        'mathtext.fontset': 'cm',  # Use Computer Modern fonts for math\n",
    "        'mathtext.rm': 'serif',\n",
    "    })\n",
    "\n",
    "    num_configs = len(configurations)\n",
    "    num_rows_per_config = (num_paths_per_config + num_cols - 1) // num_cols  # Ceiling division\n",
    "    total_rows = num_configs * num_rows_per_config\n",
    "\n",
    "    # Setup the subplot layout with decreased vertical spacing within configurations\n",
    "    fig, axs = plt.subplots(total_rows, num_cols, figsize=(5 * num_cols, 5 * total_rows),\n",
    "                            gridspec_kw={'hspace': 0.2})  # Reduce hspace to decrease vertical spacing\n",
    "    axs = np.array(axs)\n",
    "\n",
    "    # Adjust layout to make room for the legend, labels, and to accommodate the left label\n",
    "    plt.subplots_adjust(top=0.88, bottom=0.05, left=0.12, right=0.95, wspace=0.1)\n",
    "\n",
    "    # Create legend elements manually to ensure all lines are included\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], color='blue', lw=2, label='History'),\n",
    "        Line2D([0], [0], color='green', lw=2, label='Ground Truth Future'),\n",
    "        Line2D([0], [0], color='orange', lw=2, linestyle=':', label='Predicted Future'),\n",
    "    ]\n",
    "\n",
    "    plot_idx = 0\n",
    "    for config_idx, config in enumerate(configurations):\n",
    "        fut_len = config['conditional_fut_len'] if conditional else config['future_len']\n",
    "        key = (fut_len, config_idx)\n",
    "        res = res_dict[key]\n",
    "        sample_list = res['sample_list']\n",
    "        if valid:\n",
    "            sample_list = res['samples_valid']\n",
    "        ground_truth_hist = res['ground_truth_hist']\n",
    "        ground_truth_fut = res['ground_truth_fut']\n",
    "        valid_ids = res['valid_ids']\n",
    "\n",
    "        path_count = 0\n",
    "        attempts = 0\n",
    "        max_attempts = 1000\n",
    "\n",
    "        while path_count < num_paths_per_config and attempts < max_attempts:\n",
    "            batch_idx = torch.randint(0, len(ground_truth_hist), (1,)).item()\n",
    "            idx = torch.randint(0, len(ground_truth_hist[batch_idx]), (1,)).item()\n",
    "            attempts += 1\n",
    "            if valid and valid_ids[batch_idx][idx] is None:\n",
    "                continue\n",
    "\n",
    "            if idx >= len(ground_truth_hist[batch_idx]):\n",
    "                continue\n",
    "\n",
    "            row = (config_idx * num_rows_per_config) + (path_count // num_cols)\n",
    "            col = path_count % num_cols\n",
    "            ax = axs[row, col] if total_rows > 1 else axs[col]\n",
    "            ax.cla()\n",
    "\n",
    "            # Plot all edges as background with lighter color\n",
    "            for edge in edge_coordinates:\n",
    "                ax.plot(edge[:, 0], edge[:, 1], color='lightgrey', linewidth=0.5, zorder=1)\n",
    "\n",
    "            # Plot trajectories\n",
    "            def plot_trajectory(edge_indices, color, linestyle='-', lw=2):\n",
    "                edge_indices = edge_indices[edge_indices >= 0]\n",
    "                if edge_indices.dim() == 2:\n",
    "                    edge_indices = edge_indices.squeeze(0)\n",
    "                if edge_indices.numel() > 0:\n",
    "                    for edge_idx in edge_indices:\n",
    "                        edge = edge_coordinates[edge_idx]\n",
    "                        ax.plot(edge[:, 0], edge[:, 1], color=color, linewidth=lw, linestyle=linestyle, zorder=2)\n",
    "\n",
    "            \n",
    "            plot_trajectory(ground_truth_fut[batch_idx][idx], color='green', linestyle='-', lw=2)\n",
    "            plot_trajectory(ground_truth_hist[batch_idx][idx], color='blue', linestyle='-', lw=2)\n",
    "            plot_trajectory(sample_list[batch_idx][idx], color='orange', linestyle=':', lw=3)\n",
    "\n",
    "            if zoom_in:\n",
    "                all_edges = torch.cat([ground_truth_hist[batch_idx][idx], ground_truth_fut[batch_idx][idx], sample_list[batch_idx][idx]])\n",
    "                all_edges = all_edges[all_edges >= 0]\n",
    "                if all_edges.numel() > 0:\n",
    "                    all_coords = edge_coordinates[all_edges].view(-1, 2)\n",
    "                    xmin, xmax = all_coords[:, 0].min(), all_coords[:, 0].max()\n",
    "                    ymin, ymax = all_coords[:, 1].min(), all_coords[:, 1].max()\n",
    "                    x_margin = (xmax - xmin) * 0.2\n",
    "                    y_margin = (ymax - ymin) * 0.2\n",
    "                    ax.set_xlim(xmin - x_margin, xmax + x_margin)\n",
    "                    ax.set_ylim(ymin - y_margin, ymax + y_margin)\n",
    "            else:\n",
    "                ax.set_xlim(edge_coordinates[:, :, 0].min(), edge_coordinates[:, :, 0].max())\n",
    "                ax.set_ylim(edge_coordinates[:, :, 1].min(), edge_coordinates[:, :, 1].max())\n",
    "\n",
    "            # Remove axes ticks and labels\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            ax.axis('off')\n",
    "\n",
    "            path_count += 1\n",
    "            plot_idx += 1\n",
    "\n",
    "    # Remove any unused subplots\n",
    "    total_plots = total_rows * num_cols\n",
    "    for i in range(plot_idx, total_plots):\n",
    "        row = i // num_cols\n",
    "        col = i % num_cols\n",
    "        if total_rows > 1:\n",
    "            fig.delaxes(axs[row, col])\n",
    "        else:\n",
    "            fig.delaxes(axs[col])\n",
    "\n",
    "    # Adjust the figure canvas to update positions\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    # Increase the vertical space between the legend and the first row of plots\n",
    "    legend_y = 0.94  # Adjust this value to move the legend higher or lower\n",
    "    fig.legend(handles=legend_elements, loc='upper center', ncol=3, bbox_to_anchor=(0.5, legend_y),\n",
    "               frameon=True, fontsize=22)\n",
    "\n",
    "    # Add horizontal lines and future length labels\n",
    "    features = ['$F_1$', '$F_2$', '$F_3$']\n",
    "    for config_idx in range(num_configs):\n",
    "        # Determine the vertical positions\n",
    "        row_start = config_idx * num_rows_per_config\n",
    "        row_end = row_start + num_rows_per_config - 1\n",
    "\n",
    "        # Get the positions of the top and bottom of the section\n",
    "        bbox_top = axs[row_start, 0].get_position()\n",
    "        bbox_bottom = axs[row_end, 0].get_position()\n",
    "\n",
    "        section_top = bbox_top.y1\n",
    "        section_bottom = bbox_bottom.y0\n",
    "\n",
    "        # Calculate the middle y-position for the label\n",
    "        section_middle = (section_top + section_bottom) / 2\n",
    "\n",
    "        # Add the future length label to the left\n",
    "        fut_len = configurations[config_idx]['conditional_fut_len'] if conditional else configurations[config_idx]['future_len']\n",
    "        f = 'f'\n",
    "        # Fix the LaTeX code for fut_len_display\n",
    "        if conditional:\n",
    "            fut_len_display = f'$f_{{cond}} = {fut_len}$'\n",
    "        else:\n",
    "            fut_len_display = f'$f = {fut_len}$'\n",
    "\n",
    "        #fut_len_display = features[config_idx]\n",
    "        # Add text to the left of the plots, centered vertically\n",
    "        #fig.text(0.05, section_middle, fut_len_display, ha='left', va='center', fontsize=24)\n",
    "\n",
    "        # Add horizontal line at the bottom of the section, except for the last one\n",
    "        if config_idx < num_configs - 1:\n",
    "            # Position for the line is between this section and the next\n",
    "            next_bbox_top = axs[row_end + 1, 0].get_position()\n",
    "            line_y = (bbox_bottom.y0 + next_bbox_top.y1) / 2\n",
    "\n",
    "            # Add horizontal line across the figure\n",
    "            fig.add_artist(Line2D([0.1, 0.99], [line_y, line_y], transform=fig.transFigure, color='lightgrey', linewidth=1.5))\n",
    "\n",
    "    # Save and show the figure\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "save_path = f'{folder}/{dataset}_multiple_configs/output'\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "if conditional:\n",
    "    future_len_str = \"_\".join([str(config['conditional_fut_len']) for config in configurations])\n",
    "    save_filename = f'cond_fut_lens_{future_len_str}_multiple_configs.png'\n",
    "else:\n",
    "    future_len_str = \"_\".join([str(config['future_len']) for config in configurations])\n",
    "    save_filename = f'fut_lens_{future_len_str}_multiple_configs.png'\n",
    "\n",
    "save_full_path = os.path.join(save_path, save_filename)\n",
    "\n",
    "print(\"Saved at\", save_full_path)\n",
    "\n",
    "plot_paths_random_multiple_configs(res_dict, edge_coordinates, configurations,\n",
    "                                   conditional=conditional, valid=False, num_paths_per_config=8, num_cols=4,\n",
    "                                   save_path=save_full_path, zoom_in=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valid Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_paths_random_multiple_configs(res_dict, edge_coordinates, configurations,\n",
    "                                   conditional=conditional, valid=True, num_paths_per_config=8, num_cols=4,\n",
    "                                   save_path=save_full_path, zoom_in=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d3pm_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
